{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4b1b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "# Configure amd test GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Prevent automatic GPU memory pre-allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(tf.__version__)\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4701cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole network composed of 63 layers, approximately 2.6m total no. of parameters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPool2D,\\\n",
    "                                    GlobalAvgPool2D, Dense, Add, Concatenate, Input,\\\n",
    "                                    Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Note: tf version 2.9.1 does not have Identity layer. Implement our own identity layer which is argument insensitive\n",
    "# and returns its inputs argument as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300f98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpriupperhalf_convno, batch_no, pooling_dropout, output_convno,\n",
    "# fc_dropout, lr, l2_conv2d\n",
    "def input_module(x):\n",
    "\n",
    "    # Set no. of filters to 256 to match the output of Add layer at the end of\n",
    "    # upper half of MPRI module\n",
    "    x = Conv2D(filters = 256, kernel_size = 3, strides = 1,\n",
    "               padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Normally, strides = 2 to reduce dimensions but set strides =1 for now to match\n",
    "    # output shapes\n",
    "    x = MaxPool2D(pool_size= 3, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def mpri_upperhalf(x):\n",
    "\n",
    "    # Save input as another variable since need to add input of mpri\n",
    "    # with output of mpri\n",
    "    input_tensor = x\n",
    "\n",
    "    # Bottleneck layer with 1x1 conv filter\n",
    "    bottlenecked_tensor = Conv2D(filters = 128, kernel_size = 1, strides = 1,\n",
    "                                 padding = 'same')(x)\n",
    "\n",
    "    # First path\n",
    "    firstpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    firstpath_tensor = ReLU()(firstpath_tensor)\n",
    "    firstpath_tensor = Conv2D(filters = 64, kernel_size = 1, strides = 1,\n",
    "                              padding = 'same')(firstpath_tensor)\n",
    "\n",
    "    # Second path\n",
    "    secondpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    secondpath_tensor = ReLU()(secondpath_tensor)\n",
    "    secondpath_tensor = Conv2D(filters = 32, kernel_size = (5,1), strides = 1,\n",
    "                               padding = 'same')(secondpath_tensor)\n",
    "    secondpath_tensor = Conv2D(filters = 32, kernel_size = (1,3), strides = 1,\n",
    "                               padding = 'same')(secondpath_tensor)\n",
    "\n",
    "    # Third path\n",
    "    # Normally, strides = 2 to reduce the dimensions of the input\n",
    "    # In this case, experiment with strides = 1 to fit desired output shape for concatenation layer\n",
    "    thirdpath_tensor = MaxPool2D(pool_size = 3, strides = 1, padding = 'same')(bottlenecked_tensor)\n",
    "    thirdpath_tensor = BatchNormalization()(thirdpath_tensor)\n",
    "    thirdpath_tensor = ReLU()(thirdpath_tensor)\n",
    "    thirdpath_tensor = Conv2D(filters = 32, kernel_size = 3, strides = 1,\n",
    "                              padding = 'same')(thirdpath_tensor)\n",
    "\n",
    "    # Fourth path\n",
    "    fourthpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    fourthpath_tensor = ReLU()(fourthpath_tensor)\n",
    "    fourthpath_tensor = Conv2D(filters = 32, kernel_size = 1, strides = 1,\n",
    "                               padding = 'same')(fourthpath_tensor)\n",
    "\n",
    "    fourthpath_tensor = BatchNormalization()(fourthpath_tensor)\n",
    "    fourthpath_tensor = ReLU()(fourthpath_tensor)\n",
    "    fourthpath_tensor = Conv2D(filters = 128, kernel_size = 1, strides = 1,\n",
    "                               padding = 'same')(fourthpath_tensor)\n",
    "\n",
    "    # Depth concatenate the output from the four paths\n",
    "    concatenated_tensor = Concatenate()([firstpath_tensor, secondpath_tensor, thirdpath_tensor, fourthpath_tensor])\n",
    "\n",
    "    # Add the depth concatenated layer and input tensor\n",
    "    # To add successfully, input tensor must have 256 channels as well to match the shape of\n",
    "    # the concatenated tensor\n",
    "    output_tensor = Add()([input_tensor, concatenated_tensor])\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "def mpri_lowerhalf(x):\n",
    "\n",
    "    def conv3x3_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 3, strides = 1,\n",
    "                   padding = 'same')(x)\n",
    "        return x\n",
    "\n",
    "    def conv1x1_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 1, strides = 1,\n",
    "                   padding = 'same')(x)\n",
    "        return x\n",
    "\n",
    "    # --- First layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # --- Second layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(upperpath_tensor)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(lowerpath_tensor)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # --- Third layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(upperpath_tensor)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(lowerpath_tensor)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # Final layer - Add upper and lower path tensors\n",
    "    output_tensor = Add()([upperpath_tensor, lowerpath_tensor])\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "def output_module(x, num_classes = 1000):\n",
    "\n",
    "    x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    x = Dropout(rate = 0.5)(x)\n",
    "    x = Dense(units = num_classes, activation = 'softmax')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2278f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/mpri\n",
      "/home/jovyan/committed_git/datasets\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../datasets')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2113482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Get dictionary of RP index and coordinates\n",
    "# Open HDF5 file and access the dataset\n",
    "filename = 'dataset_SNR10_outdoor.mat'\n",
    "hdf5_file = h5py.File(filename, 'r')\n",
    "\n",
    "features_dataset = hdf5_file['features']\n",
    "labels_dataset = hdf5_file['labels']['position']\n",
    "\n",
    "# Convert HDF5 dataset to NumPy array\n",
    "features = np.array(features_dataset)\n",
    "labels = np.array(labels_dataset)\n",
    "\n",
    "# Prepare features for dataset\n",
    "# Retrieve features from the first UE and transpose the individual matrix\n",
    "features_transposed = np.zeros((3876,193,16), dtype = np.float64)\n",
    "for i in range(len(features)):\n",
    "    features_transposed[i] = features[i][0].T\n",
    "\n",
    "# Prepare labels for dataset\n",
    "count = 0\n",
    "rp_dict = {}\n",
    "# For labels, have a shape of (1,) where that number represents the class of that coordinate\n",
    "\n",
    "for label in labels:\n",
    "    rp_dict[count] = label\n",
    "    count += 1\n",
    "\n",
    "# Close the HDF5 file\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe1528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features np array: (89628, 193, 16)\n",
      "Shape of labels np array: (89628,)\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "features = np.load('augmented_features_10_ue1_v2_ds.npy')\n",
    "labels = np.load('augmented_labels_10_ue1_v2_ds.npy')\n",
    "\n",
    "print(f'Shape of features np array: {features.shape}')\n",
    "print(f'Shape of labels np array: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a00f2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755b6194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/datasets\n",
      "/home/jovyan/committed_git/mpri\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../mpri')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6c799bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom callbacks to evaluate model\n",
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, X_val, Y_val, cur_val_loss, val_loss_threshold):\n",
    "        super(ValidationCallback,self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.cur_val_loss = cur_val_loss\n",
    "        self.val_loss_threshold = val_loss_threshold\n",
    "        \n",
    "    # number_of_iterations = total_number_of_training_examples / batch_size\n",
    "    # In this case, train example of 1,000 and batch size of 100\n",
    "    # number_of_iterations over 1 epoch is 10\n",
    "    # if have 5 epochs, number of iterations is 50\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "        x_error = (actual[0] - predicted[0])**2\n",
    "        y_error = (actual[1] - predicted[1])**2\n",
    "        z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "        return x_error + y_error + z_error\n",
    "        \n",
    "    # Have one function that reports metrics on end of every epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \n",
    "        # Get evaluation metrics\n",
    "        print('\\n')\n",
    "        print('Epoch End - Custom Validation Callback')\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.X_val, self.Y_val, verbose = 0)\n",
    "        \n",
    "        # Get distance error metrics - RMSE\n",
    "        # Get predictions for each feature heatmap in X_val\n",
    "        Y_pred = self.model.predict(self.X_val, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(self.X_val)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[self.Y_val[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(Y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            err_sum += err\n",
    "        rmse = np.sqrt((err_sum/len(self.X_val)))\n",
    "       \n",
    "        # Save values to log\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['val_accuracy'] = val_accuracy\n",
    "        logs['rmse'] = rmse\n",
    "        \n",
    "        # Whenever validation loss is minimised and below threshold, save the model\n",
    "        # and update current minimum loss\n",
    "        if val_loss < self.cur_val_loss and val_loss < self.val_loss_threshold:\n",
    "            self.model.save('mpri_model.h5')\n",
    "            self.cur_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3182d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but removed early stopping callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import time\n",
    "\n",
    "class MPRI_model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        model_input = Input(shape = (193,16,1))\n",
    "        model_output = output_module(mpri_lowerhalf(mpri_upperhalf(input_module(model_input))), num_classes = 3876)\n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                      loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train_model(self):\n",
    "    \n",
    "        # In training, use model.fit() validation callback to get results on training loss, training accuracy,\n",
    "        # validation loss and validation accuracy and rmse after every epoch\n",
    "        val_callback = ValidationCallback(X_test, y_test, math.inf, 1)\n",
    "        \n",
    "        # Can leave out early stopping for now, manually observe when val_loss stops improving to determine\n",
    "        # optimal number of epochs\n",
    "        \n",
    "        # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        start_time = time.time()\n",
    "        hist = self.model.fit(X_train, y_train,\n",
    "                              epochs = 100,\n",
    "                              batch_size = 64,\n",
    "                              callbacks = [val_callback]\n",
    "#                              callbacks = [val_callback, stop_early]\n",
    "                             )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'Time taken to clear 100 epochs: {end_time - start_time}')\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "            x_error = (actual[0] - predicted[0])**2\n",
    "            y_error = (actual[1] - predicted[1])**2\n",
    "            z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "            return x_error + y_error + z_error\n",
    "    \n",
    "    def calc_errorcdf(self, errors):\n",
    "        \n",
    "        # Sort the array\n",
    "        sorted_data = np.sort(errors)\n",
    "\n",
    "        # Calculate cumulative probabilities\n",
    "        n = len(sorted_data)\n",
    "        cumulative_probs = np.arange(1, n + 1) / n\n",
    "    \n",
    "        return (sorted_data, cumulative_probs)\n",
    "        \n",
    "    def test_model(self, filename):\n",
    "        \n",
    "        # Load model\n",
    "        self.model = keras.models.load_model(filename)\n",
    "        \n",
    "        # In test, use model.predict() to get the RMSE errors of predictions and CDF of distance error\n",
    "        y_pred = self.model.predict(X_test, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        dist_errors = []\n",
    "        max_disterror = -math.inf\n",
    "        max_disterror_actual, max_disterror_pred = None, None\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(X_test)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[y_test[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            \n",
    "            # Update the maximum errror, if needed\n",
    "            dist_err = np.sqrt(err)\n",
    "            if dist_err > max_disterror:\n",
    "                \n",
    "                # Update max error\n",
    "                max_disterror = dist_err\n",
    "                \n",
    "                # Return the class index and then retrieve actual coordinates from rp_dict\n",
    "                max_disterror_actual = y_test[i]\n",
    "                max_disterror_pred = predicted_rp\n",
    "            \n",
    "            # Append error to distance errors\n",
    "            dist_errors.append(dist_err)\n",
    "            err_sum += err\n",
    "            \n",
    "        # Get RMSE of all predicted points\n",
    "        rmse = np.sqrt((err_sum/len(X_test)))\n",
    "        \n",
    "        # Get actual and predicted point with the largest error\n",
    "        print(f'Largest error: {max_disterror}, Actual RP index: {max_disterror_actual}, Predicted RP index: {max_disterror_pred}')\n",
    "        \n",
    "        return (rmse, *self.calc_errorcdf(dist_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82e08592",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 193, 16, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 193, 16, 256  2560        ['input_6[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 193, 16, 256  1024       ['conv2d_75[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 193, 16, 256  0           ['batch_normalization_65[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_40 (MaxPooling2D  (None, 97, 8, 256)  0           ['re_lu_65[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 97, 8, 128)   32896       ['max_pooling2d_40[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 97, 8, 128)  512         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 97, 8, 128)  512         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_41 (MaxPooling2D  (None, 97, 8, 128)  0           ['conv2d_76[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 97, 8, 32)    4128        ['re_lu_69[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 97, 8, 128)  512         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 97, 8, 128)  512         ['max_pooling2d_41[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 97, 8, 32)   128         ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 97, 8, 32)    20512       ['re_lu_67[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 97, 8, 32)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 97, 8, 64)    8256        ['re_lu_66[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 97, 8, 32)    3104        ['conv2d_78[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 97, 8, 32)    36896       ['re_lu_68[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 97, 8, 128)   4224        ['re_lu_70[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 97, 8, 256)   0           ['conv2d_77[0][0]',              \n",
      "                                                                  'conv2d_79[0][0]',              \n",
      "                                                                  'conv2d_80[0][0]',              \n",
      "                                                                  'conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 97, 8, 256)   0           ['max_pooling2d_40[0][0]',       \n",
      "                                                                  'concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_42 (MaxPooling2D  (None, 49, 4, 256)  0           ['add_40[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_43 (MaxPooling2D  (None, 49, 4, 256)  0           ['add_40[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 49, 4, 256)  1024        ['max_pooling2d_42[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 49, 4, 256)  1024        ['max_pooling2d_43[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)                (None, 49, 4, 256)   0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)                (None, 49, 4, 256)   0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 49, 4, 256)   590080      ['re_lu_71[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 49, 4, 256)   65792       ['re_lu_72[0][0]']               \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 49, 4, 256)   0           ['max_pooling2d_42[0][0]',       \n",
      "                                                                  'conv2d_83[0][0]',              \n",
      "                                                                  'conv2d_84[0][0]']              \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 49, 4, 256)   0           ['max_pooling2d_43[0][0]',       \n",
      "                                                                  'conv2d_84[0][0]',              \n",
      "                                                                  'add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_44 (MaxPooling2D  (None, 25, 2, 256)  0           ['add_41[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_45 (MaxPooling2D  (None, 25, 2, 256)  0           ['add_42[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 25, 2, 256)  1024        ['max_pooling2d_44[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 25, 2, 256)  1024        ['max_pooling2d_45[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)                (None, 25, 2, 256)   0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)                (None, 25, 2, 256)   0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 25, 2, 256)   590080      ['re_lu_73[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 25, 2, 256)   65792       ['re_lu_74[0][0]']               \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 25, 2, 256)   0           ['max_pooling2d_44[0][0]',       \n",
      "                                                                  'conv2d_85[0][0]',              \n",
      "                                                                  'conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 25, 2, 256)   0           ['max_pooling2d_45[0][0]',       \n",
      "                                                                  'conv2d_86[0][0]',              \n",
      "                                                                  'add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_46 (MaxPooling2D  (None, 13, 1, 256)  0           ['add_43[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_47 (MaxPooling2D  (None, 13, 1, 256)  0           ['add_44[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_46[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_47[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 13, 1, 256)   590080      ['re_lu_75[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 13, 1, 256)   65792       ['re_lu_76[0][0]']               \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 13, 1, 256)   0           ['max_pooling2d_46[0][0]',       \n",
      "                                                                  'conv2d_87[0][0]',              \n",
      "                                                                  'conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 13, 1, 256)   0           ['max_pooling2d_47[0][0]',       \n",
      "                                                                  'conv2d_88[0][0]',              \n",
      "                                                                  'add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 13, 1, 256)   0           ['add_45[0][0]',                 \n",
      "                                                                  'add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 13, 1, 128)   295040      ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 13, 1, 128)  512         ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 13, 1, 128)   0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['re_lu_77[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128)          0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 3876)         500004      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,885,092\n",
      "Trainable params: 2,880,164\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 7.6947 - accuracy: 0.0030\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 40s 35ms/step - loss: 7.6947 - accuracy: 0.0030 - val_loss: 7.1314 - val_accuracy: 0.0099 - rmse: 7.1105\n",
      "Epoch 2/100\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 6.6030 - accuracy: 0.0201\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 6.6030 - accuracy: 0.0201 - val_loss: 5.9425 - val_accuracy: 0.0406 - rmse: 5.4641\n",
      "Epoch 3/100\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 5.5298 - accuracy: 0.0691\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 5.5298 - accuracy: 0.0691 - val_loss: 4.8031 - val_accuracy: 0.1623 - rmse: 4.4739\n",
      "Epoch 4/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 4.5058 - accuracy: 0.1605\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 4.5053 - accuracy: 0.1606 - val_loss: 3.8132 - val_accuracy: 0.3289 - rmse: 3.4343\n",
      "Epoch 5/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 3.6416 - accuracy: 0.2742\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 3.6413 - accuracy: 0.2742 - val_loss: 2.9217 - val_accuracy: 0.4833 - rmse: 2.4782\n",
      "Epoch 6/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.9934 - accuracy: 0.3720\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 2.9933 - accuracy: 0.3721 - val_loss: 2.4609 - val_accuracy: 0.5928 - rmse: 2.0282\n",
      "Epoch 7/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.5115 - accuracy: 0.4513\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.5114 - accuracy: 0.4512 - val_loss: 1.9887 - val_accuracy: 0.6761 - rmse: 1.6841\n",
      "Epoch 8/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.1537 - accuracy: 0.5170\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.1536 - accuracy: 0.5170 - val_loss: 1.7851 - val_accuracy: 0.6719 - rmse: 1.5845\n",
      "Epoch 9/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.8775 - accuracy: 0.5672\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 1.8775 - accuracy: 0.5673 - val_loss: 1.4874 - val_accuracy: 0.7463 - rmse: 1.3549\n",
      "Epoch 10/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.6659 - accuracy: 0.6045\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.6655 - accuracy: 0.6046 - val_loss: 1.3064 - val_accuracy: 0.7902 - rmse: 1.2555\n",
      "Epoch 11/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.4888 - accuracy: 0.6378\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.4888 - accuracy: 0.6378 - val_loss: 1.2183 - val_accuracy: 0.7522 - rmse: 1.2638\n",
      "Epoch 12/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.3497 - accuracy: 0.6615\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.3497 - accuracy: 0.6615 - val_loss: 1.0611 - val_accuracy: 0.8112 - rmse: 1.0999\n",
      "Epoch 13/100\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 1.2320 - accuracy: 0.6875\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.2321 - accuracy: 0.6875 - val_loss: 0.9739 - val_accuracy: 0.8207 - rmse: 1.0687\n",
      "Epoch 14/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.1322 - accuracy: 0.7086\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.1323 - accuracy: 0.7086 - val_loss: 0.8894 - val_accuracy: 0.8415 - rmse: 0.9647\n",
      "Epoch 15/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.0390 - accuracy: 0.7292\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.0390 - accuracy: 0.7291 - val_loss: 0.8231 - val_accuracy: 0.8451 - rmse: 0.9031\n",
      "Epoch 16/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.9674 - accuracy: 0.7410\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.9673 - accuracy: 0.7410 - val_loss: 0.7453 - val_accuracy: 0.8676 - rmse: 0.8486\n",
      "Epoch 17/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8987 - accuracy: 0.7579\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8986 - accuracy: 0.7580 - val_loss: 0.7381 - val_accuracy: 0.8393 - rmse: 0.8629\n",
      "Epoch 18/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8415 - accuracy: 0.7693\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8414 - accuracy: 0.7694 - val_loss: 0.6548 - val_accuracy: 0.8775 - rmse: 0.7569\n",
      "Epoch 19/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7918 - accuracy: 0.7816\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7918 - accuracy: 0.7817 - val_loss: 0.6412 - val_accuracy: 0.8677 - rmse: 0.7567\n",
      "Epoch 20/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7428 - accuracy: 0.7921\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7427 - accuracy: 0.7920 - val_loss: 0.5734 - val_accuracy: 0.8940 - rmse: 0.7078\n",
      "Epoch 21/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.8037\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.7033 - accuracy: 0.8037 - val_loss: 0.6184 - val_accuracy: 0.8517 - rmse: 0.8543\n",
      "Epoch 22/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6668 - accuracy: 0.8119\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6669 - accuracy: 0.8119 - val_loss: 0.5314 - val_accuracy: 0.8950 - rmse: 0.6647\n",
      "Epoch 23/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6302 - accuracy: 0.8198\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6304 - accuracy: 0.8198 - val_loss: 0.5232 - val_accuracy: 0.8801 - rmse: 0.7258\n",
      "Epoch 24/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.8286\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5987 - accuracy: 0.8286 - val_loss: 0.4820 - val_accuracy: 0.8927 - rmse: 0.6486\n",
      "Epoch 25/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5686 - accuracy: 0.8353\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.5686 - accuracy: 0.8353 - val_loss: 0.5370 - val_accuracy: 0.8590 - rmse: 0.7572\n",
      "Epoch 26/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.8423\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5452 - accuracy: 0.8423 - val_loss: 0.4276 - val_accuracy: 0.9090 - rmse: 0.6334\n",
      "Epoch 27/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5203 - accuracy: 0.8478\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.5203 - accuracy: 0.8478 - val_loss: 0.4579 - val_accuracy: 0.8884 - rmse: 0.6762\n",
      "Epoch 28/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.8522\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.5005 - accuracy: 0.8522 - val_loss: 0.4493 - val_accuracy: 0.8869 - rmse: 0.6864\n",
      "Epoch 29/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4808 - accuracy: 0.8582\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4807 - accuracy: 0.8583 - val_loss: 0.3923 - val_accuracy: 0.9063 - rmse: 0.6018\n",
      "Epoch 30/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8631\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4630 - accuracy: 0.8631 - val_loss: 0.3623 - val_accuracy: 0.9218 - rmse: 0.5799\n",
      "Epoch 31/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4461 - accuracy: 0.8665\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.4460 - accuracy: 0.8666 - val_loss: 0.4222 - val_accuracy: 0.8829 - rmse: 0.6421\n",
      "Epoch 32/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8708\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.4286 - accuracy: 0.8708 - val_loss: 0.3648 - val_accuracy: 0.9126 - rmse: 0.5745\n",
      "Epoch 33/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8742\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.4161 - accuracy: 0.8743 - val_loss: 0.3729 - val_accuracy: 0.9034 - rmse: 0.6016\n",
      "Epoch 34/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4001 - accuracy: 0.8787\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4002 - accuracy: 0.8787 - val_loss: 0.3167 - val_accuracy: 0.9314 - rmse: 0.5015\n",
      "Epoch 35/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8830\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3851 - accuracy: 0.8830 - val_loss: 0.3008 - val_accuracy: 0.9346 - rmse: 0.4954\n",
      "Epoch 36/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3748 - accuracy: 0.8850\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3748 - accuracy: 0.8849 - val_loss: 0.3185 - val_accuracy: 0.9246 - rmse: 0.5207\n",
      "Epoch 37/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.8882\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3653 - accuracy: 0.8882 - val_loss: 0.3126 - val_accuracy: 0.9240 - rmse: 0.5221\n",
      "Epoch 38/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8907\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3522 - accuracy: 0.8907 - val_loss: 0.2701 - val_accuracy: 0.9415 - rmse: 0.4853\n",
      "Epoch 39/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8953\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3433 - accuracy: 0.8952 - val_loss: 0.3017 - val_accuracy: 0.9215 - rmse: 0.5158\n",
      "Epoch 40/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8971\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3333 - accuracy: 0.8971 - val_loss: 0.2709 - val_accuracy: 0.9368 - rmse: 0.4909\n",
      "Epoch 41/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8988\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3260 - accuracy: 0.8987 - val_loss: 0.2903 - val_accuracy: 0.9254 - rmse: 0.5352\n",
      "Epoch 42/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9023\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3141 - accuracy: 0.9023 - val_loss: 0.2544 - val_accuracy: 0.9422 - rmse: 0.4611\n",
      "Epoch 43/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3042 - accuracy: 0.9047\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3043 - accuracy: 0.9047 - val_loss: 0.2722 - val_accuracy: 0.9300 - rmse: 0.4914\n",
      "Epoch 44/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.9059\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3016 - accuracy: 0.9060 - val_loss: 0.2452 - val_accuracy: 0.9423 - rmse: 0.4616\n",
      "Epoch 45/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2920 - accuracy: 0.9084\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2921 - accuracy: 0.9084 - val_loss: 0.2513 - val_accuracy: 0.9382 - rmse: 0.5007\n",
      "Epoch 46/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.9125\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2844 - accuracy: 0.9124 - val_loss: 0.2497 - val_accuracy: 0.9379 - rmse: 0.4828\n",
      "Epoch 47/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9125\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2778 - accuracy: 0.9124 - val_loss: 0.2432 - val_accuracy: 0.9399 - rmse: 0.4718\n",
      "Epoch 48/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2728 - accuracy: 0.9139\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2728 - accuracy: 0.9138 - val_loss: 0.2397 - val_accuracy: 0.9395 - rmse: 0.4640\n",
      "Epoch 49/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.9151\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2685 - accuracy: 0.9151 - val_loss: 0.2345 - val_accuracy: 0.9421 - rmse: 0.4395\n",
      "Epoch 50/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9191\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2563 - accuracy: 0.9191 - val_loss: 0.2354 - val_accuracy: 0.9423 - rmse: 0.4422\n",
      "Epoch 51/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9183\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2556 - accuracy: 0.9183 - val_loss: 0.2775 - val_accuracy: 0.9182 - rmse: 0.5205\n",
      "Epoch 52/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9188\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2508 - accuracy: 0.9188 - val_loss: 0.2497 - val_accuracy: 0.9316 - rmse: 0.5096\n",
      "Epoch 53/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.9212\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2447 - accuracy: 0.9212 - val_loss: 0.2200 - val_accuracy: 0.9442 - rmse: 0.4593\n",
      "Epoch 54/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9234\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2400 - accuracy: 0.9234 - val_loss: 0.2037 - val_accuracy: 0.9507 - rmse: 0.4318\n",
      "Epoch 55/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9241\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2347 - accuracy: 0.9240 - val_loss: 0.2267 - val_accuracy: 0.9390 - rmse: 0.4367\n",
      "Epoch 56/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9261\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2311 - accuracy: 0.9261 - val_loss: 0.2239 - val_accuracy: 0.9403 - rmse: 0.4922\n",
      "Epoch 57/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9256\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2282 - accuracy: 0.9256 - val_loss: 0.2059 - val_accuracy: 0.9483 - rmse: 0.4246\n",
      "Epoch 58/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9263\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2246 - accuracy: 0.9263 - val_loss: 0.2679 - val_accuracy: 0.9204 - rmse: 0.5392\n",
      "Epoch 59/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9283\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2191 - accuracy: 0.9283 - val_loss: 0.1911 - val_accuracy: 0.9519 - rmse: 0.4012\n",
      "Epoch 60/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.9297\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2150 - accuracy: 0.9296 - val_loss: 0.2087 - val_accuracy: 0.9468 - rmse: 0.4294\n",
      "Epoch 61/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9324\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2091 - accuracy: 0.9323 - val_loss: 0.2533 - val_accuracy: 0.9256 - rmse: 0.5217\n",
      "Epoch 62/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2104 - accuracy: 0.9315\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2105 - accuracy: 0.9315 - val_loss: 0.2023 - val_accuracy: 0.9478 - rmse: 0.4283\n",
      "Epoch 63/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2060 - accuracy: 0.9331\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2060 - accuracy: 0.9331 - val_loss: 0.2141 - val_accuracy: 0.9428 - rmse: 0.4673\n",
      "Epoch 64/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9359\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1992 - accuracy: 0.9358 - val_loss: 0.2296 - val_accuracy: 0.9352 - rmse: 0.4616\n",
      "Epoch 65/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2028 - accuracy: 0.9328\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2028 - accuracy: 0.9328 - val_loss: 0.2083 - val_accuracy: 0.9458 - rmse: 0.4500\n",
      "Epoch 66/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9369\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1935 - accuracy: 0.9369 - val_loss: 0.1811 - val_accuracy: 0.9552 - rmse: 0.4016\n",
      "Epoch 67/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9380\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1894 - accuracy: 0.9380 - val_loss: 0.1779 - val_accuracy: 0.9565 - rmse: 0.3817\n",
      "Epoch 68/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9373\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1890 - accuracy: 0.9374 - val_loss: 0.1852 - val_accuracy: 0.9524 - rmse: 0.4300\n",
      "Epoch 69/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9393\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1848 - accuracy: 0.9393 - val_loss: 0.1837 - val_accuracy: 0.9528 - rmse: 0.3819\n",
      "Epoch 70/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.9378\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1855 - accuracy: 0.9378 - val_loss: 0.1916 - val_accuracy: 0.9499 - rmse: 0.4441\n",
      "Epoch 71/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9412\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1782 - accuracy: 0.9411 - val_loss: 0.2234 - val_accuracy: 0.9342 - rmse: 0.4809\n",
      "Epoch 72/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9397\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1812 - accuracy: 0.9397 - val_loss: 0.1833 - val_accuracy: 0.9530 - rmse: 0.4029\n",
      "Epoch 73/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9426\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1741 - accuracy: 0.9426 - val_loss: 0.2088 - val_accuracy: 0.9428 - rmse: 0.4632\n",
      "Epoch 74/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9437\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1715 - accuracy: 0.9437 - val_loss: 0.1857 - val_accuracy: 0.9530 - rmse: 0.4307\n",
      "Epoch 75/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9429\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1728 - accuracy: 0.9429 - val_loss: 0.1785 - val_accuracy: 0.9535 - rmse: 0.4169\n",
      "Epoch 76/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9423\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1714 - accuracy: 0.9422 - val_loss: 0.1941 - val_accuracy: 0.9487 - rmse: 0.4238\n",
      "Epoch 77/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9431\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1670 - accuracy: 0.9431 - val_loss: 0.1775 - val_accuracy: 0.9546 - rmse: 0.4035\n",
      "Epoch 78/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9439\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1668 - accuracy: 0.9439 - val_loss: 0.1778 - val_accuracy: 0.9518 - rmse: 0.4063\n",
      "Epoch 79/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9461\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1610 - accuracy: 0.9462 - val_loss: 0.1682 - val_accuracy: 0.9584 - rmse: 0.3945\n",
      "Epoch 80/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9447\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1615 - accuracy: 0.9447 - val_loss: 0.1654 - val_accuracy: 0.9583 - rmse: 0.3952\n",
      "Epoch 81/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1590 - accuracy: 0.9466\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1590 - accuracy: 0.9466 - val_loss: 0.1650 - val_accuracy: 0.9602 - rmse: 0.3930\n",
      "Epoch 82/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9484\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1539 - accuracy: 0.9484 - val_loss: 0.1936 - val_accuracy: 0.9477 - rmse: 0.4410\n",
      "Epoch 83/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 0.9467\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1557 - accuracy: 0.9468 - val_loss: 0.1790 - val_accuracy: 0.9526 - rmse: 0.3896\n",
      "Epoch 84/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9480\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1544 - accuracy: 0.9481 - val_loss: 0.1992 - val_accuracy: 0.9447 - rmse: 0.4517\n",
      "Epoch 85/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9489\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1513 - accuracy: 0.9488 - val_loss: 0.1952 - val_accuracy: 0.9457 - rmse: 0.4399\n",
      "Epoch 86/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9502\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1496 - accuracy: 0.9502 - val_loss: 0.1710 - val_accuracy: 0.9551 - rmse: 0.3896\n",
      "Epoch 87/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9502\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1474 - accuracy: 0.9501 - val_loss: 0.2000 - val_accuracy: 0.9432 - rmse: 0.4305\n",
      "Epoch 88/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9519\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1436 - accuracy: 0.9518 - val_loss: 0.1594 - val_accuracy: 0.9601 - rmse: 0.3717\n",
      "Epoch 89/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.9511\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1447 - accuracy: 0.9511 - val_loss: 0.1802 - val_accuracy: 0.9515 - rmse: 0.4274\n",
      "Epoch 90/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9511\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1449 - accuracy: 0.9511 - val_loss: 0.1786 - val_accuracy: 0.9520 - rmse: 0.4010\n",
      "Epoch 91/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9512\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1435 - accuracy: 0.9512 - val_loss: 0.1737 - val_accuracy: 0.9552 - rmse: 0.4238\n",
      "Epoch 92/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9531\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1402 - accuracy: 0.9531 - val_loss: 0.1581 - val_accuracy: 0.9609 - rmse: 0.3826\n",
      "Epoch 93/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9537\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1374 - accuracy: 0.9537 - val_loss: 0.1693 - val_accuracy: 0.9546 - rmse: 0.4031\n",
      "Epoch 94/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9525\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1399 - accuracy: 0.9524 - val_loss: 0.1590 - val_accuracy: 0.9594 - rmse: 0.3776\n",
      "Epoch 95/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9553\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1335 - accuracy: 0.9553 - val_loss: 0.1666 - val_accuracy: 0.9562 - rmse: 0.3982\n",
      "Epoch 96/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9542\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1336 - accuracy: 0.9542 - val_loss: 0.1680 - val_accuracy: 0.9552 - rmse: 0.4208\n",
      "Epoch 97/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9549\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1317 - accuracy: 0.9549 - val_loss: 0.1590 - val_accuracy: 0.9597 - rmse: 0.3972\n",
      "Epoch 98/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9549\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1339 - accuracy: 0.9549 - val_loss: 0.1933 - val_accuracy: 0.9447 - rmse: 0.4278\n",
      "Epoch 99/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1292 - accuracy: 0.9568\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1292 - accuracy: 0.9568 - val_loss: 0.1552 - val_accuracy: 0.9621 - rmse: 0.3892\n",
      "Epoch 100/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9550\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1310 - accuracy: 0.9550 - val_loss: 0.1537 - val_accuracy: 0.9617 - rmse: 0.3747\n",
      "Time taken to clear 100 epochs: 3880.9592113494873\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "mpri_model = MPRI_model()\n",
    "trg_results = mpri_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "284c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trg_results.history['loss']\n",
    "acc = trg_results.history['accuracy']\n",
    "val_loss = trg_results.history['val_loss']\n",
    "val_acc = trg_results.history['val_accuracy']\n",
    "rmse = trg_results.history['rmse']\n",
    "epochs = [i for i in range(len(rmse))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c63e887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "fig, axs = plt.subplots(1,3)\n",
    "\n",
    "axs[0].plot(epochs, loss, color='teal', label='trg_loss')\n",
    "axs[0].plot(epochs, val_loss, color='orange', label='val_loss')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[0].set_title('Loss', fontsize=20)\n",
    "\n",
    "axs[1].plot(epochs, acc, color='teal', label='acc')\n",
    "axs[1].plot(epochs, val_acc, color='orange', label='val_acc')\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].set_title('Accuracy', fontsize=20)\n",
    "\n",
    "axs[2].plot(epochs, rmse, color='teal', label='rmse')\n",
    "axs[2].legend(loc='upper left')\n",
    "axs[2].set_title('RMSE', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a891292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum loss: 0.15366923809051514\n",
      "Best Epoch no: 99\n",
      "Best val loss: 0.15366923809051514, Best val acc: 0.961675763130188\n",
      "Best trg loss: 0.1310051530599594, Best trg acc: 0.9550082087516785\n"
     ]
    }
   ],
   "source": [
    "val_loss = np.array(val_loss)\n",
    "print(f'Minimum loss: {val_loss.min()}')\n",
    "best_epoch = np.where(val_loss == val_loss.min())[0][0]\n",
    "\n",
    "print(f'Best Epoch no: {best_epoch}')\n",
    "print(f'Best val loss: {val_loss[best_epoch]}, Best val acc: {val_acc[best_epoch]}')\n",
    "print(f'Best trg loss: {loss[best_epoch]}, Best trg acc: {acc[best_epoch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1952721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest error: 8.139410298049853, Actual RP index: 1868, Predicted RP index: 1750\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "rmse, dist_errors, cdf_vals = mpri_model.test_model(\"mpri_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fc0c4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37467677319133735\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d56914f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "plt.plot(dist_errors, cdf_vals, marker='o')\n",
    "plt.xlabel('Distance Error(m)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Probability Function')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90bc1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5af64ead",
   "metadata": {},
   "source": [
    "## Repeat but with 400 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c13d8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole network composed of 63 layers, approximately 2.6m total no. of parameters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPool2D,\\\n",
    "                                    GlobalAvgPool2D, Dense, Add, Concatenate, Input,\\\n",
    "                                    Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Note: tf version 2.9.1 does not have Identity layer. Implement our own identity layer which is argument insensitive\n",
    "# and returns its inputs argument as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1740e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom callbacks to evaluate model\n",
    "class ValidationCallback2(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, X_val, Y_val, cur_val_loss, val_loss_threshold):\n",
    "        super(ValidationCallback2,self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.cur_val_loss = cur_val_loss\n",
    "        self.val_loss_threshold = val_loss_threshold\n",
    "        \n",
    "    # number_of_iterations = total_number_of_training_examples / batch_size\n",
    "    # In this case, train example of 1,000 and batch size of 100\n",
    "    # number_of_iterations over 1 epoch is 10\n",
    "    # if have 5 epochs, number of iterations is 50\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "        x_error = (actual[0] - predicted[0])**2\n",
    "        y_error = (actual[1] - predicted[1])**2\n",
    "        z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "        return x_error + y_error + z_error\n",
    "        \n",
    "    # Have one function that reports metrics on end of every epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \n",
    "        # Get evaluation metrics\n",
    "        print('\\n')\n",
    "        print('Epoch End - Custom Validation Callback')\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.X_val, self.Y_val, verbose = 0)\n",
    "        \n",
    "        # Get distance error metrics - RMSE\n",
    "        # Get predictions for each feature heatmap in X_val\n",
    "        Y_pred = self.model.predict(self.X_val, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(self.X_val)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[self.Y_val[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(Y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            err_sum += err\n",
    "        rmse = np.sqrt((err_sum/len(self.X_val)))\n",
    "       \n",
    "        # Save values to log\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['val_accuracy'] = val_accuracy\n",
    "        logs['rmse'] = rmse\n",
    "        \n",
    "        # Whenever validation loss is minimised and below threshold, save the model\n",
    "        # and update current minimum loss\n",
    "        if val_loss < self.cur_val_loss and val_loss < self.val_loss_threshold:\n",
    "            self.model.save('mpri_model2.h5')\n",
    "            self.cur_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515aef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but removed early stopping callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import time\n",
    "\n",
    "class MPRI_model2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        model_input = Input(shape = (193,16,1))\n",
    "        model_output = output_module(mpri_lowerhalf(mpri_upperhalf(input_module(model_input))), num_classes = 3876)\n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                      loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train_model(self):\n",
    "    \n",
    "        # In training, use model.fit() validation callback to get results on training loss, training accuracy,\n",
    "        # validation loss and validation accuracy and rmse after every epoch\n",
    "        val_callback = ValidationCallback2(X_test, y_test, math.inf, 1)\n",
    "        \n",
    "        # Can leave out early stopping for now, manually observe when val_loss stops improving to determine\n",
    "        # optimal number of epochs\n",
    "        \n",
    "        # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        start_time = time.time()\n",
    "        hist = self.model.fit(X_train, y_train,\n",
    "                              epochs = 400,\n",
    "                              batch_size = 64,\n",
    "                              callbacks = [val_callback]\n",
    "#                              callbacks = [val_callback, stop_early]\n",
    "                             )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'Time taken to clear 400 epochs: {end_time - start_time}')\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "            x_error = (actual[0] - predicted[0])**2\n",
    "            y_error = (actual[1] - predicted[1])**2\n",
    "            z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "            return x_error + y_error + z_error\n",
    "    \n",
    "    def calc_errorcdf(self, errors):\n",
    "        \n",
    "        # Sort the array\n",
    "        sorted_data = np.sort(errors)\n",
    "\n",
    "        # Calculate cumulative probabilities\n",
    "        n = len(sorted_data)\n",
    "        cumulative_probs = np.arange(1, n + 1) / n\n",
    "    \n",
    "        return (sorted_data, cumulative_probs)\n",
    "        \n",
    "    def test_model(self, filename):\n",
    "        \n",
    "        # Load model\n",
    "        self.model = keras.models.load_model(filename)\n",
    "        \n",
    "        # In test, use model.predict() to get the RMSE errors of predictions and CDF of distance error\n",
    "        y_pred = self.model.predict(X_test, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        dist_errors = []\n",
    "        max_disterror = -math.inf\n",
    "        max_disterror_actual, max_disterror_pred = None, None\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(X_test)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[y_test[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            \n",
    "            # Update the maximum errror, if needed\n",
    "            dist_err = np.sqrt(err)\n",
    "            if dist_err > max_disterror:\n",
    "                \n",
    "                # Update max error\n",
    "                max_disterror = dist_err\n",
    "                \n",
    "                # Return the class index and then retrieve actual coordinates from rp_dict\n",
    "                max_disterror_actual = y_test[i]\n",
    "                max_disterror_pred = predicted_rp\n",
    "            \n",
    "            # Append error to distance errors\n",
    "            dist_errors.append(dist_err)\n",
    "            err_sum += err\n",
    "            \n",
    "        # Get RMSE of all predicted points\n",
    "        rmse = np.sqrt((err_sum/len(X_test)))\n",
    "        \n",
    "        # Get actual and predicted point with the largest error\n",
    "        print(f'Largest error: {max_disterror}, Actual RP index: {max_disterror_actual}, Predicted RP index: {max_disterror_pred}')\n",
    "        \n",
    "        return (rmse, *self.calc_errorcdf(dist_errors))\n",
    "    \n",
    "    def eval_model(self, filename):\n",
    "        \n",
    "        self.model = keras.models.load_model(filename)\n",
    "        test_loss, test_acc = self.model.evaluate(X_test, y_test, batch_size = 64)\n",
    "        \n",
    "        return (test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef953a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 01:35:29.161091: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 01:35:29.968446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 33281 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:e1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 193, 16, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 193, 16, 256  2560        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 193, 16, 256  1024       ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 193, 16, 256  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 97, 8, 256)   0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 97, 8, 128)   32896       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 97, 8, 128)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 97, 8, 32)    4128        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 97, 8, 128)  512         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 97, 8, 32)   128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 97, 8, 32)    20512       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 97, 8, 32)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 97, 8, 64)    8256        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 97, 8, 32)    3104        ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 97, 8, 32)    36896       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 97, 8, 128)   4224        ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 97, 8, 256)   0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 97, 8, 256)   0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 49, 4, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 49, 4, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 49, 4, 256)  1024        ['max_pooling2d_2[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 49, 4, 256)  1024        ['max_pooling2d_3[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 49, 4, 256)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 49, 4, 256)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 49, 4, 256)   590080      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 49, 4, 256)   65792       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 49, 4, 256)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 49, 4, 256)   0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 25, 2, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 25, 2, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 2, 256)  1024        ['max_pooling2d_4[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 25, 2, 256)  1024        ['max_pooling2d_5[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 25, 2, 256)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 25, 2, 256)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 2, 256)   590080      ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 2, 256)   65792       ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 25, 2, 256)   0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 25, 2, 256)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv2d_11[0][0]',              \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 13, 1, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 13, 1, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_6[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_7[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 13, 1, 256)   590080      ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 13, 1, 256)   65792       ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 13, 1, 256)   0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'conv2d_12[0][0]',              \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 13, 1, 256)   0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 13, 1, 256)   0           ['add_5[0][0]',                  \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 13, 1, 128)   295040      ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 13, 1, 128)  512         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 13, 1, 128)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['re_lu_12[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3876)         500004      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,885,092\n",
      "Trainable params: 2,880,164\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mpri_model2 = MPRI_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc71c555",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 193, 16, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 193, 16, 256  2560        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 193, 16, 256  1024       ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 193, 16, 256  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 97, 8, 256)   0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 97, 8, 128)   32896       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 97, 8, 128)  0           ['conv2d_1[0][0]']               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 09:08:26.169767: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-27 09:08:26.607076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43428 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 97, 8, 32)    4128        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 97, 8, 128)  512         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 97, 8, 32)   128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 97, 8, 32)    20512       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 97, 8, 32)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 97, 8, 64)    8256        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 97, 8, 32)    3104        ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 97, 8, 32)    36896       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 97, 8, 128)   4224        ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 97, 8, 256)   0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 97, 8, 256)   0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 49, 4, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 49, 4, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 49, 4, 256)  1024        ['max_pooling2d_2[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 49, 4, 256)  1024        ['max_pooling2d_3[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 49, 4, 256)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 49, 4, 256)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 49, 4, 256)   590080      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 49, 4, 256)   65792       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 49, 4, 256)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 49, 4, 256)   0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 25, 2, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 25, 2, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 2, 256)  1024        ['max_pooling2d_4[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 25, 2, 256)  1024        ['max_pooling2d_5[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 25, 2, 256)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 25, 2, 256)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 2, 256)   590080      ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 2, 256)   65792       ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 25, 2, 256)   0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 25, 2, 256)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv2d_11[0][0]',              \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 13, 1, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 13, 1, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_6[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_7[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 13, 1, 256)   590080      ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 13, 1, 256)   65792       ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 13, 1, 256)   0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'conv2d_12[0][0]',              \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 13, 1, 256)   0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 13, 1, 256)   0           ['add_5[0][0]',                  \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 13, 1, 128)   295040      ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 13, 1, 128)  512         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 13, 1, 128)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['re_lu_12[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3876)         500004      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,885,092\n",
      "Trainable params: 2,880,164\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 09:08:29.773829: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-06-27 09:08:31.060813: I tensorflow/stream_executor/cuda/cuda_blas.cc:1804] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121/1121 [==============================] - ETA: 0s - loss: 7.7001 - accuracy: 0.0028\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 43s 36ms/step - loss: 7.7001 - accuracy: 0.0028 - val_loss: 7.0649 - val_accuracy: 0.0114 - rmse: 6.9501\n",
      "Epoch 2/400\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 6.5625 - accuracy: 0.0226\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 6.5625 - accuracy: 0.0226 - val_loss: 5.8288 - val_accuracy: 0.0594 - rmse: 5.2929\n",
      "Epoch 3/400\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 5.4324 - accuracy: 0.0767\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 5.4324 - accuracy: 0.0767 - val_loss: 4.7849 - val_accuracy: 0.1806 - rmse: 4.2784\n",
      "Epoch 4/400\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 4.4272 - accuracy: 0.1686\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 4.4272 - accuracy: 0.1686 - val_loss: 3.7207 - val_accuracy: 0.3334 - rmse: 3.3411\n",
      "Epoch 5/400\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 3.5770 - accuracy: 0.2835\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 3.5770 - accuracy: 0.2835 - val_loss: 2.9664 - val_accuracy: 0.5060 - rmse: 2.5984\n",
      "Epoch 6/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.9455 - accuracy: 0.3836\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.9454 - accuracy: 0.3836 - val_loss: 2.3328 - val_accuracy: 0.6108 - rmse: 2.1711\n",
      "Epoch 7/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.4693 - accuracy: 0.4672\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.4690 - accuracy: 0.4673 - val_loss: 1.9658 - val_accuracy: 0.7079 - rmse: 1.8094\n",
      "Epoch 8/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.1137 - accuracy: 0.5295\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.1135 - accuracy: 0.5295 - val_loss: 1.6457 - val_accuracy: 0.7224 - rmse: 1.5286\n",
      "Epoch 9/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.8505 - accuracy: 0.5768\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.8506 - accuracy: 0.5768 - val_loss: 1.4516 - val_accuracy: 0.7646 - rmse: 1.4241\n",
      "Epoch 10/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.6426 - accuracy: 0.6104\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.6423 - accuracy: 0.6104 - val_loss: 1.2791 - val_accuracy: 0.7973 - rmse: 1.4122\n",
      "Epoch 11/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.4712 - accuracy: 0.6422\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.4711 - accuracy: 0.6423 - val_loss: 1.1452 - val_accuracy: 0.8107 - rmse: 1.1301\n",
      "Epoch 12/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.3309 - accuracy: 0.6708\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.3311 - accuracy: 0.6709 - val_loss: 1.0327 - val_accuracy: 0.8221 - rmse: 1.0837\n",
      "Epoch 13/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.2090 - accuracy: 0.6951\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.2089 - accuracy: 0.6950 - val_loss: 0.9310 - val_accuracy: 0.8517 - rmse: 1.0496\n",
      "Epoch 14/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 1.1143 - accuracy: 0.7134\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.1144 - accuracy: 0.7133 - val_loss: 0.9229 - val_accuracy: 0.8139 - rmse: 1.0588\n",
      "Epoch 15/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 1.0249 - accuracy: 0.7328\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.0248 - accuracy: 0.7328 - val_loss: 0.8220 - val_accuracy: 0.8467 - rmse: 0.9013\n",
      "Epoch 16/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.9514 - accuracy: 0.7491\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.9515 - accuracy: 0.7490 - val_loss: 0.7215 - val_accuracy: 0.8734 - rmse: 0.7900\n",
      "Epoch 17/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8841 - accuracy: 0.7631\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8841 - accuracy: 0.7631 - val_loss: 0.6789 - val_accuracy: 0.8777 - rmse: 0.8088\n",
      "Epoch 18/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8287 - accuracy: 0.7742\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8286 - accuracy: 0.7741 - val_loss: 0.6187 - val_accuracy: 0.8886 - rmse: 0.7554\n",
      "Epoch 19/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7737 - accuracy: 0.7879\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7736 - accuracy: 0.7880 - val_loss: 0.5902 - val_accuracy: 0.8943 - rmse: 0.7117\n",
      "Epoch 20/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7305 - accuracy: 0.7974\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7304 - accuracy: 0.7974 - val_loss: 0.5684 - val_accuracy: 0.8875 - rmse: 0.7380\n",
      "Epoch 21/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6891 - accuracy: 0.8084\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6892 - accuracy: 0.8083 - val_loss: 0.5353 - val_accuracy: 0.8988 - rmse: 0.6809\n",
      "Epoch 22/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6560 - accuracy: 0.8148\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6560 - accuracy: 0.8148 - val_loss: 0.4982 - val_accuracy: 0.9020 - rmse: 0.6847\n",
      "Epoch 23/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6219 - accuracy: 0.8217\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6218 - accuracy: 0.8217 - val_loss: 0.4733 - val_accuracy: 0.9116 - rmse: 0.5858\n",
      "Epoch 24/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.5894 - accuracy: 0.8314\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5895 - accuracy: 0.8314 - val_loss: 0.4927 - val_accuracy: 0.8874 - rmse: 0.7441\n",
      "Epoch 25/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5597 - accuracy: 0.8388\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5598 - accuracy: 0.8387 - val_loss: 0.4284 - val_accuracy: 0.9100 - rmse: 0.6642\n",
      "Epoch 26/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.8441\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5377 - accuracy: 0.8441 - val_loss: 0.4497 - val_accuracy: 0.8969 - rmse: 0.6420\n",
      "Epoch 27/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5115 - accuracy: 0.8519\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5114 - accuracy: 0.8519 - val_loss: 0.3944 - val_accuracy: 0.9201 - rmse: 0.5763\n",
      "Epoch 28/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.8576\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4887 - accuracy: 0.8575 - val_loss: 0.3871 - val_accuracy: 0.9205 - rmse: 0.5747\n",
      "Epoch 29/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.8604\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4749 - accuracy: 0.8603 - val_loss: 0.3729 - val_accuracy: 0.9201 - rmse: 0.5710\n",
      "Epoch 30/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.8614\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4599 - accuracy: 0.8614 - val_loss: 0.3697 - val_accuracy: 0.9193 - rmse: 0.5825\n",
      "Epoch 31/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4369 - accuracy: 0.8705\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4369 - accuracy: 0.8705 - val_loss: 0.3391 - val_accuracy: 0.9277 - rmse: 0.5413\n",
      "Epoch 32/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4238 - accuracy: 0.8721\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4238 - accuracy: 0.8721 - val_loss: 0.3263 - val_accuracy: 0.9284 - rmse: 0.5179\n",
      "Epoch 33/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4092 - accuracy: 0.8763\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4091 - accuracy: 0.8763 - val_loss: 0.3175 - val_accuracy: 0.9309 - rmse: 0.5531\n",
      "Epoch 34/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8823\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3916 - accuracy: 0.8823 - val_loss: 0.3027 - val_accuracy: 0.9314 - rmse: 0.5101\n",
      "Epoch 35/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8855\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3794 - accuracy: 0.8855 - val_loss: 0.3119 - val_accuracy: 0.9238 - rmse: 0.5626\n",
      "Epoch 36/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8864\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3733 - accuracy: 0.8864 - val_loss: 0.2967 - val_accuracy: 0.9330 - rmse: 0.5163\n",
      "Epoch 37/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.8928\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3540 - accuracy: 0.8928 - val_loss: 0.2801 - val_accuracy: 0.9386 - rmse: 0.4870\n",
      "Epoch 38/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.8915\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3492 - accuracy: 0.8915 - val_loss: 0.2814 - val_accuracy: 0.9331 - rmse: 0.5202\n",
      "Epoch 39/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.8964\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3367 - accuracy: 0.8964 - val_loss: 0.2677 - val_accuracy: 0.9409 - rmse: 0.4626\n",
      "Epoch 40/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8981\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3282 - accuracy: 0.8981 - val_loss: 0.2599 - val_accuracy: 0.9411 - rmse: 0.4954\n",
      "Epoch 41/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.9020\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3180 - accuracy: 0.9020 - val_loss: 0.2648 - val_accuracy: 0.9358 - rmse: 0.5189\n",
      "Epoch 42/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3090 - accuracy: 0.9039\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3091 - accuracy: 0.9039 - val_loss: 0.2695 - val_accuracy: 0.9326 - rmse: 0.5405\n",
      "Epoch 43/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.9038\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3050 - accuracy: 0.9038 - val_loss: 0.2699 - val_accuracy: 0.9287 - rmse: 0.5510\n",
      "Epoch 44/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2945 - accuracy: 0.9082\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2946 - accuracy: 0.9081 - val_loss: 0.2302 - val_accuracy: 0.9466 - rmse: 0.4755\n",
      "Epoch 45/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.9120\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2843 - accuracy: 0.9121 - val_loss: 0.2447 - val_accuracy: 0.9395 - rmse: 0.4775\n",
      "Epoch 46/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.9094\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2828 - accuracy: 0.9095 - val_loss: 0.2378 - val_accuracy: 0.9418 - rmse: 0.5024\n",
      "Epoch 47/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.9138\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2729 - accuracy: 0.9138 - val_loss: 0.2376 - val_accuracy: 0.9404 - rmse: 0.4892\n",
      "Epoch 48/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.9158\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2667 - accuracy: 0.9158 - val_loss: 0.2169 - val_accuracy: 0.9498 - rmse: 0.4309\n",
      "Epoch 49/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9172\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2608 - accuracy: 0.9172 - val_loss: 0.2328 - val_accuracy: 0.9415 - rmse: 0.4914\n",
      "Epoch 50/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2578 - accuracy: 0.9167\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2578 - accuracy: 0.9167 - val_loss: 0.2208 - val_accuracy: 0.9437 - rmse: 0.4616\n",
      "Epoch 51/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2522 - accuracy: 0.9195\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2522 - accuracy: 0.9195 - val_loss: 0.2100 - val_accuracy: 0.9501 - rmse: 0.4265\n",
      "Epoch 52/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.9210\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2471 - accuracy: 0.9210 - val_loss: 0.2157 - val_accuracy: 0.9445 - rmse: 0.4448\n",
      "Epoch 53/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2387 - accuracy: 0.9239\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2387 - accuracy: 0.9239 - val_loss: 0.2187 - val_accuracy: 0.9432 - rmse: 0.4691\n",
      "Epoch 54/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9242\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2367 - accuracy: 0.9242 - val_loss: 0.2216 - val_accuracy: 0.9398 - rmse: 0.5048\n",
      "Epoch 55/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9267\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2297 - accuracy: 0.9266 - val_loss: 0.2087 - val_accuracy: 0.9457 - rmse: 0.4549\n",
      "Epoch 56/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2252 - accuracy: 0.9274\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2252 - accuracy: 0.9274 - val_loss: 0.2112 - val_accuracy: 0.9483 - rmse: 0.4433\n",
      "Epoch 57/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2218 - accuracy: 0.9293\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2219 - accuracy: 0.9292 - val_loss: 0.1983 - val_accuracy: 0.9502 - rmse: 0.4342\n",
      "Epoch 58/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9301\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2180 - accuracy: 0.9301 - val_loss: 0.1996 - val_accuracy: 0.9502 - rmse: 0.4378\n",
      "Epoch 59/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9291\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2159 - accuracy: 0.9292 - val_loss: 0.2062 - val_accuracy: 0.9456 - rmse: 0.4826\n",
      "Epoch 60/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.9312\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2102 - accuracy: 0.9312 - val_loss: 0.2366 - val_accuracy: 0.9324 - rmse: 0.5050\n",
      "Epoch 61/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.9332\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2081 - accuracy: 0.9331 - val_loss: 0.2202 - val_accuracy: 0.9380 - rmse: 0.4932\n",
      "Epoch 62/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.9328\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2046 - accuracy: 0.9327 - val_loss: 0.1948 - val_accuracy: 0.9507 - rmse: 0.4444\n",
      "Epoch 63/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1988 - accuracy: 0.9362\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1989 - accuracy: 0.9362 - val_loss: 0.1895 - val_accuracy: 0.9507 - rmse: 0.4349\n",
      "Epoch 64/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.9332\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2040 - accuracy: 0.9332 - val_loss: 0.1976 - val_accuracy: 0.9479 - rmse: 0.4449\n",
      "Epoch 65/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.1978 - accuracy: 0.9347\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1977 - accuracy: 0.9347 - val_loss: 0.1956 - val_accuracy: 0.9477 - rmse: 0.4709\n",
      "Epoch 66/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9383\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1900 - accuracy: 0.9382 - val_loss: 0.1964 - val_accuracy: 0.9471 - rmse: 0.4926\n",
      "Epoch 67/400\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1865 - accuracy: 0.9386 - val_loss: 0.1835 - val_accuracy: 0.9522 - rmse: 0.4177\n",
      "Epoch 70/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9399\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1814 - accuracy: 0.9398 - val_loss: 0.1813 - val_accuracy: 0.9554 - rmse: 0.4233\n",
      "Epoch 71/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9406\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1791 - accuracy: 0.9406 - val_loss: 0.1658 - val_accuracy: 0.9599 - rmse: 0.3940\n",
      "Epoch 72/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1744 - accuracy: 0.9419\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1745 - accuracy: 0.9419 - val_loss: 0.1656 - val_accuracy: 0.9615 - rmse: 0.3695\n",
      "Epoch 73/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9416\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1726 - accuracy: 0.9416 - val_loss: 0.1861 - val_accuracy: 0.9519 - rmse: 0.4399\n",
      "Epoch 74/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9433\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1702 - accuracy: 0.9433 - val_loss: 0.1786 - val_accuracy: 0.9541 - rmse: 0.4304\n",
      "Epoch 75/400\n",
      " 361/1121 [========>.....................] - ETA: 22s - loss: 0.1665 - accuracy: 0.9442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9552\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1328 - accuracy: 0.9552 - val_loss: 0.1550 - val_accuracy: 0.9606 - rmse: 0.4114\n",
      "Epoch 98/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9564\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1294 - accuracy: 0.9564 - val_loss: 0.1575 - val_accuracy: 0.9582 - rmse: 0.3892\n",
      "Epoch 99/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9566\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1290 - accuracy: 0.9566 - val_loss: 0.1670 - val_accuracy: 0.9563 - rmse: 0.4335\n",
      "Epoch 100/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9562\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1283 - accuracy: 0.9562 - val_loss: 0.1609 - val_accuracy: 0.9573 - rmse: 0.4167\n",
      "Epoch 101/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9565\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1277 - accuracy: 0.9565 - val_loss: 0.1577 - val_accuracy: 0.9603 - rmse: 0.4007\n",
      "Epoch 102/400\n",
      " 793/1121 [====================>.........] - ETA: 9s - loss: 0.1263 - accuracy: 0.9568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9642\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1038 - accuracy: 0.9641 - val_loss: 0.1467 - val_accuracy: 0.9609 - rmse: 0.3729\n",
      "Epoch 126/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9638\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1039 - accuracy: 0.9638 - val_loss: 0.1406 - val_accuracy: 0.9661 - rmse: 0.3675\n",
      "Epoch 127/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.9646\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1036 - accuracy: 0.9646 - val_loss: 0.1574 - val_accuracy: 0.9588 - rmse: 0.4020\n",
      "Epoch 128/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.9655\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1010 - accuracy: 0.9655 - val_loss: 0.1387 - val_accuracy: 0.9666 - rmse: 0.3604\n",
      "Epoch 129/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1034 - accuracy: 0.9642\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1034 - accuracy: 0.9642 - val_loss: 0.1378 - val_accuracy: 0.9665 - rmse: 0.3627\n",
      "Epoch 130/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9651\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1003 - accuracy: 0.9651 - val_loss: 0.1440 - val_accuracy: 0.9666 - rmse: 0.3454\n",
      "Epoch 131/400\n",
      " 155/1121 [===>..........................] - ETA: 28s - loss: 0.0956 - accuracy: 0.9659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 0.9648\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1017 - accuracy: 0.9648 - val_loss: 0.1584 - val_accuracy: 0.9584 - rmse: 0.4012\n",
      "Epoch 133/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9656\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 0.1411 - val_accuracy: 0.9643 - rmse: 0.4108\n",
      "Epoch 134/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.9663\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0976 - accuracy: 0.9663 - val_loss: 0.1511 - val_accuracy: 0.9611 - rmse: 0.3997\n",
      "Epoch 135/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.9660\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0971 - accuracy: 0.9660 - val_loss: 0.1465 - val_accuracy: 0.9636 - rmse: 0.3793\n",
      "Epoch 136/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9658\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0985 - accuracy: 0.9658 - val_loss: 0.1390 - val_accuracy: 0.9644 - rmse: 0.3789\n",
      "Epoch 137/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9681\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0932 - accuracy: 0.9681 - val_loss: 0.1635 - val_accuracy: 0.9569 - rmse: 0.4363\n",
      "Epoch 138/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9673\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0939 - accuracy: 0.9673 - val_loss: 0.1434 - val_accuracy: 0.9640 - rmse: 0.3775\n",
      "Epoch 139/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9664\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0963 - accuracy: 0.9665 - val_loss: 0.1379 - val_accuracy: 0.9671 - rmse: 0.3631\n",
      "Epoch 140/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9681\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0924 - accuracy: 0.9681 - val_loss: 0.1415 - val_accuracy: 0.9651 - rmse: 0.3789\n",
      "Epoch 141/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9679\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0921 - accuracy: 0.9679 - val_loss: 0.1341 - val_accuracy: 0.9670 - rmse: 0.3699\n",
      "Epoch 142/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 0.9684\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0908 - accuracy: 0.9684 - val_loss: 0.1524 - val_accuracy: 0.9616 - rmse: 0.3884\n",
      "Epoch 143/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.9682\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0908 - accuracy: 0.9682 - val_loss: 0.1429 - val_accuracy: 0.9647 - rmse: 0.3852\n",
      "Epoch 144/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9685\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0907 - accuracy: 0.9685 - val_loss: 0.1403 - val_accuracy: 0.9635 - rmse: 0.3719\n",
      "Epoch 145/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9676\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0914 - accuracy: 0.9676 - val_loss: 0.1392 - val_accuracy: 0.9645 - rmse: 0.3492\n",
      "Epoch 146/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9663\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0944 - accuracy: 0.9663 - val_loss: 0.1337 - val_accuracy: 0.9661 - rmse: 0.3544\n",
      "Epoch 147/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9680\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.1381 - val_accuracy: 0.9656 - rmse: 0.3544\n",
      "Epoch 148/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9691\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0888 - accuracy: 0.9691 - val_loss: 0.1370 - val_accuracy: 0.9668 - rmse: 0.3668\n",
      "Epoch 149/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 0.9679\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0902 - accuracy: 0.9679 - val_loss: 0.1334 - val_accuracy: 0.9679 - rmse: 0.3476\n",
      "Epoch 150/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 0.9690\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0884 - accuracy: 0.9689 - val_loss: 0.1394 - val_accuracy: 0.9644 - rmse: 0.3840\n",
      "Epoch 151/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 0.9685\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0889 - accuracy: 0.9684 - val_loss: 0.1525 - val_accuracy: 0.9603 - rmse: 0.4027\n",
      "Epoch 152/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 0.9695\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0874 - accuracy: 0.9695 - val_loss: 0.1366 - val_accuracy: 0.9656 - rmse: 0.3747\n",
      "Epoch 153/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 0.9704\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0853 - accuracy: 0.9704 - val_loss: 0.1343 - val_accuracy: 0.9665 - rmse: 0.3701\n",
      "Epoch 154/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9702\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0851 - accuracy: 0.9703 - val_loss: 0.1333 - val_accuracy: 0.9670 - rmse: 0.3582\n",
      "Epoch 155/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9695\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0879 - accuracy: 0.9694 - val_loss: 0.1385 - val_accuracy: 0.9657 - rmse: 0.3643\n",
      "Epoch 156/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9697\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0858 - accuracy: 0.9697 - val_loss: 0.1427 - val_accuracy: 0.9623 - rmse: 0.3970\n",
      "Epoch 157/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0840 - accuracy: 0.9710\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0839 - accuracy: 0.9710 - val_loss: 0.1406 - val_accuracy: 0.9653 - rmse: 0.3562\n",
      "Epoch 158/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0860 - accuracy: 0.9697\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0862 - accuracy: 0.9696 - val_loss: 0.1378 - val_accuracy: 0.9659 - rmse: 0.3916\n",
      "Epoch 159/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0869 - accuracy: 0.9692\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0869 - accuracy: 0.9692 - val_loss: 0.1463 - val_accuracy: 0.9618 - rmse: 0.3862\n",
      "Epoch 160/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 0.9696\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0863 - accuracy: 0.9696 - val_loss: 0.1465 - val_accuracy: 0.9621 - rmse: 0.4136\n",
      "Epoch 161/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 0.9719\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0817 - accuracy: 0.9719 - val_loss: 0.1445 - val_accuracy: 0.9632 - rmse: 0.3882\n",
      "Epoch 162/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 0.9718\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 0.1222 - val_accuracy: 0.9719 - rmse: 0.3335\n",
      "Epoch 163/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 0.9711\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0820 - accuracy: 0.9710 - val_loss: 0.1494 - val_accuracy: 0.9606 - rmse: 0.3996\n",
      "Epoch 164/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9704\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0830 - accuracy: 0.9704 - val_loss: 0.1310 - val_accuracy: 0.9675 - rmse: 0.3521\n",
      "Epoch 165/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9716\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0802 - accuracy: 0.9716 - val_loss: 0.1292 - val_accuracy: 0.9683 - rmse: 0.3594\n",
      "Epoch 166/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0821 - accuracy: 0.9711\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0822 - accuracy: 0.9711 - val_loss: 0.1322 - val_accuracy: 0.9663 - rmse: 0.3796\n",
      "Epoch 167/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9711\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0821 - accuracy: 0.9712 - val_loss: 0.1419 - val_accuracy: 0.9646 - rmse: 0.3602\n",
      "Epoch 168/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9732\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0779 - accuracy: 0.9731 - val_loss: 0.1323 - val_accuracy: 0.9681 - rmse: 0.3808\n",
      "Epoch 169/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9720\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0789 - accuracy: 0.9720 - val_loss: 0.1314 - val_accuracy: 0.9675 - rmse: 0.3532\n",
      "Epoch 170/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9724\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 0.1289 - val_accuracy: 0.9689 - rmse: 0.3398\n",
      "Epoch 171/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9713\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0808 - accuracy: 0.9713 - val_loss: 0.1320 - val_accuracy: 0.9676 - rmse: 0.3555\n",
      "Epoch 172/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9724\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0788 - accuracy: 0.9724 - val_loss: 0.1385 - val_accuracy: 0.9655 - rmse: 0.3422\n",
      "Epoch 173/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0786 - accuracy: 0.9723\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0786 - accuracy: 0.9723 - val_loss: 0.1251 - val_accuracy: 0.9707 - rmse: 0.3305\n",
      "Epoch 174/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9728\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0777 - accuracy: 0.9728 - val_loss: 0.1398 - val_accuracy: 0.9645 - rmse: 0.3715\n",
      "Epoch 175/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9733\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0762 - accuracy: 0.9733 - val_loss: 0.1467 - val_accuracy: 0.9625 - rmse: 0.3767\n",
      "Epoch 176/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9727\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0767 - accuracy: 0.9727 - val_loss: 0.1317 - val_accuracy: 0.9680 - rmse: 0.3459\n",
      "Epoch 177/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9728\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0757 - accuracy: 0.9728 - val_loss: 0.1254 - val_accuracy: 0.9712 - rmse: 0.3206\n",
      "Epoch 178/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9733\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0765 - accuracy: 0.9733 - val_loss: 0.1401 - val_accuracy: 0.9642 - rmse: 0.3731\n",
      "Epoch 179/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9732\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0761 - accuracy: 0.9732 - val_loss: 0.1298 - val_accuracy: 0.9688 - rmse: 0.3533\n",
      "Epoch 180/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9725\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0763 - accuracy: 0.9724 - val_loss: 0.1298 - val_accuracy: 0.9687 - rmse: 0.3483\n",
      "Epoch 181/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9742\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0732 - accuracy: 0.9742 - val_loss: 0.1297 - val_accuracy: 0.9681 - rmse: 0.3598\n",
      "Epoch 182/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9738\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0748 - accuracy: 0.9738 - val_loss: 0.1381 - val_accuracy: 0.9655 - rmse: 0.3647\n",
      "Epoch 183/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 0.9741\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0727 - accuracy: 0.9741 - val_loss: 0.1326 - val_accuracy: 0.9672 - rmse: 0.3463\n",
      "Epoch 184/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9741\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0729 - accuracy: 0.9741 - val_loss: 0.1396 - val_accuracy: 0.9635 - rmse: 0.4012\n",
      "Epoch 185/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9733\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0750 - accuracy: 0.9733 - val_loss: 0.1300 - val_accuracy: 0.9685 - rmse: 0.3548\n",
      "Epoch 186/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9739\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0731 - accuracy: 0.9739 - val_loss: 0.1415 - val_accuracy: 0.9651 - rmse: 0.3687\n",
      "Epoch 187/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9749\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0708 - accuracy: 0.9750 - val_loss: 0.1403 - val_accuracy: 0.9645 - rmse: 0.3974\n",
      "Epoch 188/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9736\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0740 - accuracy: 0.9736 - val_loss: 0.1349 - val_accuracy: 0.9680 - rmse: 0.3696\n",
      "Epoch 189/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9746\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0723 - accuracy: 0.9746 - val_loss: 0.1369 - val_accuracy: 0.9679 - rmse: 0.3683\n",
      "Epoch 190/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9744\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0723 - accuracy: 0.9744 - val_loss: 0.1342 - val_accuracy: 0.9673 - rmse: 0.3898\n",
      "Epoch 191/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9753\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0693 - accuracy: 0.9753 - val_loss: 0.1456 - val_accuracy: 0.9641 - rmse: 0.4316\n",
      "Epoch 192/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9744\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0717 - accuracy: 0.9744 - val_loss: 0.1444 - val_accuracy: 0.9632 - rmse: 0.3792\n",
      "Epoch 193/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9750\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0715 - accuracy: 0.9750 - val_loss: 0.1358 - val_accuracy: 0.9658 - rmse: 0.3716\n",
      "Epoch 194/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9758\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0684 - accuracy: 0.9759 - val_loss: 0.1353 - val_accuracy: 0.9668 - rmse: 0.3390\n",
      "Epoch 195/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9744\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0716 - accuracy: 0.9744 - val_loss: 0.1346 - val_accuracy: 0.9675 - rmse: 0.3752\n",
      "Epoch 196/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.9756\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.1319 - val_accuracy: 0.9650 - rmse: 0.3665\n",
      "Epoch 197/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9747\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0704 - accuracy: 0.9748 - val_loss: 0.1310 - val_accuracy: 0.9694 - rmse: 0.3446\n",
      "Epoch 198/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9749\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0711 - accuracy: 0.9749 - val_loss: 0.1440 - val_accuracy: 0.9640 - rmse: 0.4016\n",
      "Epoch 199/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9754\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0702 - accuracy: 0.9755 - val_loss: 0.1377 - val_accuracy: 0.9649 - rmse: 0.3646\n",
      "Epoch 200/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9756\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0687 - accuracy: 0.9756 - val_loss: 0.1267 - val_accuracy: 0.9695 - rmse: 0.3626\n",
      "Epoch 201/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9758\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0698 - accuracy: 0.9758 - val_loss: 0.1262 - val_accuracy: 0.9679 - rmse: 0.3665\n",
      "Epoch 202/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9756\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0678 - accuracy: 0.9756 - val_loss: 0.1349 - val_accuracy: 0.9667 - rmse: 0.3361\n",
      "Epoch 203/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9742\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0717 - accuracy: 0.9742 - val_loss: 0.1205 - val_accuracy: 0.9710 - rmse: 0.3329\n",
      "Epoch 204/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9764\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0679 - accuracy: 0.9764 - val_loss: 0.1345 - val_accuracy: 0.9683 - rmse: 0.3596\n",
      "Epoch 205/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9774\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0648 - accuracy: 0.9774 - val_loss: 0.1355 - val_accuracy: 0.9654 - rmse: 0.3669\n",
      "Epoch 206/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 0.9766\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0670 - accuracy: 0.9766 - val_loss: 0.1297 - val_accuracy: 0.9681 - rmse: 0.3549\n",
      "Epoch 207/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9765\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0670 - accuracy: 0.9765 - val_loss: 0.1420 - val_accuracy: 0.9655 - rmse: 0.3731\n",
      "Epoch 208/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 0.9762\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0672 - accuracy: 0.9763 - val_loss: 0.1238 - val_accuracy: 0.9703 - rmse: 0.3351\n",
      "Epoch 209/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9767\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0650 - accuracy: 0.9767 - val_loss: 0.1457 - val_accuracy: 0.9643 - rmse: 0.3558\n",
      "Epoch 210/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9756\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0680 - accuracy: 0.9756 - val_loss: 0.1331 - val_accuracy: 0.9664 - rmse: 0.3689\n",
      "Epoch 211/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9776\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0651 - accuracy: 0.9776 - val_loss: 0.1276 - val_accuracy: 0.9683 - rmse: 0.3373\n",
      "Epoch 212/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9768\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0655 - accuracy: 0.9768 - val_loss: 0.1261 - val_accuracy: 0.9690 - rmse: 0.3473\n",
      "Epoch 213/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9777\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0637 - accuracy: 0.9777 - val_loss: 0.1354 - val_accuracy: 0.9685 - rmse: 0.3345\n",
      "Epoch 214/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9766\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0653 - accuracy: 0.9766 - val_loss: 0.1286 - val_accuracy: 0.9681 - rmse: 0.3756\n",
      "Epoch 215/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9772\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.1314 - val_accuracy: 0.9690 - rmse: 0.3549\n",
      "Epoch 216/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9783\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0627 - accuracy: 0.9783 - val_loss: 0.1373 - val_accuracy: 0.9650 - rmse: 0.3490\n",
      "Epoch 217/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9768\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 40s 36ms/step - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.1262 - val_accuracy: 0.9694 - rmse: 0.3475\n",
      "Epoch 218/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9761\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0661 - accuracy: 0.9761 - val_loss: 0.1309 - val_accuracy: 0.9685 - rmse: 0.3529\n",
      "Epoch 219/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.9785\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0618 - accuracy: 0.9785 - val_loss: 0.1231 - val_accuracy: 0.9706 - rmse: 0.3351\n",
      "Epoch 220/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9771\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0645 - accuracy: 0.9771 - val_loss: 0.1437 - val_accuracy: 0.9649 - rmse: 0.3757\n",
      "Epoch 221/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9773\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0647 - accuracy: 0.9773 - val_loss: 0.1336 - val_accuracy: 0.9659 - rmse: 0.3825\n",
      "Epoch 222/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9779\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0625 - accuracy: 0.9779 - val_loss: 0.1243 - val_accuracy: 0.9695 - rmse: 0.3228\n",
      "Epoch 223/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9786\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0618 - accuracy: 0.9786 - val_loss: 0.1373 - val_accuracy: 0.9663 - rmse: 0.3814\n",
      "Epoch 224/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9787\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0625 - accuracy: 0.9787 - val_loss: 0.1361 - val_accuracy: 0.9671 - rmse: 0.3514\n",
      "Epoch 225/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9778\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0632 - accuracy: 0.9778 - val_loss: 0.1253 - val_accuracy: 0.9698 - rmse: 0.3448\n",
      "Epoch 226/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9780\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.1261 - val_accuracy: 0.9722 - rmse: 0.3311\n",
      "Epoch 227/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9785\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0609 - accuracy: 0.9785 - val_loss: 0.1278 - val_accuracy: 0.9688 - rmse: 0.3440\n",
      "Epoch 228/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9782\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0607 - accuracy: 0.9781 - val_loss: 0.1477 - val_accuracy: 0.9635 - rmse: 0.4199\n",
      "Epoch 229/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9777\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0631 - accuracy: 0.9777 - val_loss: 0.1257 - val_accuracy: 0.9709 - rmse: 0.3407\n",
      "Epoch 230/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9786\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0600 - accuracy: 0.9786 - val_loss: 0.1416 - val_accuracy: 0.9664 - rmse: 0.3916\n",
      "Epoch 231/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9783\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.1345 - val_accuracy: 0.9655 - rmse: 0.3719\n",
      "Epoch 232/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9791\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0588 - accuracy: 0.9791 - val_loss: 0.1324 - val_accuracy: 0.9675 - rmse: 0.3453\n",
      "Epoch 233/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9784\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0613 - accuracy: 0.9784 - val_loss: 0.1247 - val_accuracy: 0.9717 - rmse: 0.3381\n",
      "Epoch 234/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9789\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0592 - accuracy: 0.9789 - val_loss: 0.1291 - val_accuracy: 0.9685 - rmse: 0.3414\n",
      "Epoch 235/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9793\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0594 - accuracy: 0.9792 - val_loss: 0.1386 - val_accuracy: 0.9668 - rmse: 0.3572\n",
      "Epoch 236/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9783\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0609 - accuracy: 0.9782 - val_loss: 0.1411 - val_accuracy: 0.9628 - rmse: 0.3878\n",
      "Epoch 237/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9780\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0609 - accuracy: 0.9780 - val_loss: 0.1284 - val_accuracy: 0.9696 - rmse: 0.3145\n",
      "Epoch 238/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9794\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.1296 - val_accuracy: 0.9690 - rmse: 0.3462\n",
      "Epoch 239/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9803\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0570 - accuracy: 0.9802 - val_loss: 0.1268 - val_accuracy: 0.9700 - rmse: 0.3330\n",
      "Epoch 243/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9792\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 0.1302 - val_accuracy: 0.9681 - rmse: 0.3516\n",
      "Epoch 244/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9793\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0570 - accuracy: 0.9793 - val_loss: 0.1286 - val_accuracy: 0.9709 - rmse: 0.3278\n",
      "Epoch 245/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9786\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0602 - accuracy: 0.9785 - val_loss: 0.1339 - val_accuracy: 0.9680 - rmse: 0.3529\n",
      "Epoch 246/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9797\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0568 - accuracy: 0.9797 - val_loss: 0.1243 - val_accuracy: 0.9711 - rmse: 0.3432\n",
      "Epoch 247/400\n",
      " 773/1121 [===================>..........] - ETA: 10s - loss: 0.0574 - accuracy: 0.9796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9812\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0528 - accuracy: 0.9812 - val_loss: 0.1208 - val_accuracy: 0.9717 - rmse: 0.3357\n",
      "Epoch 271/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9814\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0523 - accuracy: 0.9814 - val_loss: 0.1354 - val_accuracy: 0.9680 - rmse: 0.3746\n",
      "Epoch 272/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9796\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0559 - accuracy: 0.9796 - val_loss: 0.1401 - val_accuracy: 0.9667 - rmse: 0.3647\n",
      "Epoch 273/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9807\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 0.1281 - val_accuracy: 0.9697 - rmse: 0.3364\n",
      "Epoch 274/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9818\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0507 - accuracy: 0.9818 - val_loss: 0.1242 - val_accuracy: 0.9704 - rmse: 0.3315\n",
      "Epoch 275/400\n",
      "1099/1121 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9825\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.1238 - val_accuracy: 0.9710 - rmse: 0.3414\n",
      "Epoch 298/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9827\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0499 - accuracy: 0.9827 - val_loss: 0.1299 - val_accuracy: 0.9674 - rmse: 0.3533\n",
      "Epoch 299/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9833\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0477 - accuracy: 0.9833 - val_loss: 0.1266 - val_accuracy: 0.9700 - rmse: 0.3410\n",
      "Epoch 300/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9828\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0495 - accuracy: 0.9828 - val_loss: 0.1216 - val_accuracy: 0.9718 - rmse: 0.3262\n",
      "Epoch 301/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9831\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 0.1422 - val_accuracy: 0.9644 - rmse: 0.3876\n",
      "Epoch 302/400\n",
      " 859/1121 [=====================>........] - ETA: 7s - loss: 0.0470 - accuracy: 0.9835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9839\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0461 - accuracy: 0.9839 - val_loss: 0.1214 - val_accuracy: 0.9727 - rmse: 0.3401\n",
      "Epoch 326/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.9835\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0468 - accuracy: 0.9834 - val_loss: 0.1211 - val_accuracy: 0.9731 - rmse: 0.3359\n",
      "Epoch 327/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9837\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.1280 - val_accuracy: 0.9717 - rmse: 0.3432\n",
      "Epoch 328/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9850\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0458 - accuracy: 0.9850 - val_loss: 0.1169 - val_accuracy: 0.9748 - rmse: 0.3119\n",
      "Epoch 329/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9832\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0464 - accuracy: 0.9832 - val_loss: 0.1260 - val_accuracy: 0.9712 - rmse: 0.3247\n",
      "Epoch 330/400\n",
      " 949/1121 [========================>.....] - ETA: 5s - loss: 0.0461 - accuracy: 0.9833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9850\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0414 - accuracy: 0.9850 - val_loss: 0.1276 - val_accuracy: 0.9714 - rmse: 0.3630\n",
      "Epoch 354/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9842\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0440 - accuracy: 0.9842 - val_loss: 0.1322 - val_accuracy: 0.9706 - rmse: 0.3306\n",
      "Epoch 355/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9850\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0426 - accuracy: 0.9850 - val_loss: 0.1268 - val_accuracy: 0.9727 - rmse: 0.3607\n",
      "Epoch 356/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9853\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0402 - accuracy: 0.9854 - val_loss: 0.1241 - val_accuracy: 0.9711 - rmse: 0.3571\n",
      "Epoch 357/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9848\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0434 - accuracy: 0.9848 - val_loss: 0.1304 - val_accuracy: 0.9693 - rmse: 0.3564\n",
      "Epoch 358/400\n",
      "1077/1121 [===========================>..] - ETA: 1s - loss: 0.0396 - accuracy: 0.9859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9854\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0412 - accuracy: 0.9853 - val_loss: 0.1254 - val_accuracy: 0.9714 - rmse: 0.3515\n",
      "Epoch 380/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9862\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.1241 - val_accuracy: 0.9725 - rmse: 0.3306\n",
      "Epoch 381/400\n",
      " 341/1121 [========>.....................] - ETA: 22s - loss: 0.0403 - accuracy: 0.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9851\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0404 - accuracy: 0.9851 - val_loss: 0.1284 - val_accuracy: 0.9717 - rmse: 0.3457\n",
      "Epoch 383/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9859\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0390 - accuracy: 0.9859 - val_loss: 0.1270 - val_accuracy: 0.9724 - rmse: 0.3353\n",
      "Epoch 384/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9857\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0390 - accuracy: 0.9857 - val_loss: 0.1374 - val_accuracy: 0.9697 - rmse: 0.3747\n",
      "Epoch 385/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9856\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0401 - accuracy: 0.9856 - val_loss: 0.1250 - val_accuracy: 0.9731 - rmse: 0.3415\n",
      "Epoch 386/400\n",
      " 553/1121 [=============>................] - ETA: 16s - loss: 0.0381 - accuracy: 0.9859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trg_results2 = mpri_model2.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218d37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = trg_results2.history['loss']\n",
    "acc2 = trg_results2.history['accuracy']\n",
    "val_loss2 = trg_results2.history['val_loss']\n",
    "val_acc2 = trg_results2.history['val_accuracy']\n",
    "rmse2 = trg_results2.history['rmse']\n",
    "epochs2 = [i for i in range(len(rmse2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "117e1e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "fig, axs = plt.subplots(1,3)\n",
    "\n",
    "axs[0].plot(epochs2, loss2, color='teal', label='trg_loss')\n",
    "axs[0].plot(epochs2, val_loss2, color='orange', label='val_loss')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[0].set_title('Loss', fontsize=20)\n",
    "\n",
    "axs[1].plot(epochs2, acc2, color='teal', label='acc')\n",
    "axs[1].plot(epochs2, val_acc2, color='orange', label='val_acc')\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].set_title('Accuracy', fontsize=20)\n",
    "\n",
    "axs[2].plot(epochs2, rmse2, color='teal', label='rmse')\n",
    "axs[2].legend(loc='upper left')\n",
    "axs[2].set_title('RMSE', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8216dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum loss: 0.11320377886295319\n",
      "Best Epoch no: 340\n",
      "Best val loss: 0.11320377886295319, Best val acc: 0.9747294187545776\n",
      "Best trg loss: 0.044030942022800446, Best trg acc: 0.9843518733978271\n"
     ]
    }
   ],
   "source": [
    "val_loss2= np.array(val_loss2)\n",
    "print(f'Minimum loss: {val_loss2.min()}')\n",
    "best_epoch2= np.where(val_loss2== val_loss2.min())[0][0]\n",
    "\n",
    "print(f'Best Epoch no: {best_epoch2}')\n",
    "print(f'Best val loss: {val_loss2[best_epoch2]}, Best val acc: {val_acc2[best_epoch2]}')\n",
    "print(f'Best trg loss: {loss2[best_epoch2]}, Best trg acc: {acc2[best_epoch2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "017c8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 01:35:40.959285: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-06-30 01:35:42.529122: I tensorflow/stream_executor/cuda/cuda_blas.cc:1804] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest error: 7.664854858377946, Actual RP index: 2695, Predicted RP index: 874\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "rmse2, dist_errors2, cdf_vals2 = mpri_model2.test_model(\"mpri_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a15330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31500377652610084\n"
     ]
    }
   ],
   "source": [
    "print(rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda413c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "plt.plot(dist_errors2, cdf_vals2, marker='o')\n",
    "plt.xlabel('Distance Error(m)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Probability Function')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9ebf0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         ... 6.67083203 7.07106781 7.66485486]\n",
      "[5.57848935e-05 1.11569787e-04 1.67354680e-04 ... 9.99888430e-01\n",
      " 9.99944215e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Save sorted values and cdf_values into a file\n",
    "print(dist_errors2)\n",
    "print(cdf_vals2)\n",
    "\n",
    "mpri_dist_errors = np.array(dist_errors2)\n",
    "mpri_cdf_vals = np.array(cdf_vals2)\n",
    "\n",
    "np.save('mpri_sorted_errors.npy', mpri_dist_errors)\n",
    "np.save('mpri_cdf_vals', mpri_cdf_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba27a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 5s 18ms/step - loss: 0.1132 - accuracy: 0.9746\n",
      " Test loss: 0.11320668458938599, Test Accuracy: 0.9746178984642029\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy\n",
    "test_loss, test_acc = mpri_model2.eval_model(\"mpri_model_final.h5\")\n",
    "print(f' Test loss: {test_loss}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db79da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9feb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2513c173",
   "metadata": {},
   "source": [
    "## Try out on barrel rolling augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57142731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole network composed of 63 layers, approximately 2.6m total no. of parameters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPool2D,\\\n",
    "                                    GlobalAvgPool2D, Dense, Add, Concatenate, Input,\\\n",
    "                                    Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Note: tf version 2.9.1 does not have Identity layer. Implement our own identity layer which is argument insensitive\n",
    "# and returns its inputs argument as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b037555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/mpri\n",
      "/home/jovyan/committed_git/datasets\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../datasets')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf0b6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = np.load('augmented_features_8_ue1_br_ds.npy')\n",
    "labels = np.load('augmented_labels_8_ue1_br_ds.npy')\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "# random_state = 42 to always ensure same split of dataset\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size = 0.125, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60ae4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Get dictionary of RP index and coordinates\n",
    "# Open HDF5 file and access the dataset\n",
    "filename = 'dataset_SNR10_outdoor.mat'\n",
    "hdf5_file = h5py.File(filename, 'r')\n",
    "\n",
    "features_dataset = hdf5_file['features']\n",
    "labels_dataset = hdf5_file['labels']['position']\n",
    "\n",
    "# Convert HDF5 dataset to NumPy array\n",
    "features = np.array(features_dataset)\n",
    "labels = np.array(labels_dataset)\n",
    "\n",
    "# Prepare features for dataset\n",
    "# Retrieve features from the first UE and transpose the individual matrix\n",
    "features_transposed = np.zeros((3876,193,16), dtype = np.float64)\n",
    "for i in range(len(features)):\n",
    "    features_transposed[i] = features[i][0].T\n",
    "\n",
    "# Prepare labels for dataset\n",
    "count = 0\n",
    "rp_dict = {}\n",
    "# For labels, have a shape of (1,) where that number represents the class of that coordinate\n",
    "\n",
    "for label in labels:\n",
    "    rp_dict[count] = label\n",
    "    count += 1\n",
    "\n",
    "# Close the HDF5 file\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6025c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpriupperhalf_convno, batch_no, pooling_dropout, output_convno,\n",
    "# fc_dropout, lr, l2_conv2d\n",
    "def input_module(x):\n",
    "\n",
    "    # Set no. of filters to 256 to match the output of Add layer at the end of\n",
    "    # upper half of MPRI module\n",
    "    x = Conv2D(filters = 256, kernel_size = 3, strides = 1,\n",
    "               padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Normally, strides = 2 to reduce dimensions but set strides =1 for now to match\n",
    "    # output shapes\n",
    "    x = MaxPool2D(pool_size= 3, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def mpri_upperhalf(x):\n",
    "\n",
    "    # Save input as another variable since need to add input of mpri\n",
    "    # with output of mpri\n",
    "    input_tensor = x\n",
    "\n",
    "    # Bottleneck layer with 1x1 conv filter\n",
    "    bottlenecked_tensor = Conv2D(filters = 128, kernel_size = 1, strides = 1,\n",
    "                                 padding = 'same')(x)\n",
    "\n",
    "    # First path\n",
    "    firstpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    firstpath_tensor = ReLU()(firstpath_tensor)\n",
    "    firstpath_tensor = Conv2D(filters = 64, kernel_size = 1, strides = 1,\n",
    "                              padding = 'same')(firstpath_tensor)\n",
    "\n",
    "    # Second path\n",
    "    secondpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    secondpath_tensor = ReLU()(secondpath_tensor)\n",
    "    secondpath_tensor = Conv2D(filters = 32, kernel_size = (5,1), strides = 1,\n",
    "                               padding = 'same')(secondpath_tensor)\n",
    "    secondpath_tensor = Conv2D(filters = 32, kernel_size = (1,3), strides = 1,\n",
    "                               padding = 'same')(secondpath_tensor)\n",
    "\n",
    "    # Third path\n",
    "    # Normally, strides = 2 to reduce the dimensions of the input\n",
    "    # In this case, experiment with strides = 1 to fit desired output shape for concatenation layer\n",
    "    thirdpath_tensor = MaxPool2D(pool_size = 3, strides = 1, padding = 'same')(bottlenecked_tensor)\n",
    "    thirdpath_tensor = BatchNormalization()(thirdpath_tensor)\n",
    "    thirdpath_tensor = ReLU()(thirdpath_tensor)\n",
    "    thirdpath_tensor = Conv2D(filters = 32, kernel_size = 3, strides = 1,\n",
    "                              padding = 'same')(thirdpath_tensor)\n",
    "\n",
    "    # Fourth path\n",
    "    fourthpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    fourthpath_tensor = ReLU()(fourthpath_tensor)\n",
    "    fourthpath_tensor = Conv2D(filters = 32, kernel_size = 1, strides = 1,\n",
    "                               padding = 'same')(fourthpath_tensor)\n",
    "\n",
    "    fourthpath_tensor = BatchNormalization()(fourthpath_tensor)\n",
    "    fourthpath_tensor = ReLU()(fourthpath_tensor)\n",
    "    fourthpath_tensor = Conv2D(filters = 128, kernel_size = 1, strides = 1,\n",
    "                               padding = 'same')(fourthpath_tensor)\n",
    "\n",
    "    # Depth concatenate the output from the four paths\n",
    "    concatenated_tensor = Concatenate()([firstpath_tensor, secondpath_tensor, thirdpath_tensor, fourthpath_tensor])\n",
    "\n",
    "    # Add the depth concatenated layer and input tensor\n",
    "    # To add successfully, input tensor must have 256 channels as well to match the shape of\n",
    "    # the concatenated tensor\n",
    "    output_tensor = Add()([input_tensor, concatenated_tensor])\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "def mpri_lowerhalf(x):\n",
    "\n",
    "    def conv3x3_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 3, strides = 1,\n",
    "                   padding = 'same')(x)\n",
    "        return x\n",
    "\n",
    "    def conv1x1_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 1, strides = 1,\n",
    "                   padding = 'same')(x)\n",
    "        return x\n",
    "\n",
    "    # --- First layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # --- Second layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(upperpath_tensor)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(lowerpath_tensor)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # --- Third layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(upperpath_tensor)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(lowerpath_tensor)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # Final layer - Add upper and lower path tensors\n",
    "    output_tensor = Add()([upperpath_tensor, lowerpath_tensor])\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "def output_module(x, num_classes = 1000):\n",
    "\n",
    "    x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    x = Dropout(rate = 0.5)(x)\n",
    "    x = Dense(units = num_classes, activation = 'softmax')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43e86a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom callbacks to evaluate model\n",
    "class ValidationCallback3(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, X_val, Y_val, cur_val_loss, val_loss_threshold):\n",
    "        super(ValidationCallback3,self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.cur_val_loss = cur_val_loss\n",
    "        self.val_loss_threshold = val_loss_threshold\n",
    "        \n",
    "    # number_of_iterations = total_number_of_training_examples / batch_size\n",
    "    # In this case, train example of 1,000 and batch size of 100\n",
    "    # number_of_iterations over 1 epoch is 10\n",
    "    # if have 5 epochs, number of iterations is 50\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "        x_error = (actual[0] - predicted[0])**2\n",
    "        y_error = (actual[1] - predicted[1])**2\n",
    "        z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "        return x_error + y_error + z_error\n",
    "        \n",
    "    # Have one function that reports metrics on end of every epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \n",
    "        if epoch % 3 == 0:\n",
    "            # Get evaluation metrics\n",
    "            print('\\n')\n",
    "            print('Epoch End - Custom Validation Callback')\n",
    "\n",
    "\n",
    "            val_loss, val_accuracy = self.model.evaluate(self.X_val, self.Y_val, verbose = 0)\n",
    "\n",
    "            # Get distance error metrics - RMSE\n",
    "            # Get predictions for each feature heatmap in X_val\n",
    "            Y_pred = self.model.predict(self.X_val, verbose = 0)\n",
    "            err_sum = 0\n",
    "\n",
    "            # Iterate through actual and predicted to get distance error\n",
    "            for i in range(len(self.X_val)):\n",
    "\n",
    "                # Get the coordinates for actual y\n",
    "                actual_coords = rp_dict[self.Y_val[i]]\n",
    "\n",
    "                # Get the coordinates for predicted y\n",
    "                predicted_rp = np.argmax(Y_pred[i])\n",
    "                pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "                # Calculate distance error\n",
    "                err = self.calc_error(actual_coords, pred_coords)\n",
    "                err_sum += err\n",
    "            rmse = np.sqrt((err_sum/len(self.X_val)))\n",
    "\n",
    "            # Save values to log\n",
    "            logs['val_loss'] = val_loss\n",
    "            logs['val_accuracy'] = val_accuracy\n",
    "            logs['rmse'] = rmse\n",
    "\n",
    "            # Whenever validation loss is minimised and below threshold, save the model\n",
    "            # and update current minimum loss\n",
    "            if val_loss < self.cur_val_loss and val_loss < self.val_loss_threshold:\n",
    "                self.model.save('mpri_model3.h5')\n",
    "                self.cur_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a57fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but removed early stopping callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import time\n",
    "\n",
    "class MPRI_model3:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        model_input = Input(shape = (193,16,1))\n",
    "        model_output = output_module(mpri_lowerhalf(mpri_upperhalf(input_module(model_input))), num_classes = 3876)\n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                      loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train_model(self):\n",
    "    \n",
    "        # In training, use model.fit() validation callback to get results on training loss, training accuracy,\n",
    "        # validation loss and validation accuracy and rmse after every epoch\n",
    "        val_callback = ValidationCallback3(X_val, y_val, math.inf, 1)\n",
    "        \n",
    "        # Can leave out early stopping for now, manually observe when val_loss stops improving to determine\n",
    "        # optimal number of epochs\n",
    "        \n",
    "        # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        start_time = time.time()\n",
    "        hist = self.model.fit(X_train, y_train,\n",
    "                              epochs = 400,\n",
    "                              batch_size = 64,\n",
    "                              callbacks = [val_callback]\n",
    "#                              callbacks = [val_callback, stop_early]\n",
    "                             )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'Time taken to clear 400 epochs: {end_time - start_time}')\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "            x_error = (actual[0] - predicted[0])**2\n",
    "            y_error = (actual[1] - predicted[1])**2\n",
    "            z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "            return x_error + y_error + z_error\n",
    "    \n",
    "    def calc_errorcdf(self, errors):\n",
    "        \n",
    "        # Sort the array\n",
    "        sorted_data = np.sort(errors)\n",
    "\n",
    "        # Calculate cumulative probabilities\n",
    "        n = len(sorted_data)\n",
    "        cumulative_probs = np.arange(1, n + 1) / n\n",
    "    \n",
    "        return (sorted_data, cumulative_probs)\n",
    "        \n",
    "    def test_model(self, filename):\n",
    "        \n",
    "        # Load model\n",
    "        self.model = keras.models.load_model(filename)\n",
    "        \n",
    "        # In test, use model.predict() to get the RMSE errors of predictions and CDF of distance error\n",
    "        y_pred = self.model.predict(X_test, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        dist_errors = []\n",
    "        max_disterror = -math.inf\n",
    "        max_disterror_actual, max_disterror_pred = None, None\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(X_test)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[y_test[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            \n",
    "            # Update the maximum errror, if needed\n",
    "            dist_err = np.sqrt(err)\n",
    "            if dist_err > max_disterror:\n",
    "                \n",
    "                # Update max error\n",
    "                max_disterror = dist_err\n",
    "                \n",
    "                # Return the class index and then retrieve actual coordinates from rp_dict\n",
    "                max_disterror_actual = y_test[i]\n",
    "                max_disterror_pred = predicted_rp\n",
    "            \n",
    "            # Append error to distance errors\n",
    "            dist_errors.append(dist_err)\n",
    "            err_sum += err\n",
    "            \n",
    "        # Get RMSE of all predicted points\n",
    "        rmse = np.sqrt((err_sum/len(X_test)))\n",
    "        \n",
    "        # Get actual and predicted point with the largest error\n",
    "        print(f'Largest error: {max_disterror}, Actual RP index: {max_disterror_actual}, Predicted RP index: {max_disterror_pred}')\n",
    "        \n",
    "        return (rmse, *self.calc_errorcdf(dist_errors))\n",
    "    \n",
    "    def eval_model(self, filename):\n",
    "        \n",
    "        self.model = keras.models.load_model(filename)\n",
    "        test_loss, test_acc = self.model.evaluate(X_test, y_test, batch_size = 64)\n",
    "        \n",
    "        return (test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cde70709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/datasets\n",
      "/home/jovyan/committed_git/mpri\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../mpri')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f675f80c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 193, 16, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 193, 16, 256  2560        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 193, 16, 256  1024       ['conv2d_30[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 193, 16, 256  0           ['batch_normalization_26[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_16 (MaxPooling2D  (None, 97, 8, 256)  0           ['re_lu_26[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 97, 8, 128)   32896       ['max_pooling2d_16[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 97, 8, 128)  512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 97, 8, 128)  512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_17 (MaxPooling2D  (None, 97, 8, 128)  0           ['conv2d_31[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 97, 8, 32)    4128        ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 97, 8, 128)  512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 97, 8, 128)  512         ['max_pooling2d_17[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 97, 8, 32)   128         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 97, 8, 32)    20512       ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 97, 8, 32)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 97, 8, 64)    8256        ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 97, 8, 32)    3104        ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 97, 8, 32)    36896       ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 97, 8, 128)   4224        ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 97, 8, 256)   0           ['conv2d_32[0][0]',              \n",
      "                                                                  'conv2d_34[0][0]',              \n",
      "                                                                  'conv2d_35[0][0]',              \n",
      "                                                                  'conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 97, 8, 256)   0           ['max_pooling2d_16[0][0]',       \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_18 (MaxPooling2D  (None, 49, 4, 256)  0           ['add_16[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_19 (MaxPooling2D  (None, 49, 4, 256)  0           ['add_16[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 49, 4, 256)  1024        ['max_pooling2d_18[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 49, 4, 256)  1024        ['max_pooling2d_19[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 49, 4, 256)   0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 49, 4, 256)   0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 49, 4, 256)   590080      ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 49, 4, 256)   65792       ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 49, 4, 256)   0           ['max_pooling2d_18[0][0]',       \n",
      "                                                                  'conv2d_38[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 49, 4, 256)   0           ['max_pooling2d_19[0][0]',       \n",
      "                                                                  'conv2d_39[0][0]',              \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooling2D  (None, 25, 2, 256)  0           ['add_17[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_21 (MaxPooling2D  (None, 25, 2, 256)  0           ['add_18[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 25, 2, 256)  1024        ['max_pooling2d_20[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 25, 2, 256)  1024        ['max_pooling2d_21[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 25, 2, 256)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 25, 2, 256)   0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 25, 2, 256)   590080      ['re_lu_34[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 25, 2, 256)   65792       ['re_lu_35[0][0]']               \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 25, 2, 256)   0           ['max_pooling2d_20[0][0]',       \n",
      "                                                                  'conv2d_40[0][0]',              \n",
      "                                                                  'conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 25, 2, 256)   0           ['max_pooling2d_21[0][0]',       \n",
      "                                                                  'conv2d_41[0][0]',              \n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooling2D  (None, 13, 1, 256)  0           ['add_19[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooling2D  (None, 13, 1, 256)  0           ['add_20[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_22[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_23[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 13, 1, 256)   590080      ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 13, 1, 256)   65792       ['re_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 13, 1, 256)   0           ['max_pooling2d_22[0][0]',       \n",
      "                                                                  'conv2d_42[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 13, 1, 256)   0           ['max_pooling2d_23[0][0]',       \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 13, 1, 256)   0           ['add_21[0][0]',                 \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 13, 1, 128)   295040      ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 13, 1, 128)  512         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 13, 1, 128)   0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 128)         0           ['re_lu_38[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3876)         500004      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,885,092\n",
      "Trainable params: 2,880,164\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mpri_model3 = MPRI_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a96c1e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 7.8794 - accuracy: 0.0088\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 39s 33ms/step - loss: 7.8785 - accuracy: 0.0088 - val_loss: 7.2308 - val_accuracy: 0.0410 - rmse: 5.3904\n",
      "Epoch 2/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 6.3525 - accuracy: 0.0757\n",
      "Epoch 3/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 4.6521 - accuracy: 0.2203\n",
      "Epoch 4/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 3.3458 - accuracy: 0.4018\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 3.3452 - accuracy: 0.4020 - val_loss: 2.6401 - val_accuracy: 0.6360 - rmse: 1.3120\n",
      "Epoch 5/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 2.4750 - accuracy: 0.5519\n",
      "Epoch 6/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 1.9091 - accuracy: 0.6502\n",
      "Epoch 7/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 1.5171 - accuracy: 0.7198\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 1.5171 - accuracy: 0.7198 - val_loss: 1.0585 - val_accuracy: 0.8995 - rmse: 0.4841\n",
      "Epoch 8/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 1.2448 - accuracy: 0.7640\n",
      "Epoch 9/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 1.0366 - accuracy: 0.7986\n",
      "Epoch 10/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.8833 - accuracy: 0.8252\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.8832 - accuracy: 0.8253 - val_loss: 0.5651 - val_accuracy: 0.9390 - rmse: 0.3500\n",
      "Epoch 11/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.7580 - accuracy: 0.8469\n",
      "Epoch 12/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.6649 - accuracy: 0.8633\n",
      "Epoch 13/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.5841 - accuracy: 0.8753\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.5841 - accuracy: 0.8752 - val_loss: 0.3535 - val_accuracy: 0.9572 - rmse: 0.3108\n",
      "Epoch 14/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.5249 - accuracy: 0.8848\n",
      "Epoch 15/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.4717 - accuracy: 0.8953\n",
      "Epoch 16/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.4270 - accuracy: 0.9022\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.4269 - accuracy: 0.9022 - val_loss: 0.2366 - val_accuracy: 0.9689 - rmse: 0.2517\n",
      "Epoch 17/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.3893 - accuracy: 0.9107\n",
      "Epoch 18/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.3566 - accuracy: 0.9166\n",
      "Epoch 19/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.3285 - accuracy: 0.9229\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.3286 - accuracy: 0.9228 - val_loss: 0.1786 - val_accuracy: 0.9699 - rmse: 0.2429\n",
      "Epoch 20/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.3064 - accuracy: 0.9252\n",
      "Epoch 21/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.2881 - accuracy: 0.9278\n",
      "Epoch 22/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.9340\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.2656 - accuracy: 0.9340 - val_loss: 0.1273 - val_accuracy: 0.9784 - rmse: 0.2121\n",
      "Epoch 23/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.2518 - accuracy: 0.9363\n",
      "Epoch 24/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.2354 - accuracy: 0.9413\n",
      "Epoch 25/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9428\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.2224 - accuracy: 0.9428 - val_loss: 0.1055 - val_accuracy: 0.9819 - rmse: 0.2121\n",
      "Epoch 26/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.2098 - accuracy: 0.9456\n",
      "Epoch 27/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.1993 - accuracy: 0.9484\n",
      "Epoch 28/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.1907 - accuracy: 0.9497\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.1907 - accuracy: 0.9497 - val_loss: 0.0860 - val_accuracy: 0.9828 - rmse: 0.1882\n",
      "Epoch 29/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.1827 - accuracy: 0.9517\n",
      "Epoch 30/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.1749 - accuracy: 0.9533\n",
      "Epoch 31/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9560\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.1638 - accuracy: 0.9560 - val_loss: 0.0749 - val_accuracy: 0.9828 - rmse: 0.1851\n",
      "Epoch 32/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.1605 - accuracy: 0.9565\n",
      "Epoch 33/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.1547 - accuracy: 0.9580\n",
      "Epoch 34/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9579\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.1507 - accuracy: 0.9579 - val_loss: 0.0620 - val_accuracy: 0.9842 - rmse: 0.1942\n",
      "Epoch 35/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.1407 - accuracy: 0.9614\n",
      "Epoch 36/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.1379 - accuracy: 0.9617\n",
      "Epoch 37/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9631\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.1336 - accuracy: 0.9631 - val_loss: 0.0566 - val_accuracy: 0.9871 - rmse: 0.1706\n",
      "Epoch 38/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.1299 - accuracy: 0.9629\n",
      "Epoch 39/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.1276 - accuracy: 0.9639\n",
      "Epoch 40/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9653\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.1216 - accuracy: 0.9653 - val_loss: 0.0488 - val_accuracy: 0.9871 - rmse: 0.1742\n",
      "Epoch 41/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.1173 - accuracy: 0.9664\n",
      "Epoch 42/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.1148 - accuracy: 0.9666\n",
      "Epoch 43/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9676\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.1118 - accuracy: 0.9676 - val_loss: 0.0383 - val_accuracy: 0.9917 - rmse: 0.1245\n",
      "Epoch 44/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.1110 - accuracy: 0.9676\n",
      "Epoch 45/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.1065 - accuracy: 0.9694\n",
      "Epoch 46/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9687\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.1059 - accuracy: 0.9686 - val_loss: 0.0459 - val_accuracy: 0.9869 - rmse: 0.1636\n",
      "Epoch 47/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.0994 - accuracy: 0.9703\n",
      "Epoch 48/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.1010 - accuracy: 0.9704\n",
      "Epoch 49/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9704\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0980 - accuracy: 0.9704 - val_loss: 0.0332 - val_accuracy: 0.9912 - rmse: 0.1361\n",
      "Epoch 50/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.0968 - accuracy: 0.9713\n",
      "Epoch 51/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.0929 - accuracy: 0.9719\n",
      "Epoch 52/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9720\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0930 - accuracy: 0.9720 - val_loss: 0.0299 - val_accuracy: 0.9910 - rmse: 0.1442\n",
      "Epoch 53/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0889 - accuracy: 0.9734\n",
      "Epoch 54/400\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.0881 - accuracy: 0.9733\n",
      "Epoch 55/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9739\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0857 - accuracy: 0.9739 - val_loss: 0.0339 - val_accuracy: 0.9890 - rmse: 0.1541\n",
      "Epoch 56/400\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.0843 - accuracy: 0.9736\n",
      "Epoch 57/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0820 - accuracy: 0.9751\n",
      "Epoch 58/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9761\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0804 - accuracy: 0.9761 - val_loss: 0.0312 - val_accuracy: 0.9906 - rmse: 0.1529\n",
      "Epoch 59/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0807 - accuracy: 0.9748\n",
      "Epoch 60/400\n",
      "1145/1145 [==============================] - 35s 31ms/step - loss: 0.0786 - accuracy: 0.9757\n",
      "Epoch 61/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9755\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.0788 - accuracy: 0.9755 - val_loss: 0.0296 - val_accuracy: 0.9901 - rmse: 0.1463\n",
      "Epoch 62/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0747 - accuracy: 0.9772\n",
      "Epoch 63/400\n",
      "1145/1145 [==============================] - 44s 38ms/step - loss: 0.0757 - accuracy: 0.9761\n",
      "Epoch 64/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.9772\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 46s 40ms/step - loss: 0.0732 - accuracy: 0.9772 - val_loss: 0.0316 - val_accuracy: 0.9886 - rmse: 0.1517\n",
      "Epoch 65/400\n",
      "1145/1145 [==============================] - 35s 31ms/step - loss: 0.0741 - accuracy: 0.9765\n",
      "Epoch 66/400\n",
      "1145/1145 [==============================] - 39s 34ms/step - loss: 0.0721 - accuracy: 0.9774\n",
      "Epoch 67/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9778\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 0.0279 - val_accuracy: 0.9905 - rmse: 0.1476\n",
      "Epoch 68/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0684 - accuracy: 0.9791\n",
      "Epoch 69/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0702 - accuracy: 0.9780\n",
      "Epoch 70/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9795\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0656 - accuracy: 0.9795 - val_loss: 0.0236 - val_accuracy: 0.9923 - rmse: 0.1510\n",
      "Epoch 71/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0672 - accuracy: 0.9786\n",
      "Epoch 72/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0672 - accuracy: 0.9783\n",
      "Epoch 73/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9795\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 39s 34ms/step - loss: 0.0645 - accuracy: 0.9795 - val_loss: 0.0211 - val_accuracy: 0.9925 - rmse: 0.1316\n",
      "Epoch 74/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0635 - accuracy: 0.9803\n",
      "Epoch 75/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0655 - accuracy: 0.9793\n",
      "Epoch 76/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9809\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 48s 42ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.0237 - val_accuracy: 0.9924 - rmse: 0.1383\n",
      "Epoch 77/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0607 - accuracy: 0.9810\n",
      "Epoch 78/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0598 - accuracy: 0.9812\n",
      "Epoch 79/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9798\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 41s 36ms/step - loss: 0.0620 - accuracy: 0.9798 - val_loss: 0.0257 - val_accuracy: 0.9918 - rmse: 0.1392\n",
      "Epoch 80/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0601 - accuracy: 0.9811\n",
      "Epoch 81/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0565 - accuracy: 0.9822\n",
      "Epoch 82/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9808\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0604 - accuracy: 0.9808 - val_loss: 0.0176 - val_accuracy: 0.9943 - rmse: 0.1160\n",
      "Epoch 83/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0611 - accuracy: 0.9798\n",
      "Epoch 84/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0544 - accuracy: 0.9825\n",
      "Epoch 85/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9822\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0559 - accuracy: 0.9822 - val_loss: 0.0179 - val_accuracy: 0.9933 - rmse: 0.1486\n",
      "Epoch 86/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0560 - accuracy: 0.9819\n",
      "Epoch 87/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0557 - accuracy: 0.9824\n",
      "Epoch 88/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9827\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.0214 - val_accuracy: 0.9925 - rmse: 0.1314\n",
      "Epoch 89/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.0530 - accuracy: 0.9828\n",
      "Epoch 90/400\n",
      "1145/1145 [==============================] - 39s 34ms/step - loss: 0.0538 - accuracy: 0.9823\n",
      "Epoch 91/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9826\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 0.0204 - val_accuracy: 0.9927 - rmse: 0.1240\n",
      "Epoch 92/400\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0532 - accuracy: 0.9823\n",
      "Epoch 93/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0516 - accuracy: 0.9832\n",
      "Epoch 94/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9832\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0512 - accuracy: 0.9832 - val_loss: 0.0187 - val_accuracy: 0.9928 - rmse: 0.1214\n",
      "Epoch 95/400\n",
      "1145/1145 [==============================] - 38s 34ms/step - loss: 0.0529 - accuracy: 0.9818\n",
      "Epoch 96/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0492 - accuracy: 0.9841\n",
      "Epoch 97/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9832\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 0.0212 - val_accuracy: 0.9914 - rmse: 0.1298\n",
      "Epoch 98/400\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.0481 - accuracy: 0.9836\n",
      "Epoch 99/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0488 - accuracy: 0.9843\n",
      "Epoch 100/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9837\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 48s 42ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.0163 - val_accuracy: 0.9938 - rmse: 0.1160\n",
      "Epoch 101/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0471 - accuracy: 0.9845\n",
      "Epoch 102/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0501 - accuracy: 0.9834\n",
      "Epoch 103/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9852\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 41s 36ms/step - loss: 0.0457 - accuracy: 0.9852 - val_loss: 0.0228 - val_accuracy: 0.9903 - rmse: 0.1473\n",
      "Epoch 104/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0478 - accuracy: 0.9844\n",
      "Epoch 105/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0475 - accuracy: 0.9848\n",
      "Epoch 106/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9849\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 0.0123 - val_accuracy: 0.9955 - rmse: 0.1119\n",
      "Epoch 107/400\n",
      "1145/1145 [==============================] - 43s 37ms/step - loss: 0.0454 - accuracy: 0.9850\n",
      "Epoch 108/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0460 - accuracy: 0.9846\n",
      "Epoch 109/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9857\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.0147 - val_accuracy: 0.9934 - rmse: 0.1304\n",
      "Epoch 110/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0462 - accuracy: 0.9846\n",
      "Epoch 111/400\n",
      "1145/1145 [==============================] - 41s 36ms/step - loss: 0.0425 - accuracy: 0.9861\n",
      "Epoch 112/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9849\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0438 - accuracy: 0.9849 - val_loss: 0.0155 - val_accuracy: 0.9932 - rmse: 0.1328\n",
      "Epoch 113/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0442 - accuracy: 0.9846\n",
      "Epoch 114/400\n",
      "1145/1145 [==============================] - 39s 34ms/step - loss: 0.0440 - accuracy: 0.9856\n",
      "Epoch 115/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9858\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0419 - accuracy: 0.9858 - val_loss: 0.0254 - val_accuracy: 0.9894 - rmse: 0.1465\n",
      "Epoch 116/400\n",
      "1145/1145 [==============================] - 36s 31ms/step - loss: 0.0417 - accuracy: 0.9863\n",
      "Epoch 117/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0414 - accuracy: 0.9863\n",
      "Epoch 118/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9861\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0145 - val_accuracy: 0.9932 - rmse: 0.1261\n",
      "Epoch 119/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0437 - accuracy: 0.9855\n",
      "Epoch 120/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0407 - accuracy: 0.9865\n",
      "Epoch 121/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9864\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0415 - accuracy: 0.9864 - val_loss: 0.0129 - val_accuracy: 0.9939 - rmse: 0.1141\n",
      "Epoch 122/400\n",
      "1145/1145 [==============================] - 35s 30ms/step - loss: 0.0433 - accuracy: 0.9851\n",
      "Epoch 123/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0419 - accuracy: 0.9858\n",
      "Epoch 124/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9869\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 0.0145 - val_accuracy: 0.9934 - rmse: 0.1274\n",
      "Epoch 125/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0415 - accuracy: 0.9859\n",
      "Epoch 126/400\n",
      "1145/1145 [==============================] - 44s 38ms/step - loss: 0.0390 - accuracy: 0.9870\n",
      "Epoch 127/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.9868\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 44s 38ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.0172 - val_accuracy: 0.9926 - rmse: 0.1288\n",
      "Epoch 128/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0402 - accuracy: 0.9865\n",
      "Epoch 129/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0374 - accuracy: 0.9879\n",
      "Epoch 130/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9869\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0396 - accuracy: 0.9869 - val_loss: 0.0115 - val_accuracy: 0.9952 - rmse: 0.1040\n",
      "Epoch 131/400\n",
      "1145/1145 [==============================] - 44s 38ms/step - loss: 0.0386 - accuracy: 0.9869\n",
      "Epoch 132/400\n",
      "1145/1145 [==============================] - 44s 38ms/step - loss: 0.0392 - accuracy: 0.9869\n",
      "Epoch 133/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9867\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 47s 41ms/step - loss: 0.0399 - accuracy: 0.9867 - val_loss: 0.0120 - val_accuracy: 0.9949 - rmse: 0.1067\n",
      "Epoch 134/400\n",
      "1145/1145 [==============================] - 44s 38ms/step - loss: 0.0364 - accuracy: 0.9875\n",
      "Epoch 135/400\n",
      "1145/1145 [==============================] - 39s 34ms/step - loss: 0.0377 - accuracy: 0.9876\n",
      "Epoch 136/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9889\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0341 - accuracy: 0.9889 - val_loss: 0.0124 - val_accuracy: 0.9954 - rmse: 0.1097\n",
      "Epoch 137/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.0390 - accuracy: 0.9863\n",
      "Epoch 138/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0386 - accuracy: 0.9876\n",
      "Epoch 139/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9874\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0367 - accuracy: 0.9874 - val_loss: 0.0184 - val_accuracy: 0.9931 - rmse: 0.1155\n",
      "Epoch 140/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0366 - accuracy: 0.9877\n",
      "Epoch 141/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0350 - accuracy: 0.9883\n",
      "Epoch 142/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9879\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.0135 - val_accuracy: 0.9935 - rmse: 0.1074\n",
      "Epoch 143/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0384 - accuracy: 0.9867\n",
      "Epoch 144/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0359 - accuracy: 0.9874\n",
      "Epoch 145/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9890\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.0149 - val_accuracy: 0.9928 - rmse: 0.1198\n",
      "Epoch 146/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0356 - accuracy: 0.9879\n",
      "Epoch 147/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0349 - accuracy: 0.9880\n",
      "Epoch 148/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9877\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0130 - val_accuracy: 0.9950 - rmse: 0.1110\n",
      "Epoch 149/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0349 - accuracy: 0.9880\n",
      "Epoch 150/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0339 - accuracy: 0.9883\n",
      "Epoch 151/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9886\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.0141 - val_accuracy: 0.9941 - rmse: 0.1214\n",
      "Epoch 152/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0337 - accuracy: 0.9881\n",
      "Epoch 153/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0343 - accuracy: 0.9885\n",
      "Epoch 154/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9886\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 41s 36ms/step - loss: 0.0329 - accuracy: 0.9886 - val_loss: 0.0144 - val_accuracy: 0.9941 - rmse: 0.1244\n",
      "Epoch 155/400\n",
      "1145/1145 [==============================] - 42s 37ms/step - loss: 0.0331 - accuracy: 0.9885\n",
      "Epoch 156/400\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0340 - accuracy: 0.9882\n",
      "Epoch 157/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9894\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0145 - val_accuracy: 0.9940 - rmse: 0.0984\n",
      "Epoch 158/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0341 - accuracy: 0.9883\n",
      "Epoch 159/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0332 - accuracy: 0.9884\n",
      "Epoch 160/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9894\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 0.0190 - val_accuracy: 0.9921 - rmse: 0.1195\n",
      "Epoch 161/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0332 - accuracy: 0.9886\n",
      "Epoch 162/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0313 - accuracy: 0.9892\n",
      "Epoch 163/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9887\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 45s 39ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 0.0151 - val_accuracy: 0.9928 - rmse: 0.1374\n",
      "Epoch 164/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0318 - accuracy: 0.9886\n",
      "Epoch 165/400\n",
      "1145/1145 [==============================] - 43s 38ms/step - loss: 0.0345 - accuracy: 0.9883\n",
      "Epoch 166/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9893\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 48s 42ms/step - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.0108 - val_accuracy: 0.9952 - rmse: 0.1058\n",
      "Epoch 167/400\n",
      "1145/1145 [==============================] - 41s 36ms/step - loss: 0.0317 - accuracy: 0.9893\n",
      "Epoch 168/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0309 - accuracy: 0.9895\n",
      "Epoch 169/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9894\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.0116 - val_accuracy: 0.9946 - rmse: 0.1281\n",
      "Epoch 170/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0303 - accuracy: 0.9891\n",
      "Epoch 171/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0318 - accuracy: 0.9891\n",
      "Epoch 172/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9893\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0135 - val_accuracy: 0.9936 - rmse: 0.1140\n",
      "Epoch 173/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0314 - accuracy: 0.9890\n",
      "Epoch 174/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0295 - accuracy: 0.9900\n",
      "Epoch 175/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9889\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.0095 - val_accuracy: 0.9960 - rmse: 0.0940\n",
      "Epoch 176/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0310 - accuracy: 0.9890\n",
      "Epoch 177/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0305 - accuracy: 0.9893\n",
      "Epoch 178/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9901\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.0116 - val_accuracy: 0.9946 - rmse: 0.1009\n",
      "Epoch 179/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0293 - accuracy: 0.9894\n",
      "Epoch 180/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0308 - accuracy: 0.9890\n",
      "Epoch 181/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9902\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0112 - val_accuracy: 0.9955 - rmse: 0.0994\n",
      "Epoch 182/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0289 - accuracy: 0.9900\n",
      "Epoch 183/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0295 - accuracy: 0.9897\n",
      "Epoch 184/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9897\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.0109 - val_accuracy: 0.9951 - rmse: 0.1220\n",
      "Epoch 185/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0270 - accuracy: 0.9903\n",
      "Epoch 186/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0297 - accuracy: 0.9897\n",
      "Epoch 187/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9905\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.0169 - val_accuracy: 0.9933 - rmse: 0.1152\n",
      "Epoch 188/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0282 - accuracy: 0.9904\n",
      "Epoch 189/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0309 - accuracy: 0.9894\n",
      "Epoch 190/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9908\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0109 - val_accuracy: 0.9951 - rmse: 0.0953\n",
      "Epoch 191/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0286 - accuracy: 0.9899\n",
      "Epoch 192/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0258 - accuracy: 0.9913\n",
      "Epoch 193/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9909\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.0084 - val_accuracy: 0.9967 - rmse: 0.0838\n",
      "Epoch 194/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0268 - accuracy: 0.9906\n",
      "Epoch 195/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0278 - accuracy: 0.9901\n",
      "Epoch 196/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9896\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.0097 - val_accuracy: 0.9950 - rmse: 0.1130\n",
      "Epoch 197/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0269 - accuracy: 0.9902\n",
      "Epoch 198/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0268 - accuracy: 0.9905\n",
      "Epoch 199/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9896\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0276 - accuracy: 0.9896 - val_loss: 0.0085 - val_accuracy: 0.9965 - rmse: 0.0935\n",
      "Epoch 200/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0277 - accuracy: 0.9901\n",
      "Epoch 201/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0258 - accuracy: 0.9911\n",
      "Epoch 202/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9903\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.0091 - val_accuracy: 0.9958 - rmse: 0.1040\n",
      "Epoch 203/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0260 - accuracy: 0.9910\n",
      "Epoch 204/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0252 - accuracy: 0.9913\n",
      "Epoch 205/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9902\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0280 - accuracy: 0.9902 - val_loss: 0.0104 - val_accuracy: 0.9946 - rmse: 0.1121\n",
      "Epoch 206/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0259 - accuracy: 0.9910\n",
      "Epoch 207/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0284 - accuracy: 0.9899\n",
      "Epoch 208/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9914\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0102 - val_accuracy: 0.9953 - rmse: 0.1025\n",
      "Epoch 209/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0265 - accuracy: 0.9912\n",
      "Epoch 210/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0260 - accuracy: 0.9910\n",
      "Epoch 211/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9913\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0080 - val_accuracy: 0.9957 - rmse: 0.1006\n",
      "Epoch 212/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0271 - accuracy: 0.9903\n",
      "Epoch 213/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0263 - accuracy: 0.9909\n",
      "Epoch 214/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9912\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.0075 - val_accuracy: 0.9966 - rmse: 0.1008\n",
      "Epoch 215/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0243 - accuracy: 0.9911\n",
      "Epoch 216/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0269 - accuracy: 0.9903\n",
      "Epoch 217/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9913\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0077 - val_accuracy: 0.9954 - rmse: 0.1113\n",
      "Epoch 218/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0258 - accuracy: 0.9914\n",
      "Epoch 219/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0262 - accuracy: 0.9911\n",
      "Epoch 220/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9911\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.0077 - val_accuracy: 0.9965 - rmse: 0.0923\n",
      "Epoch 221/400\n",
      "1145/1145 [==============================] - 34s 30ms/step - loss: 0.0254 - accuracy: 0.9912\n",
      "Epoch 222/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0265 - accuracy: 0.9907\n",
      "Epoch 223/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9907\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 38s 33ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.0092 - val_accuracy: 0.9959 - rmse: 0.1022\n",
      "Epoch 224/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 225/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0253 - accuracy: 0.9910\n",
      "Epoch 226/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9921\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0079 - val_accuracy: 0.9964 - rmse: 0.0855\n",
      "Epoch 227/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0255 - accuracy: 0.9911\n",
      "Epoch 228/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0257 - accuracy: 0.9910\n",
      "Epoch 229/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9918\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.0117 - val_accuracy: 0.9948 - rmse: 0.0977\n",
      "Epoch 230/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0251 - accuracy: 0.9906\n",
      "Epoch 231/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0244 - accuracy: 0.9917\n",
      "Epoch 232/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9913\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0137 - val_accuracy: 0.9938 - rmse: 0.1098\n",
      "Epoch 233/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0233 - accuracy: 0.9916\n",
      "Epoch 234/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0247 - accuracy: 0.9913\n",
      "Epoch 235/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9922\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.0101 - val_accuracy: 0.9947 - rmse: 0.1067\n",
      "Epoch 236/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0223 - accuracy: 0.9922\n",
      "Epoch 237/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0249 - accuracy: 0.9912\n",
      "Epoch 238/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9919\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.0117 - val_accuracy: 0.9950 - rmse: 0.1180\n",
      "Epoch 239/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0253 - accuracy: 0.9913\n",
      "Epoch 240/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0220 - accuracy: 0.9918\n",
      "Epoch 241/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9911\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0245 - accuracy: 0.9910 - val_loss: 0.0091 - val_accuracy: 0.9958 - rmse: 0.1028\n",
      "Epoch 242/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0232 - accuracy: 0.9918\n",
      "Epoch 243/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0248 - accuracy: 0.9911\n",
      "Epoch 244/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9919\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.0082 - val_accuracy: 0.9958 - rmse: 0.1083\n",
      "Epoch 245/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0230 - accuracy: 0.9919\n",
      "Epoch 246/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0238 - accuracy: 0.9914\n",
      "Epoch 247/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9922\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.0081 - val_accuracy: 0.9962 - rmse: 0.0922\n",
      "Epoch 248/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0237 - accuracy: 0.9918\n",
      "Epoch 249/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0234 - accuracy: 0.9918\n",
      "Epoch 250/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9918\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0114 - val_accuracy: 0.9955 - rmse: 0.1091\n",
      "Epoch 251/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0212 - accuracy: 0.9925\n",
      "Epoch 252/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0219 - accuracy: 0.9926\n",
      "Epoch 253/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9911\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0095 - val_accuracy: 0.9964 - rmse: 0.1121\n",
      "Epoch 254/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0232 - accuracy: 0.9919\n",
      "Epoch 255/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0221 - accuracy: 0.9918\n",
      "Epoch 256/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9922\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.0129 - val_accuracy: 0.9947 - rmse: 0.1281\n",
      "Epoch 257/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0234 - accuracy: 0.9917\n",
      "Epoch 258/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0226 - accuracy: 0.9921\n",
      "Epoch 259/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9924\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.0278 - val_accuracy: 0.9902 - rmse: 0.1446\n",
      "Epoch 260/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0222 - accuracy: 0.9918\n",
      "Epoch 261/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0214 - accuracy: 0.9927\n",
      "Epoch 262/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9928\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0062 - val_accuracy: 0.9967 - rmse: 0.0888\n",
      "Epoch 263/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0211 - accuracy: 0.9926\n",
      "Epoch 264/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0224 - accuracy: 0.9921\n",
      "Epoch 265/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9923\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 0.0107 - val_accuracy: 0.9957 - rmse: 0.1037\n",
      "Epoch 266/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0219 - accuracy: 0.9923\n",
      "Epoch 267/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0220 - accuracy: 0.9921\n",
      "Epoch 268/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9928\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0065 - val_accuracy: 0.9967 - rmse: 0.0861\n",
      "Epoch 269/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0198 - accuracy: 0.9928\n",
      "Epoch 270/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0230 - accuracy: 0.9919\n",
      "Epoch 271/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9927\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.0082 - val_accuracy: 0.9958 - rmse: 0.1158\n",
      "Epoch 272/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0219 - accuracy: 0.9919\n",
      "Epoch 273/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0213 - accuracy: 0.9924\n",
      "Epoch 274/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9922\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.0073 - val_accuracy: 0.9960 - rmse: 0.0927\n",
      "Epoch 275/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0207 - accuracy: 0.9924\n",
      "Epoch 276/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0213 - accuracy: 0.9926\n",
      "Epoch 277/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9929\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.0125 - val_accuracy: 0.9965 - rmse: 0.1063\n",
      "Epoch 278/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0225 - accuracy: 0.9921\n",
      "Epoch 279/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0205 - accuracy: 0.9927\n",
      "Epoch 280/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9929\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0075 - val_accuracy: 0.9964 - rmse: 0.1037\n",
      "Epoch 281/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0200 - accuracy: 0.9929\n",
      "Epoch 282/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0235 - accuracy: 0.9921\n",
      "Epoch 283/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9923\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0205 - accuracy: 0.9923 - val_loss: 0.0100 - val_accuracy: 0.9959 - rmse: 0.1039\n",
      "Epoch 284/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0213 - accuracy: 0.9926\n",
      "Epoch 285/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0218 - accuracy: 0.9922\n",
      "Epoch 286/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9927\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.0065 - val_accuracy: 0.9971 - rmse: 0.0779\n",
      "Epoch 287/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0233 - accuracy: 0.9919\n",
      "Epoch 288/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0196 - accuracy: 0.9932\n",
      "Epoch 289/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9929\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0094 - val_accuracy: 0.9949 - rmse: 0.1115\n",
      "Epoch 290/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0196 - accuracy: 0.9930\n",
      "Epoch 291/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0216 - accuracy: 0.9925\n",
      "Epoch 292/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9927\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.0053 - val_accuracy: 0.9979 - rmse: 0.0698\n",
      "Epoch 293/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0188 - accuracy: 0.9934\n",
      "Epoch 294/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0225 - accuracy: 0.9927\n",
      "Epoch 295/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0076 - val_accuracy: 0.9963 - rmse: 0.0951\n",
      "Epoch 296/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 297/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0203 - accuracy: 0.9925\n",
      "Epoch 298/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9925\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0070 - val_accuracy: 0.9963 - rmse: 0.0881\n",
      "Epoch 299/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 300/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0199 - accuracy: 0.9930\n",
      "Epoch 301/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9927\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0106 - val_accuracy: 0.9956 - rmse: 0.1039\n",
      "Epoch 302/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0203 - accuracy: 0.9928\n",
      "Epoch 303/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0210 - accuracy: 0.9925\n",
      "Epoch 304/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9938\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.0062 - val_accuracy: 0.9968 - rmse: 0.1005\n",
      "Epoch 305/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0213 - accuracy: 0.9924\n",
      "Epoch 306/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0210 - accuracy: 0.9924\n",
      "Epoch 307/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.0077 - val_accuracy: 0.9963 - rmse: 0.0980\n",
      "Epoch 308/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0191 - accuracy: 0.9932\n",
      "Epoch 309/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0198 - accuracy: 0.9932\n",
      "Epoch 310/400\n",
      "1145/1145 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9931\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.0115 - val_accuracy: 0.9960 - rmse: 0.0918\n",
      "Epoch 311/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0196 - accuracy: 0.9931\n",
      "Epoch 312/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0191 - accuracy: 0.9932\n",
      "Epoch 313/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9933\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0068 - val_accuracy: 0.9965 - rmse: 0.0914\n",
      "Epoch 314/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0188 - accuracy: 0.9930\n",
      "Epoch 315/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0193 - accuracy: 0.9934\n",
      "Epoch 316/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9930\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 0.0120 - val_accuracy: 0.9948 - rmse: 0.1043\n",
      "Epoch 317/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0175 - accuracy: 0.9938\n",
      "Epoch 318/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0193 - accuracy: 0.9929\n",
      "Epoch 319/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9929\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.0054 - val_accuracy: 0.9971 - rmse: 0.0852\n",
      "Epoch 320/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0183 - accuracy: 0.9934\n",
      "Epoch 321/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0191 - accuracy: 0.9931\n",
      "Epoch 322/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9932\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.0061 - val_accuracy: 0.9969 - rmse: 0.0906\n",
      "Epoch 323/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0191 - accuracy: 0.9929\n",
      "Epoch 324/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0190 - accuracy: 0.9931\n",
      "Epoch 325/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9935\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.0070 - val_accuracy: 0.9962 - rmse: 0.1092\n",
      "Epoch 326/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0183 - accuracy: 0.9933\n",
      "Epoch 327/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0200 - accuracy: 0.9930\n",
      "Epoch 328/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9936\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.0057 - val_accuracy: 0.9974 - rmse: 0.0988\n",
      "Epoch 329/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0175 - accuracy: 0.9938\n",
      "Epoch 330/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0190 - accuracy: 0.9936\n",
      "Epoch 331/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9928\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 0.0051 - val_accuracy: 0.9975 - rmse: 0.0809\n",
      "Epoch 332/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0183 - accuracy: 0.9936\n",
      "Epoch 333/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 334/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9931\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.0072 - val_accuracy: 0.9965 - rmse: 0.0950\n",
      "Epoch 335/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0157 - accuracy: 0.9945\n",
      "Epoch 336/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0178 - accuracy: 0.9936\n",
      "Epoch 337/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9927\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.0060 - val_accuracy: 0.9964 - rmse: 0.0866\n",
      "Epoch 338/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0181 - accuracy: 0.9937\n",
      "Epoch 339/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0191 - accuracy: 0.9935\n",
      "Epoch 340/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9934\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.0099 - val_accuracy: 0.9961 - rmse: 0.0977\n",
      "Epoch 341/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0193 - accuracy: 0.9930\n",
      "Epoch 342/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0175 - accuracy: 0.9938\n",
      "Epoch 343/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9936\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0063 - val_accuracy: 0.9967 - rmse: 0.1004\n",
      "Epoch 344/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0179 - accuracy: 0.9940\n",
      "Epoch 345/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0161 - accuracy: 0.9942\n",
      "Epoch 346/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9933\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.0042 - val_accuracy: 0.9980 - rmse: 0.0733\n",
      "Epoch 347/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0170 - accuracy: 0.9935\n",
      "Epoch 348/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0174 - accuracy: 0.9936\n",
      "Epoch 349/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9937\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.0075 - val_accuracy: 0.9960 - rmse: 0.0974\n",
      "Epoch 350/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0178 - accuracy: 0.9935\n",
      "Epoch 351/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0170 - accuracy: 0.9935\n",
      "Epoch 352/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9934\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 0.0060 - val_accuracy: 0.9969 - rmse: 0.0828\n",
      "Epoch 353/400\n",
      "1145/1145 [==============================] - 34s 29ms/step - loss: 0.0157 - accuracy: 0.9943\n",
      "Epoch 354/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0180 - accuracy: 0.9939\n",
      "Epoch 355/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9932\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 33ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.0054 - val_accuracy: 0.9972 - rmse: 0.0869\n",
      "Epoch 356/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0180 - accuracy: 0.9935\n",
      "Epoch 357/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0167 - accuracy: 0.9938\n",
      "Epoch 358/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9938\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.0088 - val_accuracy: 0.9958 - rmse: 0.0971\n",
      "Epoch 359/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0185 - accuracy: 0.9934\n",
      "Epoch 360/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0161 - accuracy: 0.9938\n",
      "Epoch 361/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9946\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0057 - val_accuracy: 0.9971 - rmse: 0.0918\n",
      "Epoch 362/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0184 - accuracy: 0.9935\n",
      "Epoch 363/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0172 - accuracy: 0.9938\n",
      "Epoch 364/400\n",
      "1144/1145 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9938\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0063 - val_accuracy: 0.9970 - rmse: 0.0785\n",
      "Epoch 365/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0161 - accuracy: 0.9942\n",
      "Epoch 366/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0156 - accuracy: 0.9945\n",
      "Epoch 367/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9940\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0166 - accuracy: 0.9939 - val_loss: 0.0062 - val_accuracy: 0.9971 - rmse: 0.0835\n",
      "Epoch 368/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0179 - accuracy: 0.9937\n",
      "Epoch 369/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 370/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9940\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.0071 - val_accuracy: 0.9966 - rmse: 0.0867\n",
      "Epoch 371/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0165 - accuracy: 0.9941\n",
      "Epoch 372/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0169 - accuracy: 0.9941\n",
      "Epoch 373/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9933\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0137 - val_accuracy: 0.9948 - rmse: 0.1016\n",
      "Epoch 374/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0176 - accuracy: 0.9933\n",
      "Epoch 375/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0164 - accuracy: 0.9938\n",
      "Epoch 376/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9943\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.0099 - val_accuracy: 0.9971 - rmse: 0.0880\n",
      "Epoch 377/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0161 - accuracy: 0.9941\n",
      "Epoch 378/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 379/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9943\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.0072 - val_accuracy: 0.9965 - rmse: 0.0935\n",
      "Epoch 380/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "Epoch 381/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0166 - accuracy: 0.9941\n",
      "Epoch 382/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9943\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.0072 - val_accuracy: 0.9961 - rmse: 0.0950\n",
      "Epoch 383/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0187 - accuracy: 0.9932\n",
      "Epoch 384/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0166 - accuracy: 0.9941\n",
      "Epoch 385/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9939\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.0064 - val_accuracy: 0.9965 - rmse: 0.0960\n",
      "Epoch 386/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0169 - accuracy: 0.9940\n",
      "Epoch 387/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0163 - accuracy: 0.9938\n",
      "Epoch 388/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9937\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.0061 - val_accuracy: 0.9973 - rmse: 0.0837\n",
      "Epoch 389/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0153 - accuracy: 0.9945\n",
      "Epoch 390/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0180 - accuracy: 0.9938\n",
      "Epoch 391/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9942\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.0062 - val_accuracy: 0.9964 - rmse: 0.0958\n",
      "Epoch 392/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0157 - accuracy: 0.9942\n",
      "Epoch 393/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0170 - accuracy: 0.9940\n",
      "Epoch 394/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9943\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0150 - accuracy: 0.9943 - val_loss: 0.0061 - val_accuracy: 0.9973 - rmse: 0.0834\n",
      "Epoch 395/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0160 - accuracy: 0.9941\n",
      "Epoch 396/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0166 - accuracy: 0.9943\n",
      "Epoch 397/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9942\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.0068 - val_accuracy: 0.9970 - rmse: 0.0906\n",
      "Epoch 398/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0161 - accuracy: 0.9941\n",
      "Epoch 399/400\n",
      "1145/1145 [==============================] - 33s 29ms/step - loss: 0.0155 - accuracy: 0.9943\n",
      "Epoch 400/400\n",
      "1143/1145 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9943\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1145/1145 [==============================] - 37s 32ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.0064 - val_accuracy: 0.9968 - rmse: 0.0944\n",
      "Time taken to clear 400 epochs: 14357.512730121613\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trg_results3 = mpri_model3.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae25cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss3 = trg_results3.history['loss']\n",
    "loss3 = [v for i,v in enumerate(loss3) if i % 3 == 0]\n",
    "acc3 = trg_results3.history['accuracy']\n",
    "acc3 = [v for i,v in enumerate(acc3) if i % 3 == 0]\n",
    "val_loss3 = trg_results3.history['val_loss']\n",
    "val_acc3 = trg_results3.history['val_accuracy']\n",
    "rmse3 = trg_results3.history['rmse']\n",
    "epochs3 = [i for i in range(len(rmse3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa0b561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "fig, axs = plt.subplots(1,3)\n",
    "\n",
    "axs[0].plot(epochs3, loss3, color='teal', label='trg_loss')\n",
    "axs[0].plot(epochs3, val_loss3, color='orange', label='val_loss')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[0].set_title('Loss', fontsize=20)\n",
    "\n",
    "axs[1].plot(epochs3, acc3, color='teal', label='acc')\n",
    "axs[1].plot(epochs3, val_acc3, color='orange', label='val_acc')\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].set_title('Accuracy', fontsize=20)\n",
    "\n",
    "axs[2].plot(epochs3, rmse3, color='teal', label='rmse')\n",
    "axs[2].legend(loc='upper left')\n",
    "axs[2].set_title('RMSE', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99ec367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum loss: 0.004207423888146877\n",
      "Best Epoch no: 115\n",
      "Best val loss: 0.004207423888146877, Best val acc: 0.997993528842926\n",
      "Best trg loss: 0.01822560839354992, Best trg acc: 0.9933110475540161\n"
     ]
    }
   ],
   "source": [
    "val_loss3= np.array(val_loss3)\n",
    "print(f'Minimum loss: {val_loss3.min()}')\n",
    "best_epoch3= np.where(val_loss3== val_loss3.min())[0][0]\n",
    "\n",
    "print(f'Best Epoch no: {best_epoch3}')\n",
    "print(f'Best val loss: {val_loss3[best_epoch3]}, Best val acc: {val_acc3[best_epoch3]}')\n",
    "print(f'Best trg loss: {loss3[best_epoch3]}, Best trg acc: {acc3[best_epoch3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d703f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest error: 2.0615528128088303, Actual RP index: 2028, Predicted RP index: 94\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "rmse3, dist_errors3, cdf_vals3 = mpri_model3.test_model(\"mpri_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f796575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "plt.plot(dist_errors3, cdf_vals3, marker='o')\n",
    "plt.xlabel('Distance Error(m)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Probability Function')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "944a89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         ... 2.06155281 2.06155281 2.06155281]\n",
      "[4.77760260e-05 9.55520520e-05 1.43328078e-04 ... 9.99904448e-01\n",
      " 9.99952224e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Save sorted values and cdf_values into a file\n",
    "print(dist_errors3)\n",
    "print(cdf_vals3)\n",
    "\n",
    "mpri_dist_errors = np.array(dist_errors3)\n",
    "mpri_cdf_vals = np.array(cdf_vals3)\n",
    "\n",
    "np.save('mpri_sorted_errors.npy', mpri_dist_errors)\n",
    "np.save('mpri_cdf_vals', mpri_cdf_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b58ed212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08394619606359972\n"
     ]
    }
   ],
   "source": [
    "print(rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "becff5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 3s 9ms/step - loss: 0.0055 - accuracy: 0.9971\n",
      " Test loss: 0.0054504708386957645, Test Accuracy: 0.997085690498352\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy\n",
    "test_loss, test_acc = mpri_model3.eval_model(\"mpri_model3.h5\")\n",
    "print(f' Test loss: {test_loss}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3117bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
