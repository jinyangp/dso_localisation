{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af39e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "# Configure amd test GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Prevent automatic GPU memory pre-allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(tf.__version__)\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8aa097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole network composed of 63 layers, approximately 2.6m total no. of parameters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPool2D,\\\n",
    "                                    GlobalAvgPool2D, Dense, Add, Concatenate, Input,\\\n",
    "                                    Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Note: tf version 2.9.1 does not have Identity layer. Implement our own identity layer which is argument insensitive\n",
    "# and returns its inputs argument as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1295e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpriupperhalf_convno, batch_no, pooling_dropout, output_convno,\n",
    "# fc_dropout, lr, l2_conv2d\n",
    "def input_module(x):\n",
    "\n",
    "    # Set no. of filters to 256 to match the output of Add layer at the end of\n",
    "    # upper half of MPRI module\n",
    "    x = Conv2D(filters = 256, kernel_size = 3, strides = 1,\n",
    "               padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Normally, strides = 2 to reduce dimensions but set strides =1 for now to match\n",
    "    # output shapes\n",
    "    x = MaxPool2D(pool_size= 3, strides = 2, padding = 'same')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def mpri_upperhalf(x):\n",
    "\n",
    "    # Save input as another variable since need to add input of mpri\n",
    "    # with output of mpri\n",
    "    input_tensor = x\n",
    "\n",
    "    # Bottleneck layer with 1x1 conv filter\n",
    "    bottlenecked_tensor = Conv2D(filters = 128, kernel_size = 1, strides = 1,\n",
    "                                 padding = 'same')(x)\n",
    "\n",
    "    # First path\n",
    "    firstpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    firstpath_tensor = ReLU()(firstpath_tensor)\n",
    "    firstpath_tensor = Conv2D(filters = 64, kernel_size = 1, strides = 1,\n",
    "                              padding = 'same')(firstpath_tensor)\n",
    "\n",
    "    # Second path\n",
    "    secondpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    secondpath_tensor = ReLU()(secondpath_tensor)\n",
    "    secondpath_tensor = Conv2D(filters = 32, kernel_size = (5,1), strides = 1,\n",
    "                               padding = 'same')(secondpath_tensor)\n",
    "    secondpath_tensor = Conv2D(filters = 32, kernel_size = (1,3), strides = 1,\n",
    "                               padding = 'same')(secondpath_tensor)\n",
    "\n",
    "    # Third path\n",
    "    # Normally, strides = 2 to reduce the dimensions of the input\n",
    "    # In this case, experiment with strides = 1 to fit desired output shape for concatenation layer\n",
    "    thirdpath_tensor = MaxPool2D(pool_size = 3, strides = 1, padding = 'same')(bottlenecked_tensor)\n",
    "    thirdpath_tensor = BatchNormalization()(thirdpath_tensor)\n",
    "    thirdpath_tensor = ReLU()(thirdpath_tensor)\n",
    "    thirdpath_tensor = Conv2D(filters = 32, kernel_size = 3, strides = 1,\n",
    "                              padding = 'same')(thirdpath_tensor)\n",
    "\n",
    "    # Fourth path\n",
    "    fourthpath_tensor = BatchNormalization()(bottlenecked_tensor)\n",
    "    fourthpath_tensor = ReLU()(fourthpath_tensor)\n",
    "    fourthpath_tensor = Conv2D(filters = 32, kernel_size = 1, strides = 1,\n",
    "                               padding = 'same')(fourthpath_tensor)\n",
    "\n",
    "    fourthpath_tensor = BatchNormalization()(fourthpath_tensor)\n",
    "    fourthpath_tensor = ReLU()(fourthpath_tensor)\n",
    "    fourthpath_tensor = Conv2D(filters = 128, kernel_size = 1, strides = 1,\n",
    "                               padding = 'same')(fourthpath_tensor)\n",
    "\n",
    "    # Depth concatenate the output from the four paths\n",
    "    concatenated_tensor = Concatenate()([firstpath_tensor, secondpath_tensor, thirdpath_tensor, fourthpath_tensor])\n",
    "\n",
    "    # Add the depth concatenated layer and input tensor\n",
    "    # To add successfully, input tensor must have 256 channels as well to match the shape of\n",
    "    # the concatenated tensor\n",
    "    output_tensor = Add()([input_tensor, concatenated_tensor])\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "def mpri_lowerhalf(x):\n",
    "\n",
    "    def conv3x3_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 3, strides = 1,\n",
    "                   padding = 'same')(x)\n",
    "        return x\n",
    "\n",
    "    def conv1x1_block(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 1, strides = 1,\n",
    "                   padding = 'same')(x)\n",
    "        return x\n",
    "\n",
    "    # --- First layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # --- Second layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(upperpath_tensor)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(lowerpath_tensor)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # --- Third layer ---\n",
    "    upperpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(upperpath_tensor)\n",
    "    upperpath_tensor = conv3x3_block(upperpath_pooledtensor)\n",
    "\n",
    "    lowerpath_pooledtensor = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(lowerpath_tensor)\n",
    "    lowerpath_tensor = conv1x1_block(lowerpath_pooledtensor)\n",
    "\n",
    "    upperpath_tensor = Add()([upperpath_pooledtensor, upperpath_tensor, lowerpath_tensor])\n",
    "    lowerpath_tensor = Add()([lowerpath_pooledtensor, lowerpath_tensor, upperpath_tensor])\n",
    "\n",
    "    # Final layer - Add upper and lower path tensors\n",
    "    output_tensor = Add()([upperpath_tensor, lowerpath_tensor])\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "def output_module(x, num_classes = 1000):\n",
    "\n",
    "    x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    x = Dropout(rate = 0.5)(x)\n",
    "    x = Dense(units = num_classes, activation = 'softmax')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2c82cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/mpri\n",
      "/home/jovyan/committed_git/datasets\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../datasets')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ae9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Get dictionary of RP index and coordinates\n",
    "# Open HDF5 file and access the dataset\n",
    "filename = 'dataset_SNR10_outdoor.mat'\n",
    "hdf5_file = h5py.File(filename, 'r')\n",
    "\n",
    "features_dataset = hdf5_file['features']\n",
    "labels_dataset = hdf5_file['labels']['position']\n",
    "\n",
    "# Convert HDF5 dataset to NumPy array\n",
    "features = np.array(features_dataset)\n",
    "labels = np.array(labels_dataset)\n",
    "\n",
    "# Prepare features for dataset\n",
    "# Retrieve features from the first UE and transpose the individual matrix\n",
    "features_transposed = np.zeros((3876,193,16), dtype = np.float64)\n",
    "for i in range(len(features)):\n",
    "    features_transposed[i] = features[i][0].T\n",
    "\n",
    "# Prepare labels for dataset\n",
    "count = 0\n",
    "rp_dict = {}\n",
    "# For labels, have a shape of (1,) where that number represents the class of that coordinate\n",
    "\n",
    "for label in labels:\n",
    "    rp_dict[count] = label\n",
    "    count += 1\n",
    "\n",
    "# Close the HDF5 file\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3270c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features np array: (89628, 193, 16)\n",
      "Shape of labels np array: (89628,)\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "features = np.load('augmented_features_10_ue1_v2_ds.npy')\n",
    "labels = np.load('augmented_labels_10_ue1_v2_ds.npy')\n",
    "\n",
    "print(f'Shape of features np array: {features.shape}')\n",
    "print(f'Shape of labels np array: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60be358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5a713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/datasets\n",
      "/home/jovyan/committed_git/mpri\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../mpri')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44b1516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom callbacks to evaluate model\n",
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, X_val, Y_val, cur_val_loss, val_loss_threshold):\n",
    "        super(ValidationCallback,self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.cur_val_loss = cur_val_loss\n",
    "        self.val_loss_threshold = val_loss_threshold\n",
    "        \n",
    "    # number_of_iterations = total_number_of_training_examples / batch_size\n",
    "    # In this case, train example of 1,000 and batch size of 100\n",
    "    # number_of_iterations over 1 epoch is 10\n",
    "    # if have 5 epochs, number of iterations is 50\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "        x_error = (actual[0] - predicted[0])**2\n",
    "        y_error = (actual[1] - predicted[1])**2\n",
    "        z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "        return x_error + y_error + z_error\n",
    "        \n",
    "    # Have one function that reports metrics on end of every epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \n",
    "        # Get evaluation metrics\n",
    "        print('\\n')\n",
    "        print('Epoch End - Custom Validation Callback')\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.X_val, self.Y_val, verbose = 0)\n",
    "        \n",
    "        # Get distance error metrics - RMSE\n",
    "        # Get predictions for each feature heatmap in X_val\n",
    "        Y_pred = self.model.predict(self.X_val, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(self.X_val)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[self.Y_val[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(Y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            err_sum += err\n",
    "        rmse = np.sqrt((err_sum/len(self.X_val)))\n",
    "       \n",
    "        # Save values to log\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['val_accuracy'] = val_accuracy\n",
    "        logs['rmse'] = rmse\n",
    "        \n",
    "        # Whenever validation loss is minimised and below threshold, save the model\n",
    "        # and update current minimum loss\n",
    "        if val_loss < self.cur_val_loss and val_loss < self.val_loss_threshold:\n",
    "            self.model.save('mpri_model.h5')\n",
    "            self.cur_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bcc03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but removed early stopping callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import time\n",
    "\n",
    "class MPRI_model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        model_input = Input(shape = (193,16,1))\n",
    "        model_output = output_module(mpri_lowerhalf(mpri_upperhalf(input_module(model_input))), num_classes = 3876)\n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                      loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train_model(self):\n",
    "    \n",
    "        # In training, use model.fit() validation callback to get results on training loss, training accuracy,\n",
    "        # validation loss and validation accuracy and rmse after every epoch\n",
    "        val_callback = ValidationCallback(X_test, y_test, math.inf, 1)\n",
    "        \n",
    "        # Can leave out early stopping for now, manually observe when val_loss stops improving to determine\n",
    "        # optimal number of epochs\n",
    "        \n",
    "        # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        start_time = time.time()\n",
    "        hist = self.model.fit(X_train, y_train,\n",
    "                              epochs = 100,\n",
    "                              batch_size = 64,\n",
    "                              callbacks = [val_callback]\n",
    "#                              callbacks = [val_callback, stop_early]\n",
    "                             )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'Time taken to clear 100 epochs: {end_time - start_time}')\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "            x_error = (actual[0] - predicted[0])**2\n",
    "            y_error = (actual[1] - predicted[1])**2\n",
    "            z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "            return x_error + y_error + z_error\n",
    "    \n",
    "    def calc_errorcdf(self, errors):\n",
    "        \n",
    "        # Sort the array\n",
    "        sorted_data = np.sort(errors)\n",
    "\n",
    "        # Calculate cumulative probabilities\n",
    "        n = len(sorted_data)\n",
    "        cumulative_probs = np.arange(1, n + 1) / n\n",
    "    \n",
    "        return (sorted_data, cumulative_probs)\n",
    "        \n",
    "    def test_model(self, filename):\n",
    "        \n",
    "        # Load model\n",
    "        self.model = keras.models.load_model(filename)\n",
    "        \n",
    "        # In test, use model.predict() to get the RMSE errors of predictions and CDF of distance error\n",
    "        y_pred = self.model.predict(X_test, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        dist_errors = []\n",
    "        max_disterror = -math.inf\n",
    "        max_disterror_actual, max_disterror_pred = None, None\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(X_test)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[y_test[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            \n",
    "            # Update the maximum errror, if needed\n",
    "            dist_err = np.sqrt(err)\n",
    "            if dist_err > max_disterror:\n",
    "                \n",
    "                # Update max error\n",
    "                max_disterror = dist_err\n",
    "                \n",
    "                # Return the class index and then retrieve actual coordinates from rp_dict\n",
    "                max_disterror_actual = y_test[i]\n",
    "                max_disterror_pred = predicted_rp\n",
    "            \n",
    "            # Append error to distance errors\n",
    "            dist_errors.append(dist_err)\n",
    "            err_sum += err\n",
    "            \n",
    "        # Get RMSE of all predicted points\n",
    "        rmse = np.sqrt((err_sum/len(X_test)))\n",
    "        \n",
    "        # Get actual and predicted point with the largest error\n",
    "        print(f'Largest error: {max_disterror}, Actual RP index: {max_disterror_actual}, Predicted RP index: {max_disterror_pred}')\n",
    "        \n",
    "        return (rmse, *self.calc_errorcdf(dist_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da0ad7e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 193, 16, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 193, 16, 256  2560        ['input_6[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 193, 16, 256  1024       ['conv2d_75[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 193, 16, 256  0           ['batch_normalization_65[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_40 (MaxPooling2D  (None, 97, 8, 256)  0           ['re_lu_65[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 97, 8, 128)   32896       ['max_pooling2d_40[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 97, 8, 128)  512         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 97, 8, 128)  512         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_41 (MaxPooling2D  (None, 97, 8, 128)  0           ['conv2d_76[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 97, 8, 32)    4128        ['re_lu_69[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 97, 8, 128)  512         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 97, 8, 128)  512         ['max_pooling2d_41[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 97, 8, 32)   128         ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 97, 8, 32)    20512       ['re_lu_67[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 97, 8, 128)   0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 97, 8, 32)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 97, 8, 64)    8256        ['re_lu_66[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 97, 8, 32)    3104        ['conv2d_78[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 97, 8, 32)    36896       ['re_lu_68[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 97, 8, 128)   4224        ['re_lu_70[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 97, 8, 256)   0           ['conv2d_77[0][0]',              \n",
      "                                                                  'conv2d_79[0][0]',              \n",
      "                                                                  'conv2d_80[0][0]',              \n",
      "                                                                  'conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 97, 8, 256)   0           ['max_pooling2d_40[0][0]',       \n",
      "                                                                  'concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_42 (MaxPooling2D  (None, 49, 4, 256)  0           ['add_40[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_43 (MaxPooling2D  (None, 49, 4, 256)  0           ['add_40[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 49, 4, 256)  1024        ['max_pooling2d_42[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 49, 4, 256)  1024        ['max_pooling2d_43[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)                (None, 49, 4, 256)   0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)                (None, 49, 4, 256)   0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 49, 4, 256)   590080      ['re_lu_71[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 49, 4, 256)   65792       ['re_lu_72[0][0]']               \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 49, 4, 256)   0           ['max_pooling2d_42[0][0]',       \n",
      "                                                                  'conv2d_83[0][0]',              \n",
      "                                                                  'conv2d_84[0][0]']              \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 49, 4, 256)   0           ['max_pooling2d_43[0][0]',       \n",
      "                                                                  'conv2d_84[0][0]',              \n",
      "                                                                  'add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_44 (MaxPooling2D  (None, 25, 2, 256)  0           ['add_41[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_45 (MaxPooling2D  (None, 25, 2, 256)  0           ['add_42[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 25, 2, 256)  1024        ['max_pooling2d_44[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 25, 2, 256)  1024        ['max_pooling2d_45[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)                (None, 25, 2, 256)   0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)                (None, 25, 2, 256)   0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 25, 2, 256)   590080      ['re_lu_73[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 25, 2, 256)   65792       ['re_lu_74[0][0]']               \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 25, 2, 256)   0           ['max_pooling2d_44[0][0]',       \n",
      "                                                                  'conv2d_85[0][0]',              \n",
      "                                                                  'conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 25, 2, 256)   0           ['max_pooling2d_45[0][0]',       \n",
      "                                                                  'conv2d_86[0][0]',              \n",
      "                                                                  'add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_46 (MaxPooling2D  (None, 13, 1, 256)  0           ['add_43[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_47 (MaxPooling2D  (None, 13, 1, 256)  0           ['add_44[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_46[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_47[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 13, 1, 256)   590080      ['re_lu_75[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 13, 1, 256)   65792       ['re_lu_76[0][0]']               \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 13, 1, 256)   0           ['max_pooling2d_46[0][0]',       \n",
      "                                                                  'conv2d_87[0][0]',              \n",
      "                                                                  'conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 13, 1, 256)   0           ['max_pooling2d_47[0][0]',       \n",
      "                                                                  'conv2d_88[0][0]',              \n",
      "                                                                  'add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 13, 1, 256)   0           ['add_45[0][0]',                 \n",
      "                                                                  'add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 13, 1, 128)   295040      ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 13, 1, 128)  512         ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 13, 1, 128)   0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['re_lu_77[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128)          0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 3876)         500004      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,885,092\n",
      "Trainable params: 2,880,164\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 7.6947 - accuracy: 0.0030\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 40s 35ms/step - loss: 7.6947 - accuracy: 0.0030 - val_loss: 7.1314 - val_accuracy: 0.0099 - rmse: 7.1105\n",
      "Epoch 2/100\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 6.6030 - accuracy: 0.0201\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 6.6030 - accuracy: 0.0201 - val_loss: 5.9425 - val_accuracy: 0.0406 - rmse: 5.4641\n",
      "Epoch 3/100\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 5.5298 - accuracy: 0.0691\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 5.5298 - accuracy: 0.0691 - val_loss: 4.8031 - val_accuracy: 0.1623 - rmse: 4.4739\n",
      "Epoch 4/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 4.5058 - accuracy: 0.1605\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 4.5053 - accuracy: 0.1606 - val_loss: 3.8132 - val_accuracy: 0.3289 - rmse: 3.4343\n",
      "Epoch 5/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 3.6416 - accuracy: 0.2742\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 3.6413 - accuracy: 0.2742 - val_loss: 2.9217 - val_accuracy: 0.4833 - rmse: 2.4782\n",
      "Epoch 6/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.9934 - accuracy: 0.3720\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 2.9933 - accuracy: 0.3721 - val_loss: 2.4609 - val_accuracy: 0.5928 - rmse: 2.0282\n",
      "Epoch 7/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.5115 - accuracy: 0.4513\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.5114 - accuracy: 0.4512 - val_loss: 1.9887 - val_accuracy: 0.6761 - rmse: 1.6841\n",
      "Epoch 8/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.1537 - accuracy: 0.5170\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.1536 - accuracy: 0.5170 - val_loss: 1.7851 - val_accuracy: 0.6719 - rmse: 1.5845\n",
      "Epoch 9/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.8775 - accuracy: 0.5672\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 1.8775 - accuracy: 0.5673 - val_loss: 1.4874 - val_accuracy: 0.7463 - rmse: 1.3549\n",
      "Epoch 10/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.6659 - accuracy: 0.6045\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.6655 - accuracy: 0.6046 - val_loss: 1.3064 - val_accuracy: 0.7902 - rmse: 1.2555\n",
      "Epoch 11/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.4888 - accuracy: 0.6378\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.4888 - accuracy: 0.6378 - val_loss: 1.2183 - val_accuracy: 0.7522 - rmse: 1.2638\n",
      "Epoch 12/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.3497 - accuracy: 0.6615\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.3497 - accuracy: 0.6615 - val_loss: 1.0611 - val_accuracy: 0.8112 - rmse: 1.0999\n",
      "Epoch 13/100\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 1.2320 - accuracy: 0.6875\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.2321 - accuracy: 0.6875 - val_loss: 0.9739 - val_accuracy: 0.8207 - rmse: 1.0687\n",
      "Epoch 14/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.1322 - accuracy: 0.7086\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.1323 - accuracy: 0.7086 - val_loss: 0.8894 - val_accuracy: 0.8415 - rmse: 0.9647\n",
      "Epoch 15/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.0390 - accuracy: 0.7292\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.0390 - accuracy: 0.7291 - val_loss: 0.8231 - val_accuracy: 0.8451 - rmse: 0.9031\n",
      "Epoch 16/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.9674 - accuracy: 0.7410\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.9673 - accuracy: 0.7410 - val_loss: 0.7453 - val_accuracy: 0.8676 - rmse: 0.8486\n",
      "Epoch 17/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8987 - accuracy: 0.7579\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8986 - accuracy: 0.7580 - val_loss: 0.7381 - val_accuracy: 0.8393 - rmse: 0.8629\n",
      "Epoch 18/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8415 - accuracy: 0.7693\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8414 - accuracy: 0.7694 - val_loss: 0.6548 - val_accuracy: 0.8775 - rmse: 0.7569\n",
      "Epoch 19/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7918 - accuracy: 0.7816\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7918 - accuracy: 0.7817 - val_loss: 0.6412 - val_accuracy: 0.8677 - rmse: 0.7567\n",
      "Epoch 20/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7428 - accuracy: 0.7921\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7427 - accuracy: 0.7920 - val_loss: 0.5734 - val_accuracy: 0.8940 - rmse: 0.7078\n",
      "Epoch 21/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.8037\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.7033 - accuracy: 0.8037 - val_loss: 0.6184 - val_accuracy: 0.8517 - rmse: 0.8543\n",
      "Epoch 22/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6668 - accuracy: 0.8119\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6669 - accuracy: 0.8119 - val_loss: 0.5314 - val_accuracy: 0.8950 - rmse: 0.6647\n",
      "Epoch 23/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6302 - accuracy: 0.8198\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6304 - accuracy: 0.8198 - val_loss: 0.5232 - val_accuracy: 0.8801 - rmse: 0.7258\n",
      "Epoch 24/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.8286\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5987 - accuracy: 0.8286 - val_loss: 0.4820 - val_accuracy: 0.8927 - rmse: 0.6486\n",
      "Epoch 25/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5686 - accuracy: 0.8353\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.5686 - accuracy: 0.8353 - val_loss: 0.5370 - val_accuracy: 0.8590 - rmse: 0.7572\n",
      "Epoch 26/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.8423\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5452 - accuracy: 0.8423 - val_loss: 0.4276 - val_accuracy: 0.9090 - rmse: 0.6334\n",
      "Epoch 27/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5203 - accuracy: 0.8478\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.5203 - accuracy: 0.8478 - val_loss: 0.4579 - val_accuracy: 0.8884 - rmse: 0.6762\n",
      "Epoch 28/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.8522\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.5005 - accuracy: 0.8522 - val_loss: 0.4493 - val_accuracy: 0.8869 - rmse: 0.6864\n",
      "Epoch 29/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4808 - accuracy: 0.8582\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4807 - accuracy: 0.8583 - val_loss: 0.3923 - val_accuracy: 0.9063 - rmse: 0.6018\n",
      "Epoch 30/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8631\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4630 - accuracy: 0.8631 - val_loss: 0.3623 - val_accuracy: 0.9218 - rmse: 0.5799\n",
      "Epoch 31/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4461 - accuracy: 0.8665\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.4460 - accuracy: 0.8666 - val_loss: 0.4222 - val_accuracy: 0.8829 - rmse: 0.6421\n",
      "Epoch 32/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8708\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.4286 - accuracy: 0.8708 - val_loss: 0.3648 - val_accuracy: 0.9126 - rmse: 0.5745\n",
      "Epoch 33/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8742\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.4161 - accuracy: 0.8743 - val_loss: 0.3729 - val_accuracy: 0.9034 - rmse: 0.6016\n",
      "Epoch 34/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4001 - accuracy: 0.8787\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4002 - accuracy: 0.8787 - val_loss: 0.3167 - val_accuracy: 0.9314 - rmse: 0.5015\n",
      "Epoch 35/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8830\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3851 - accuracy: 0.8830 - val_loss: 0.3008 - val_accuracy: 0.9346 - rmse: 0.4954\n",
      "Epoch 36/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3748 - accuracy: 0.8850\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3748 - accuracy: 0.8849 - val_loss: 0.3185 - val_accuracy: 0.9246 - rmse: 0.5207\n",
      "Epoch 37/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.8882\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3653 - accuracy: 0.8882 - val_loss: 0.3126 - val_accuracy: 0.9240 - rmse: 0.5221\n",
      "Epoch 38/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8907\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3522 - accuracy: 0.8907 - val_loss: 0.2701 - val_accuracy: 0.9415 - rmse: 0.4853\n",
      "Epoch 39/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8953\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3433 - accuracy: 0.8952 - val_loss: 0.3017 - val_accuracy: 0.9215 - rmse: 0.5158\n",
      "Epoch 40/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8971\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3333 - accuracy: 0.8971 - val_loss: 0.2709 - val_accuracy: 0.9368 - rmse: 0.4909\n",
      "Epoch 41/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8988\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3260 - accuracy: 0.8987 - val_loss: 0.2903 - val_accuracy: 0.9254 - rmse: 0.5352\n",
      "Epoch 42/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9023\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3141 - accuracy: 0.9023 - val_loss: 0.2544 - val_accuracy: 0.9422 - rmse: 0.4611\n",
      "Epoch 43/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3042 - accuracy: 0.9047\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3043 - accuracy: 0.9047 - val_loss: 0.2722 - val_accuracy: 0.9300 - rmse: 0.4914\n",
      "Epoch 44/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.9059\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3016 - accuracy: 0.9060 - val_loss: 0.2452 - val_accuracy: 0.9423 - rmse: 0.4616\n",
      "Epoch 45/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2920 - accuracy: 0.9084\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2921 - accuracy: 0.9084 - val_loss: 0.2513 - val_accuracy: 0.9382 - rmse: 0.5007\n",
      "Epoch 46/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.9125\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2844 - accuracy: 0.9124 - val_loss: 0.2497 - val_accuracy: 0.9379 - rmse: 0.4828\n",
      "Epoch 47/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9125\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2778 - accuracy: 0.9124 - val_loss: 0.2432 - val_accuracy: 0.9399 - rmse: 0.4718\n",
      "Epoch 48/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2728 - accuracy: 0.9139\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2728 - accuracy: 0.9138 - val_loss: 0.2397 - val_accuracy: 0.9395 - rmse: 0.4640\n",
      "Epoch 49/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.9151\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2685 - accuracy: 0.9151 - val_loss: 0.2345 - val_accuracy: 0.9421 - rmse: 0.4395\n",
      "Epoch 50/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9191\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2563 - accuracy: 0.9191 - val_loss: 0.2354 - val_accuracy: 0.9423 - rmse: 0.4422\n",
      "Epoch 51/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9183\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2556 - accuracy: 0.9183 - val_loss: 0.2775 - val_accuracy: 0.9182 - rmse: 0.5205\n",
      "Epoch 52/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9188\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2508 - accuracy: 0.9188 - val_loss: 0.2497 - val_accuracy: 0.9316 - rmse: 0.5096\n",
      "Epoch 53/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.9212\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2447 - accuracy: 0.9212 - val_loss: 0.2200 - val_accuracy: 0.9442 - rmse: 0.4593\n",
      "Epoch 54/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9234\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2400 - accuracy: 0.9234 - val_loss: 0.2037 - val_accuracy: 0.9507 - rmse: 0.4318\n",
      "Epoch 55/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9241\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2347 - accuracy: 0.9240 - val_loss: 0.2267 - val_accuracy: 0.9390 - rmse: 0.4367\n",
      "Epoch 56/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9261\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2311 - accuracy: 0.9261 - val_loss: 0.2239 - val_accuracy: 0.9403 - rmse: 0.4922\n",
      "Epoch 57/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9256\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2282 - accuracy: 0.9256 - val_loss: 0.2059 - val_accuracy: 0.9483 - rmse: 0.4246\n",
      "Epoch 58/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9263\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2246 - accuracy: 0.9263 - val_loss: 0.2679 - val_accuracy: 0.9204 - rmse: 0.5392\n",
      "Epoch 59/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9283\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2191 - accuracy: 0.9283 - val_loss: 0.1911 - val_accuracy: 0.9519 - rmse: 0.4012\n",
      "Epoch 60/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.9297\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2150 - accuracy: 0.9296 - val_loss: 0.2087 - val_accuracy: 0.9468 - rmse: 0.4294\n",
      "Epoch 61/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9324\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2091 - accuracy: 0.9323 - val_loss: 0.2533 - val_accuracy: 0.9256 - rmse: 0.5217\n",
      "Epoch 62/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2104 - accuracy: 0.9315\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2105 - accuracy: 0.9315 - val_loss: 0.2023 - val_accuracy: 0.9478 - rmse: 0.4283\n",
      "Epoch 63/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2060 - accuracy: 0.9331\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2060 - accuracy: 0.9331 - val_loss: 0.2141 - val_accuracy: 0.9428 - rmse: 0.4673\n",
      "Epoch 64/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9359\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1992 - accuracy: 0.9358 - val_loss: 0.2296 - val_accuracy: 0.9352 - rmse: 0.4616\n",
      "Epoch 65/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2028 - accuracy: 0.9328\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2028 - accuracy: 0.9328 - val_loss: 0.2083 - val_accuracy: 0.9458 - rmse: 0.4500\n",
      "Epoch 66/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9369\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1935 - accuracy: 0.9369 - val_loss: 0.1811 - val_accuracy: 0.9552 - rmse: 0.4016\n",
      "Epoch 67/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9380\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1894 - accuracy: 0.9380 - val_loss: 0.1779 - val_accuracy: 0.9565 - rmse: 0.3817\n",
      "Epoch 68/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9373\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1890 - accuracy: 0.9374 - val_loss: 0.1852 - val_accuracy: 0.9524 - rmse: 0.4300\n",
      "Epoch 69/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9393\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1848 - accuracy: 0.9393 - val_loss: 0.1837 - val_accuracy: 0.9528 - rmse: 0.3819\n",
      "Epoch 70/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.9378\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1855 - accuracy: 0.9378 - val_loss: 0.1916 - val_accuracy: 0.9499 - rmse: 0.4441\n",
      "Epoch 71/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9412\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1782 - accuracy: 0.9411 - val_loss: 0.2234 - val_accuracy: 0.9342 - rmse: 0.4809\n",
      "Epoch 72/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9397\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1812 - accuracy: 0.9397 - val_loss: 0.1833 - val_accuracy: 0.9530 - rmse: 0.4029\n",
      "Epoch 73/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9426\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1741 - accuracy: 0.9426 - val_loss: 0.2088 - val_accuracy: 0.9428 - rmse: 0.4632\n",
      "Epoch 74/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9437\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1715 - accuracy: 0.9437 - val_loss: 0.1857 - val_accuracy: 0.9530 - rmse: 0.4307\n",
      "Epoch 75/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9429\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1728 - accuracy: 0.9429 - val_loss: 0.1785 - val_accuracy: 0.9535 - rmse: 0.4169\n",
      "Epoch 76/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9423\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1714 - accuracy: 0.9422 - val_loss: 0.1941 - val_accuracy: 0.9487 - rmse: 0.4238\n",
      "Epoch 77/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9431\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1670 - accuracy: 0.9431 - val_loss: 0.1775 - val_accuracy: 0.9546 - rmse: 0.4035\n",
      "Epoch 78/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9439\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1668 - accuracy: 0.9439 - val_loss: 0.1778 - val_accuracy: 0.9518 - rmse: 0.4063\n",
      "Epoch 79/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9461\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1610 - accuracy: 0.9462 - val_loss: 0.1682 - val_accuracy: 0.9584 - rmse: 0.3945\n",
      "Epoch 80/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9447\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1615 - accuracy: 0.9447 - val_loss: 0.1654 - val_accuracy: 0.9583 - rmse: 0.3952\n",
      "Epoch 81/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1590 - accuracy: 0.9466\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1590 - accuracy: 0.9466 - val_loss: 0.1650 - val_accuracy: 0.9602 - rmse: 0.3930\n",
      "Epoch 82/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9484\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1539 - accuracy: 0.9484 - val_loss: 0.1936 - val_accuracy: 0.9477 - rmse: 0.4410\n",
      "Epoch 83/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 0.9467\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1557 - accuracy: 0.9468 - val_loss: 0.1790 - val_accuracy: 0.9526 - rmse: 0.3896\n",
      "Epoch 84/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9480\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1544 - accuracy: 0.9481 - val_loss: 0.1992 - val_accuracy: 0.9447 - rmse: 0.4517\n",
      "Epoch 85/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9489\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1513 - accuracy: 0.9488 - val_loss: 0.1952 - val_accuracy: 0.9457 - rmse: 0.4399\n",
      "Epoch 86/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9502\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1496 - accuracy: 0.9502 - val_loss: 0.1710 - val_accuracy: 0.9551 - rmse: 0.3896\n",
      "Epoch 87/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9502\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1474 - accuracy: 0.9501 - val_loss: 0.2000 - val_accuracy: 0.9432 - rmse: 0.4305\n",
      "Epoch 88/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9519\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1436 - accuracy: 0.9518 - val_loss: 0.1594 - val_accuracy: 0.9601 - rmse: 0.3717\n",
      "Epoch 89/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.9511\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1447 - accuracy: 0.9511 - val_loss: 0.1802 - val_accuracy: 0.9515 - rmse: 0.4274\n",
      "Epoch 90/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9511\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1449 - accuracy: 0.9511 - val_loss: 0.1786 - val_accuracy: 0.9520 - rmse: 0.4010\n",
      "Epoch 91/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9512\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1435 - accuracy: 0.9512 - val_loss: 0.1737 - val_accuracy: 0.9552 - rmse: 0.4238\n",
      "Epoch 92/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9531\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1402 - accuracy: 0.9531 - val_loss: 0.1581 - val_accuracy: 0.9609 - rmse: 0.3826\n",
      "Epoch 93/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9537\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1374 - accuracy: 0.9537 - val_loss: 0.1693 - val_accuracy: 0.9546 - rmse: 0.4031\n",
      "Epoch 94/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9525\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1399 - accuracy: 0.9524 - val_loss: 0.1590 - val_accuracy: 0.9594 - rmse: 0.3776\n",
      "Epoch 95/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9553\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1335 - accuracy: 0.9553 - val_loss: 0.1666 - val_accuracy: 0.9562 - rmse: 0.3982\n",
      "Epoch 96/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9542\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1336 - accuracy: 0.9542 - val_loss: 0.1680 - val_accuracy: 0.9552 - rmse: 0.4208\n",
      "Epoch 97/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9549\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1317 - accuracy: 0.9549 - val_loss: 0.1590 - val_accuracy: 0.9597 - rmse: 0.3972\n",
      "Epoch 98/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9549\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1339 - accuracy: 0.9549 - val_loss: 0.1933 - val_accuracy: 0.9447 - rmse: 0.4278\n",
      "Epoch 99/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1292 - accuracy: 0.9568\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1292 - accuracy: 0.9568 - val_loss: 0.1552 - val_accuracy: 0.9621 - rmse: 0.3892\n",
      "Epoch 100/100\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9550\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1310 - accuracy: 0.9550 - val_loss: 0.1537 - val_accuracy: 0.9617 - rmse: 0.3747\n",
      "Time taken to clear 100 epochs: 3880.9592113494873\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "mpri_model = MPRI_model()\n",
    "trg_results = mpri_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4684186",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trg_results.history['loss']\n",
    "acc = trg_results.history['accuracy']\n",
    "val_loss = trg_results.history['val_loss']\n",
    "val_acc = trg_results.history['val_accuracy']\n",
    "rmse = trg_results.history['rmse']\n",
    "epochs = [i for i in range(len(rmse))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdc62fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "fig, axs = plt.subplots(1,3)\n",
    "\n",
    "axs[0].plot(epochs, loss, color='teal', label='trg_loss')\n",
    "axs[0].plot(epochs, val_loss, color='orange', label='val_loss')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[0].set_title('Loss', fontsize=20)\n",
    "\n",
    "axs[1].plot(epochs, acc, color='teal', label='acc')\n",
    "axs[1].plot(epochs, val_acc, color='orange', label='val_acc')\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].set_title('Accuracy', fontsize=20)\n",
    "\n",
    "axs[2].plot(epochs, rmse, color='teal', label='rmse')\n",
    "axs[2].legend(loc='upper left')\n",
    "axs[2].set_title('RMSE', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f949930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum loss: 0.15366923809051514\n",
      "Best Epoch no: 99\n",
      "Best val loss: 0.15366923809051514, Best val acc: 0.961675763130188\n",
      "Best trg loss: 0.1310051530599594, Best trg acc: 0.9550082087516785\n"
     ]
    }
   ],
   "source": [
    "val_loss = np.array(val_loss)\n",
    "print(f'Minimum loss: {val_loss.min()}')\n",
    "best_epoch = np.where(val_loss == val_loss.min())[0][0]\n",
    "\n",
    "print(f'Best Epoch no: {best_epoch}')\n",
    "print(f'Best val loss: {val_loss[best_epoch]}, Best val acc: {val_acc[best_epoch]}')\n",
    "print(f'Best trg loss: {loss[best_epoch]}, Best trg acc: {acc[best_epoch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ae5d1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest error: 8.139410298049853, Actual RP index: 1868, Predicted RP index: 1750\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "rmse, dist_errors, cdf_vals = mpri_model.test_model(\"mpri_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf165b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37467677319133735\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9456ca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "plt.plot(dist_errors, cdf_vals, marker='o')\n",
    "plt.xlabel('Distance Error(m)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Probability Function')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fe88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e64632a",
   "metadata": {},
   "source": [
    "## Repeat but with 400 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595174b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole network composed of 63 layers, approximately 2.6m total no. of parameters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPool2D,\\\n",
    "                                    GlobalAvgPool2D, Dense, Add, Concatenate, Input,\\\n",
    "                                    Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Note: tf version 2.9.1 does not have Identity layer. Implement our own identity layer which is argument insensitive\n",
    "# and returns its inputs argument as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe2cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom callbacks to evaluate model\n",
    "class ValidationCallback2(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, X_val, Y_val, cur_val_loss, val_loss_threshold):\n",
    "        super(ValidationCallback2,self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.cur_val_loss = cur_val_loss\n",
    "        self.val_loss_threshold = val_loss_threshold\n",
    "        \n",
    "    # number_of_iterations = total_number_of_training_examples / batch_size\n",
    "    # In this case, train example of 1,000 and batch size of 100\n",
    "    # number_of_iterations over 1 epoch is 10\n",
    "    # if have 5 epochs, number of iterations is 50\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "        x_error = (actual[0] - predicted[0])**2\n",
    "        y_error = (actual[1] - predicted[1])**2\n",
    "        z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "        return x_error + y_error + z_error\n",
    "        \n",
    "    # Have one function that reports metrics on end of every epoch\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \n",
    "        # Get evaluation metrics\n",
    "        print('\\n')\n",
    "        print('Epoch End - Custom Validation Callback')\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.X_val, self.Y_val, verbose = 0)\n",
    "        \n",
    "        # Get distance error metrics - RMSE\n",
    "        # Get predictions for each feature heatmap in X_val\n",
    "        Y_pred = self.model.predict(self.X_val, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(self.X_val)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[self.Y_val[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(Y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            err_sum += err\n",
    "        rmse = np.sqrt((err_sum/len(self.X_val)))\n",
    "       \n",
    "        # Save values to log\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['val_accuracy'] = val_accuracy\n",
    "        logs['rmse'] = rmse\n",
    "        \n",
    "        # Whenever validation loss is minimised and below threshold, save the model\n",
    "        # and update current minimum loss\n",
    "        if val_loss < self.cur_val_loss and val_loss < self.val_loss_threshold:\n",
    "            self.model.save('mpri_model2.h5')\n",
    "            self.cur_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd245b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but removed early stopping callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import time\n",
    "\n",
    "class MPRI_model2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        model_input = Input(shape = (193,16,1))\n",
    "        model_output = output_module(mpri_lowerhalf(mpri_upperhalf(input_module(model_input))), num_classes = 3876)\n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                      loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train_model(self):\n",
    "    \n",
    "        # In training, use model.fit() validation callback to get results on training loss, training accuracy,\n",
    "        # validation loss and validation accuracy and rmse after every epoch\n",
    "        val_callback = ValidationCallback2(X_test, y_test, math.inf, 1)\n",
    "        \n",
    "        # Can leave out early stopping for now, manually observe when val_loss stops improving to determine\n",
    "        # optimal number of epochs\n",
    "        \n",
    "        # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        start_time = time.time()\n",
    "        hist = self.model.fit(X_train, y_train,\n",
    "                              epochs = 400,\n",
    "                              batch_size = 64,\n",
    "                              callbacks = [val_callback]\n",
    "#                              callbacks = [val_callback, stop_early]\n",
    "                             )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'Time taken to clear 400 epochs: {end_time - start_time}')\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def calc_error(self, actual, predicted):\n",
    "\n",
    "            x_error = (actual[0] - predicted[0])**2\n",
    "            y_error = (actual[1] - predicted[1])**2\n",
    "            z_error = (actual[2] - predicted[2])**2\n",
    "\n",
    "            return x_error + y_error + z_error\n",
    "    \n",
    "    def calc_errorcdf(self, errors):\n",
    "        \n",
    "        # Sort the array\n",
    "        sorted_data = np.sort(errors)\n",
    "\n",
    "        # Calculate cumulative probabilities\n",
    "        n = len(sorted_data)\n",
    "        cumulative_probs = np.arange(1, n + 1) / n\n",
    "    \n",
    "        return (sorted_data, cumulative_probs)\n",
    "        \n",
    "    def test_model(self, filename):\n",
    "        \n",
    "        # Load model\n",
    "        self.model = keras.models.load_model(filename)\n",
    "        \n",
    "        # In test, use model.predict() to get the RMSE errors of predictions and CDF of distance error\n",
    "        y_pred = self.model.predict(X_test, verbose = 0)\n",
    "        err_sum = 0\n",
    "        \n",
    "        dist_errors = []\n",
    "        max_disterror = -math.inf\n",
    "        max_disterror_actual, max_disterror_pred = None, None\n",
    "        \n",
    "        # Iterate through actual and predicted to get distance error\n",
    "        for i in range(len(X_test)):\n",
    "\n",
    "            # Get the coordinates for actual y\n",
    "            actual_coords = rp_dict[y_test[i]]\n",
    "            \n",
    "            # Get the coordinates for predicted y\n",
    "            predicted_rp = np.argmax(y_pred[i])\n",
    "            pred_coords = rp_dict[predicted_rp]\n",
    "\n",
    "            # Calculate distance error\n",
    "            err = self.calc_error(actual_coords, pred_coords)\n",
    "            \n",
    "            # Update the maximum errror, if needed\n",
    "            dist_err = np.sqrt(err)\n",
    "            if dist_err > max_disterror:\n",
    "                \n",
    "                # Update max error\n",
    "                max_disterror = dist_err\n",
    "                \n",
    "                # Return the class index and then retrieve actual coordinates from rp_dict\n",
    "                max_disterror_actual = y_test[i]\n",
    "                max_disterror_pred = predicted_rp\n",
    "            \n",
    "            # Append error to distance errors\n",
    "            dist_errors.append(dist_err)\n",
    "            err_sum += err\n",
    "            \n",
    "        # Get RMSE of all predicted points\n",
    "        rmse = np.sqrt((err_sum/len(X_test)))\n",
    "        \n",
    "        # Get actual and predicted point with the largest error\n",
    "        print(f'Largest error: {max_disterror}, Actual RP index: {max_disterror_actual}, Predicted RP index: {max_disterror_pred}')\n",
    "        \n",
    "        return (rmse, *self.calc_errorcdf(dist_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a4151",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 05:13:31.420720: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-23 05:13:31.869698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 25091 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 193, 16, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 193, 16, 256  2560        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 193, 16, 256  1024       ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 193, 16, 256  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 97, 8, 256)   0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 97, 8, 128)   32896       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 97, 8, 128)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 97, 8, 32)    4128        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 97, 8, 128)  512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 97, 8, 128)  512         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 97, 8, 32)   128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 97, 8, 32)    20512       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 97, 8, 128)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 97, 8, 32)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 97, 8, 64)    8256        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 97, 8, 32)    3104        ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 97, 8, 32)    36896       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 97, 8, 128)   4224        ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 97, 8, 256)   0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 97, 8, 256)   0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 49, 4, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 49, 4, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 49, 4, 256)  1024        ['max_pooling2d_2[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 49, 4, 256)  1024        ['max_pooling2d_3[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 49, 4, 256)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 49, 4, 256)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 49, 4, 256)   590080      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 49, 4, 256)   65792       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 49, 4, 256)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 49, 4, 256)   0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 25, 2, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 25, 2, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 2, 256)  1024        ['max_pooling2d_4[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 25, 2, 256)  1024        ['max_pooling2d_5[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 25, 2, 256)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 25, 2, 256)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 2, 256)   590080      ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 2, 256)   65792       ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 25, 2, 256)   0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 25, 2, 256)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv2d_11[0][0]',              \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 13, 1, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 13, 1, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_6[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 13, 1, 256)  1024        ['max_pooling2d_7[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 13, 1, 256)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 13, 1, 256)   590080      ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 13, 1, 256)   65792       ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 13, 1, 256)   0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'conv2d_12[0][0]',              \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 13, 1, 256)   0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 13, 1, 256)   0           ['add_5[0][0]',                  \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 13, 1, 128)   295040      ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 13, 1, 128)  512         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 13, 1, 128)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['re_lu_12[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3876)         500004      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,885,092\n",
      "Trainable params: 2,880,164\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 05:13:35.132909: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-06-23 05:13:36.426460: I tensorflow/stream_executor/cuda/cuda_blas.cc:1804] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121/1121 [==============================] - ETA: 0s - loss: 7.7098 - accuracy: 0.0030\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 43s 35ms/step - loss: 7.7098 - accuracy: 0.0030 - val_loss: 7.1098 - val_accuracy: 0.0112 - rmse: 7.0570\n",
      "Epoch 2/400\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 6.6023 - accuracy: 0.0227\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 6.6023 - accuracy: 0.0227 - val_loss: 5.8694 - val_accuracy: 0.0534 - rmse: 5.4190\n",
      "Epoch 3/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 5.4616 - accuracy: 0.0771\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 5.4610 - accuracy: 0.0771 - val_loss: 4.7461 - val_accuracy: 0.1844 - rmse: 4.0368\n",
      "Epoch 4/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 4.4058 - accuracy: 0.1800\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 4.4057 - accuracy: 0.1799 - val_loss: 3.7035 - val_accuracy: 0.3452 - rmse: 3.2579\n",
      "Epoch 5/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 3.5564 - accuracy: 0.2867\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 3.5560 - accuracy: 0.2868 - val_loss: 2.8799 - val_accuracy: 0.5116 - rmse: 2.3137\n",
      "Epoch 6/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 2.9147 - accuracy: 0.3896\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 2.9146 - accuracy: 0.3896 - val_loss: 2.3210 - val_accuracy: 0.6074 - rmse: 2.0323\n",
      "Epoch 7/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.4490 - accuracy: 0.4680\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 38s 34ms/step - loss: 2.4488 - accuracy: 0.4680 - val_loss: 1.9495 - val_accuracy: 0.7070 - rmse: 1.7099\n",
      "Epoch 8/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 2.1101 - accuracy: 0.5286\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 2.1102 - accuracy: 0.5286 - val_loss: 1.6559 - val_accuracy: 0.7510 - rmse: 1.5864\n",
      "Epoch 9/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.8407 - accuracy: 0.5758\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.8406 - accuracy: 0.5759 - val_loss: 1.4614 - val_accuracy: 0.7465 - rmse: 1.5531\n",
      "Epoch 10/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.6339 - accuracy: 0.6118\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 1.6338 - accuracy: 0.6117 - val_loss: 1.2757 - val_accuracy: 0.8031 - rmse: 1.3759\n",
      "Epoch 11/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.4656 - accuracy: 0.6446\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.4657 - accuracy: 0.6446 - val_loss: 1.1410 - val_accuracy: 0.8263 - rmse: 1.2653\n",
      "Epoch 12/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.3258 - accuracy: 0.6722\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.3258 - accuracy: 0.6721 - val_loss: 1.0042 - val_accuracy: 0.8467 - rmse: 1.2385\n",
      "Epoch 13/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.2064 - accuracy: 0.6955\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.2065 - accuracy: 0.6956 - val_loss: 0.9387 - val_accuracy: 0.8435 - rmse: 1.0815\n",
      "Epoch 14/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.1059 - accuracy: 0.7172\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.1059 - accuracy: 0.7172 - val_loss: 0.8498 - val_accuracy: 0.8581 - rmse: 0.9971\n",
      "Epoch 15/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 1.0242 - accuracy: 0.7314\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 1.0244 - accuracy: 0.7313 - val_loss: 0.8166 - val_accuracy: 0.8492 - rmse: 0.9881\n",
      "Epoch 16/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.9501 - accuracy: 0.7480\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.9500 - accuracy: 0.7481 - val_loss: 0.7205 - val_accuracy: 0.8793 - rmse: 0.8611\n",
      "Epoch 17/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8854 - accuracy: 0.7611\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8856 - accuracy: 0.7611 - val_loss: 0.6712 - val_accuracy: 0.8870 - rmse: 0.7853\n",
      "Epoch 18/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.8255 - accuracy: 0.7759\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.8255 - accuracy: 0.7759 - val_loss: 0.6663 - val_accuracy: 0.8714 - rmse: 0.7921\n",
      "Epoch 19/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7741 - accuracy: 0.7878\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7743 - accuracy: 0.7877 - val_loss: 0.6189 - val_accuracy: 0.8774 - rmse: 0.7539\n",
      "Epoch 20/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.7248 - accuracy: 0.8013\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.7248 - accuracy: 0.8013 - val_loss: 0.5848 - val_accuracy: 0.8780 - rmse: 0.7276\n",
      "Epoch 21/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.6894 - accuracy: 0.8064\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6896 - accuracy: 0.8064 - val_loss: 0.6226 - val_accuracy: 0.8410 - rmse: 0.9131\n",
      "Epoch 22/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.6485 - accuracy: 0.8196\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6485 - accuracy: 0.8196 - val_loss: 0.5035 - val_accuracy: 0.9036 - rmse: 0.6472\n",
      "Epoch 23/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.6143 - accuracy: 0.8256\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.6143 - accuracy: 0.8256 - val_loss: 0.4845 - val_accuracy: 0.9049 - rmse: 0.6409\n",
      "Epoch 24/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.8339\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5823 - accuracy: 0.8339 - val_loss: 0.4749 - val_accuracy: 0.9058 - rmse: 0.6276\n",
      "Epoch 25/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.8409\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5581 - accuracy: 0.8409 - val_loss: 0.4316 - val_accuracy: 0.9145 - rmse: 0.5860\n",
      "Epoch 26/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.8452\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5342 - accuracy: 0.8453 - val_loss: 0.4120 - val_accuracy: 0.9165 - rmse: 0.5958\n",
      "Epoch 27/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.8503\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.5140 - accuracy: 0.8504 - val_loss: 0.3985 - val_accuracy: 0.9192 - rmse: 0.5512\n",
      "Epoch 28/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.4904 - accuracy: 0.8564\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4905 - accuracy: 0.8564 - val_loss: 0.3836 - val_accuracy: 0.9208 - rmse: 0.5745\n",
      "Epoch 29/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.8611\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4721 - accuracy: 0.8611 - val_loss: 0.3837 - val_accuracy: 0.9146 - rmse: 0.5993\n",
      "Epoch 30/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.8664\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4524 - accuracy: 0.8663 - val_loss: 0.3687 - val_accuracy: 0.9192 - rmse: 0.5687\n",
      "Epoch 31/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4329 - accuracy: 0.8700\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4329 - accuracy: 0.8700 - val_loss: 0.3524 - val_accuracy: 0.9215 - rmse: 0.5537\n",
      "Epoch 32/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8723\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4226 - accuracy: 0.8723 - val_loss: 0.3277 - val_accuracy: 0.9286 - rmse: 0.5250\n",
      "Epoch 33/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8796\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.4027 - accuracy: 0.8795 - val_loss: 0.3200 - val_accuracy: 0.9317 - rmse: 0.5076\n",
      "Epoch 34/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8822\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3903 - accuracy: 0.8822 - val_loss: 0.3090 - val_accuracy: 0.9316 - rmse: 0.5283\n",
      "Epoch 35/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.8856\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3760 - accuracy: 0.8856 - val_loss: 0.2974 - val_accuracy: 0.9355 - rmse: 0.5075\n",
      "Epoch 36/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3692 - accuracy: 0.8863\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3692 - accuracy: 0.8863 - val_loss: 0.3043 - val_accuracy: 0.9290 - rmse: 0.5219\n",
      "Epoch 37/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3538 - accuracy: 0.8924\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3537 - accuracy: 0.8924 - val_loss: 0.2747 - val_accuracy: 0.9434 - rmse: 0.4456\n",
      "Epoch 38/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8960\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3428 - accuracy: 0.8960 - val_loss: 0.2661 - val_accuracy: 0.9425 - rmse: 0.4521\n",
      "Epoch 39/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.8965\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3367 - accuracy: 0.8964 - val_loss: 0.2655 - val_accuracy: 0.9417 - rmse: 0.4355\n",
      "Epoch 40/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.8988\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3248 - accuracy: 0.8988 - val_loss: 0.2764 - val_accuracy: 0.9345 - rmse: 0.5160\n",
      "Epoch 41/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.9023\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3155 - accuracy: 0.9023 - val_loss: 0.2575 - val_accuracy: 0.9418 - rmse: 0.4725\n",
      "Epoch 42/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3083 - accuracy: 0.9041\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.3085 - accuracy: 0.9041 - val_loss: 0.2705 - val_accuracy: 0.9317 - rmse: 0.5247\n",
      "Epoch 43/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.3028 - accuracy: 0.9051\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.3028 - accuracy: 0.9051 - val_loss: 0.2516 - val_accuracy: 0.9405 - rmse: 0.4857\n",
      "Epoch 44/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2943 - accuracy: 0.9083\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2944 - accuracy: 0.9082 - val_loss: 0.2454 - val_accuracy: 0.9375 - rmse: 0.4659\n",
      "Epoch 45/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.9117\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2843 - accuracy: 0.9117 - val_loss: 0.2415 - val_accuracy: 0.9412 - rmse: 0.4624\n",
      "Epoch 46/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.2795 - accuracy: 0.9120\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2795 - accuracy: 0.9120 - val_loss: 0.2374 - val_accuracy: 0.9434 - rmse: 0.4424\n",
      "Epoch 47/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2705 - accuracy: 0.9146\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2705 - accuracy: 0.9146 - val_loss: 0.2241 - val_accuracy: 0.9482 - rmse: 0.4549\n",
      "Epoch 48/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.9157\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2668 - accuracy: 0.9157 - val_loss: 0.2231 - val_accuracy: 0.9465 - rmse: 0.4325\n",
      "Epoch 49/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9158\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2617 - accuracy: 0.9157 - val_loss: 0.2315 - val_accuracy: 0.9427 - rmse: 0.4648\n",
      "Epoch 50/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.9186\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2539 - accuracy: 0.9186 - val_loss: 0.2094 - val_accuracy: 0.9513 - rmse: 0.4122\n",
      "Epoch 51/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.9201\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 38s 34ms/step - loss: 0.2500 - accuracy: 0.9201 - val_loss: 0.2251 - val_accuracy: 0.9413 - rmse: 0.4468\n",
      "Epoch 52/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2437 - accuracy: 0.9224\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2438 - accuracy: 0.9224 - val_loss: 0.2198 - val_accuracy: 0.9472 - rmse: 0.4586\n",
      "Epoch 53/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.9218\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2394 - accuracy: 0.9219 - val_loss: 0.2038 - val_accuracy: 0.9512 - rmse: 0.4167\n",
      "Epoch 54/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9261\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2339 - accuracy: 0.9261 - val_loss: 0.2276 - val_accuracy: 0.9411 - rmse: 0.4822\n",
      "Epoch 55/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9245\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2329 - accuracy: 0.9245 - val_loss: 0.1897 - val_accuracy: 0.9577 - rmse: 0.3889\n",
      "Epoch 56/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2220 - accuracy: 0.9291\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2221 - accuracy: 0.9290 - val_loss: 0.2155 - val_accuracy: 0.9430 - rmse: 0.4724\n",
      "Epoch 57/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2226 - accuracy: 0.9271\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2226 - accuracy: 0.9270 - val_loss: 0.1971 - val_accuracy: 0.9531 - rmse: 0.3910\n",
      "Epoch 58/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.9283\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2213 - accuracy: 0.9283 - val_loss: 0.2010 - val_accuracy: 0.9511 - rmse: 0.3985\n",
      "Epoch 59/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9313\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2117 - accuracy: 0.9311 - val_loss: 0.1912 - val_accuracy: 0.9548 - rmse: 0.4074\n",
      "Epoch 60/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.9328\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.2076 - accuracy: 0.9327 - val_loss: 0.1911 - val_accuracy: 0.9533 - rmse: 0.3860\n",
      "Epoch 61/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9316\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2067 - accuracy: 0.9316 - val_loss: 0.2040 - val_accuracy: 0.9473 - rmse: 0.4459\n",
      "Epoch 62/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.2027 - accuracy: 0.9348\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.2027 - accuracy: 0.9348 - val_loss: 0.2071 - val_accuracy: 0.9443 - rmse: 0.4414\n",
      "Epoch 63/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1978 - accuracy: 0.9365\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1980 - accuracy: 0.9364 - val_loss: 0.1995 - val_accuracy: 0.9495 - rmse: 0.4529\n",
      "Epoch 64/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1949 - accuracy: 0.9372\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1951 - accuracy: 0.9371 - val_loss: 0.1885 - val_accuracy: 0.9548 - rmse: 0.4176\n",
      "Epoch 65/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9353\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1947 - accuracy: 0.9352 - val_loss: 0.1902 - val_accuracy: 0.9525 - rmse: 0.3923\n",
      "Epoch 66/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9371\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1905 - accuracy: 0.9371 - val_loss: 0.2205 - val_accuracy: 0.9398 - rmse: 0.4668\n",
      "Epoch 67/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9370\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1903 - accuracy: 0.9370 - val_loss: 0.1806 - val_accuracy: 0.9561 - rmse: 0.3983\n",
      "Epoch 68/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1846 - accuracy: 0.9399\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1847 - accuracy: 0.9398 - val_loss: 0.1850 - val_accuracy: 0.9521 - rmse: 0.4286\n",
      "Epoch 69/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1827 - accuracy: 0.9401\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1827 - accuracy: 0.9400 - val_loss: 0.1882 - val_accuracy: 0.9502 - rmse: 0.4297\n",
      "Epoch 70/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9401\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1803 - accuracy: 0.9401 - val_loss: 0.1808 - val_accuracy: 0.9533 - rmse: 0.4084\n",
      "Epoch 71/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9402\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1808 - accuracy: 0.9403 - val_loss: 0.1758 - val_accuracy: 0.9584 - rmse: 0.3939\n",
      "Epoch 72/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9426\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1739 - accuracy: 0.9426 - val_loss: 0.1706 - val_accuracy: 0.9598 - rmse: 0.3830\n",
      "Epoch 73/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9434\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1714 - accuracy: 0.9434 - val_loss: 0.1867 - val_accuracy: 0.9524 - rmse: 0.4402\n",
      "Epoch 74/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9430\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1711 - accuracy: 0.9430 - val_loss: 0.1959 - val_accuracy: 0.9482 - rmse: 0.4494\n",
      "Epoch 75/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9431\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1705 - accuracy: 0.9430 - val_loss: 0.1840 - val_accuracy: 0.9516 - rmse: 0.4096\n",
      "Epoch 76/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9458\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1643 - accuracy: 0.9459 - val_loss: 0.1812 - val_accuracy: 0.9528 - rmse: 0.4008\n",
      "Epoch 77/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9445\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1650 - accuracy: 0.9445 - val_loss: 0.1847 - val_accuracy: 0.9524 - rmse: 0.4143\n",
      "Epoch 78/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9462\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1616 - accuracy: 0.9461 - val_loss: 0.1653 - val_accuracy: 0.9592 - rmse: 0.3660\n",
      "Epoch 79/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9483\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1567 - accuracy: 0.9483 - val_loss: 0.1669 - val_accuracy: 0.9582 - rmse: 0.3764\n",
      "Epoch 80/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1598 - accuracy: 0.9450\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1599 - accuracy: 0.9450 - val_loss: 0.1765 - val_accuracy: 0.9547 - rmse: 0.3862\n",
      "Epoch 81/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9469\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1583 - accuracy: 0.9469 - val_loss: 0.1663 - val_accuracy: 0.9589 - rmse: 0.3687\n",
      "Epoch 82/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9475\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1538 - accuracy: 0.9475 - val_loss: 0.1636 - val_accuracy: 0.9619 - rmse: 0.3624\n",
      "Epoch 83/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9491\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1506 - accuracy: 0.9491 - val_loss: 0.1763 - val_accuracy: 0.9530 - rmse: 0.4079\n",
      "Epoch 84/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9495\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1509 - accuracy: 0.9494 - val_loss: 0.1727 - val_accuracy: 0.9551 - rmse: 0.4092\n",
      "Epoch 85/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9487\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1513 - accuracy: 0.9487 - val_loss: 0.1680 - val_accuracy: 0.9563 - rmse: 0.4156\n",
      "Epoch 86/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1485 - accuracy: 0.9499\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1487 - accuracy: 0.9499 - val_loss: 0.1722 - val_accuracy: 0.9550 - rmse: 0.4078\n",
      "Epoch 87/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9502\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1463 - accuracy: 0.9502 - val_loss: 0.1614 - val_accuracy: 0.9591 - rmse: 0.3970\n",
      "Epoch 88/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9521\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1442 - accuracy: 0.9521 - val_loss: 0.1764 - val_accuracy: 0.9542 - rmse: 0.3991\n",
      "Epoch 89/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1421 - accuracy: 0.9516\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1421 - accuracy: 0.9516 - val_loss: 0.1624 - val_accuracy: 0.9582 - rmse: 0.4109\n",
      "Epoch 90/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9529\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1404 - accuracy: 0.9529 - val_loss: 0.1667 - val_accuracy: 0.9575 - rmse: 0.3933\n",
      "Epoch 91/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.9536\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1389 - accuracy: 0.9535 - val_loss: 0.1685 - val_accuracy: 0.9574 - rmse: 0.3915\n",
      "Epoch 92/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9514\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1408 - accuracy: 0.9515 - val_loss: 0.1580 - val_accuracy: 0.9594 - rmse: 0.3855\n",
      "Epoch 93/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9535\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1367 - accuracy: 0.9536 - val_loss: 0.1546 - val_accuracy: 0.9637 - rmse: 0.3648\n",
      "Epoch 94/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9543\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1346 - accuracy: 0.9542 - val_loss: 0.1696 - val_accuracy: 0.9552 - rmse: 0.4088\n",
      "Epoch 95/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1313 - accuracy: 0.9548\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1313 - accuracy: 0.9548 - val_loss: 0.1555 - val_accuracy: 0.9616 - rmse: 0.3725\n",
      "Epoch 96/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 0.9554\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1329 - accuracy: 0.9554 - val_loss: 0.1523 - val_accuracy: 0.9630 - rmse: 0.3625\n",
      "Epoch 97/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9551\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1325 - accuracy: 0.9551 - val_loss: 0.1735 - val_accuracy: 0.9541 - rmse: 0.4305\n",
      "Epoch 98/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1313 - accuracy: 0.9555\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1313 - accuracy: 0.9555 - val_loss: 0.1687 - val_accuracy: 0.9571 - rmse: 0.4046\n",
      "Epoch 99/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1270 - accuracy: 0.9573\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1271 - accuracy: 0.9573 - val_loss: 0.1618 - val_accuracy: 0.9589 - rmse: 0.3843\n",
      "Epoch 100/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9571\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1269 - accuracy: 0.9571 - val_loss: 0.1578 - val_accuracy: 0.9599 - rmse: 0.3772\n",
      "Epoch 101/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9558\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1264 - accuracy: 0.9558 - val_loss: 0.1536 - val_accuracy: 0.9627 - rmse: 0.3682\n",
      "Epoch 102/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1260 - accuracy: 0.9567\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1260 - accuracy: 0.9567 - val_loss: 0.1609 - val_accuracy: 0.9588 - rmse: 0.3697\n",
      "Epoch 103/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9586\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1214 - accuracy: 0.9586 - val_loss: 0.1564 - val_accuracy: 0.9591 - rmse: 0.3924\n",
      "Epoch 104/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9574\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1245 - accuracy: 0.9574 - val_loss: 0.1529 - val_accuracy: 0.9619 - rmse: 0.3644\n",
      "Epoch 105/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9584\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1198 - accuracy: 0.9584 - val_loss: 0.1586 - val_accuracy: 0.9617 - rmse: 0.3586\n",
      "Epoch 106/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9580\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1214 - accuracy: 0.9580 - val_loss: 0.1589 - val_accuracy: 0.9599 - rmse: 0.3923\n",
      "Epoch 107/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9602\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1164 - accuracy: 0.9602 - val_loss: 0.1538 - val_accuracy: 0.9590 - rmse: 0.3693\n",
      "Epoch 108/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.9586\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1196 - accuracy: 0.9586 - val_loss: 0.1546 - val_accuracy: 0.9622 - rmse: 0.3658\n",
      "Epoch 109/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9595\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1171 - accuracy: 0.9595 - val_loss: 0.1609 - val_accuracy: 0.9574 - rmse: 0.4048\n",
      "Epoch 110/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9619\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1139 - accuracy: 0.9619 - val_loss: 0.1723 - val_accuracy: 0.9529 - rmse: 0.4040\n",
      "Epoch 111/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9614\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1151 - accuracy: 0.9614 - val_loss: 0.1471 - val_accuracy: 0.9642 - rmse: 0.3489\n",
      "Epoch 112/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9611\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1132 - accuracy: 0.9611 - val_loss: 0.1481 - val_accuracy: 0.9649 - rmse: 0.3568\n",
      "Epoch 113/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9611\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1127 - accuracy: 0.9610 - val_loss: 0.1624 - val_accuracy: 0.9585 - rmse: 0.3620\n",
      "Epoch 114/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.9620\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1114 - accuracy: 0.9620 - val_loss: 0.1660 - val_accuracy: 0.9574 - rmse: 0.4035\n",
      "Epoch 115/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1121 - accuracy: 0.9610\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1122 - accuracy: 0.9609 - val_loss: 0.1450 - val_accuracy: 0.9640 - rmse: 0.3488\n",
      "Epoch 116/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9618\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1110 - accuracy: 0.9618 - val_loss: 0.1721 - val_accuracy: 0.9556 - rmse: 0.4103\n",
      "Epoch 117/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9619\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1093 - accuracy: 0.9620 - val_loss: 0.1654 - val_accuracy: 0.9583 - rmse: 0.3666\n",
      "Epoch 118/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9618\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1094 - accuracy: 0.9618 - val_loss: 0.1541 - val_accuracy: 0.9606 - rmse: 0.3772\n",
      "Epoch 119/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9631\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1073 - accuracy: 0.9630 - val_loss: 0.1531 - val_accuracy: 0.9602 - rmse: 0.3934\n",
      "Epoch 120/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9642\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1052 - accuracy: 0.9641 - val_loss: 0.1446 - val_accuracy: 0.9634 - rmse: 0.3809\n",
      "Epoch 121/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9622\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1087 - accuracy: 0.9622 - val_loss: 0.1446 - val_accuracy: 0.9641 - rmse: 0.3600\n",
      "Epoch 122/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9627\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1065 - accuracy: 0.9627 - val_loss: 0.1494 - val_accuracy: 0.9620 - rmse: 0.3664\n",
      "Epoch 123/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 0.9634\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1051 - accuracy: 0.9634 - val_loss: 0.1424 - val_accuracy: 0.9644 - rmse: 0.3673\n",
      "Epoch 124/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9635\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1053 - accuracy: 0.9635 - val_loss: 0.1429 - val_accuracy: 0.9645 - rmse: 0.3578\n",
      "Epoch 125/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.9637\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1034 - accuracy: 0.9637 - val_loss: 0.1497 - val_accuracy: 0.9648 - rmse: 0.3827\n",
      "Epoch 126/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 0.9641\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1019 - accuracy: 0.9641 - val_loss: 0.1635 - val_accuracy: 0.9581 - rmse: 0.4144\n",
      "Epoch 127/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.9645\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1002 - accuracy: 0.9645 - val_loss: 0.1493 - val_accuracy: 0.9609 - rmse: 0.3685\n",
      "Epoch 128/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9640\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1045 - accuracy: 0.9640 - val_loss: 0.1457 - val_accuracy: 0.9637 - rmse: 0.3453\n",
      "Epoch 129/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.9641\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.1034 - accuracy: 0.9641 - val_loss: 0.1634 - val_accuracy: 0.9564 - rmse: 0.4452\n",
      "Epoch 130/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9657\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0991 - accuracy: 0.9657 - val_loss: 0.1425 - val_accuracy: 0.9647 - rmse: 0.3518\n",
      "Epoch 131/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9658\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0980 - accuracy: 0.9658 - val_loss: 0.1538 - val_accuracy: 0.9611 - rmse: 0.3799\n",
      "Epoch 132/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9639\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.1015 - accuracy: 0.9639 - val_loss: 0.1550 - val_accuracy: 0.9597 - rmse: 0.3841\n",
      "Epoch 133/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9663\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0980 - accuracy: 0.9663 - val_loss: 0.1469 - val_accuracy: 0.9632 - rmse: 0.3737\n",
      "Epoch 134/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9655\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0986 - accuracy: 0.9655 - val_loss: 0.1476 - val_accuracy: 0.9631 - rmse: 0.3787\n",
      "Epoch 135/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9664\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0989 - accuracy: 0.9664 - val_loss: 0.1383 - val_accuracy: 0.9656 - rmse: 0.3443\n",
      "Epoch 136/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.9652\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0982 - accuracy: 0.9652 - val_loss: 0.1671 - val_accuracy: 0.9568 - rmse: 0.4354\n",
      "Epoch 137/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9670\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0939 - accuracy: 0.9670 - val_loss: 0.1507 - val_accuracy: 0.9613 - rmse: 0.3840\n",
      "Epoch 138/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9651\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0974 - accuracy: 0.9651 - val_loss: 0.1503 - val_accuracy: 0.9628 - rmse: 0.3768\n",
      "Epoch 139/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.9679\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.1424 - val_accuracy: 0.9642 - rmse: 0.3796\n",
      "Epoch 140/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.9671\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0923 - accuracy: 0.9670 - val_loss: 0.1487 - val_accuracy: 0.9616 - rmse: 0.4032\n",
      "Epoch 141/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9680\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0936 - accuracy: 0.9680 - val_loss: 0.1509 - val_accuracy: 0.9620 - rmse: 0.3763\n",
      "Epoch 142/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9671\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0947 - accuracy: 0.9671 - val_loss: 0.1396 - val_accuracy: 0.9649 - rmse: 0.3606\n",
      "Epoch 143/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9684\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0920 - accuracy: 0.9684 - val_loss: 0.1482 - val_accuracy: 0.9619 - rmse: 0.3869\n",
      "Epoch 144/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9672\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0919 - accuracy: 0.9672 - val_loss: 0.1452 - val_accuracy: 0.9646 - rmse: 0.3622\n",
      "Epoch 145/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9698\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 0.1494 - val_accuracy: 0.9644 - rmse: 0.3821\n",
      "Epoch 146/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9677\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0909 - accuracy: 0.9677 - val_loss: 0.1384 - val_accuracy: 0.9669 - rmse: 0.3377\n",
      "Epoch 147/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0885 - accuracy: 0.9696\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0884 - accuracy: 0.9697 - val_loss: 0.1422 - val_accuracy: 0.9669 - rmse: 0.3426\n",
      "Epoch 148/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9701\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0861 - accuracy: 0.9701 - val_loss: 0.1571 - val_accuracy: 0.9611 - rmse: 0.3718\n",
      "Epoch 149/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9677\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0902 - accuracy: 0.9676 - val_loss: 0.1428 - val_accuracy: 0.9639 - rmse: 0.3642\n",
      "Epoch 150/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9689\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0887 - accuracy: 0.9689 - val_loss: 0.1425 - val_accuracy: 0.9642 - rmse: 0.3556\n",
      "Epoch 151/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 0.9688\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0891 - accuracy: 0.9688 - val_loss: 0.1582 - val_accuracy: 0.9592 - rmse: 0.3900\n",
      "Epoch 152/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9695\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0873 - accuracy: 0.9696 - val_loss: 0.1493 - val_accuracy: 0.9622 - rmse: 0.3728\n",
      "Epoch 153/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9706\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0842 - accuracy: 0.9706 - val_loss: 0.1387 - val_accuracy: 0.9654 - rmse: 0.3469\n",
      "Epoch 154/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 0.9698\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0880 - accuracy: 0.9697 - val_loss: 0.1519 - val_accuracy: 0.9633 - rmse: 0.3710\n",
      "Epoch 155/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9700\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0851 - accuracy: 0.9700 - val_loss: 0.1482 - val_accuracy: 0.9624 - rmse: 0.3796\n",
      "Epoch 156/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9689\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0879 - accuracy: 0.9689 - val_loss: 0.1460 - val_accuracy: 0.9625 - rmse: 0.3716\n",
      "Epoch 157/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9705\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0839 - accuracy: 0.9705 - val_loss: 0.1332 - val_accuracy: 0.9680 - rmse: 0.3457\n",
      "Epoch 158/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9695\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0872 - accuracy: 0.9695 - val_loss: 0.1404 - val_accuracy: 0.9663 - rmse: 0.3575\n",
      "Epoch 159/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0862 - accuracy: 0.9697\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0862 - accuracy: 0.9697 - val_loss: 0.1555 - val_accuracy: 0.9580 - rmse: 0.3834\n",
      "Epoch 160/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9705\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0828 - accuracy: 0.9705 - val_loss: 0.1419 - val_accuracy: 0.9647 - rmse: 0.3590\n",
      "Epoch 161/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9722\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 0.1330 - val_accuracy: 0.9683 - rmse: 0.3411\n",
      "Epoch 162/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 0.9705\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0845 - accuracy: 0.9704 - val_loss: 0.1314 - val_accuracy: 0.9685 - rmse: 0.3415\n",
      "Epoch 163/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0812 - accuracy: 0.9720\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0812 - accuracy: 0.9720 - val_loss: 0.1407 - val_accuracy: 0.9647 - rmse: 0.3914\n",
      "Epoch 164/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9714\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0809 - accuracy: 0.9713 - val_loss: 0.1738 - val_accuracy: 0.9548 - rmse: 0.4595\n",
      "Epoch 165/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9716\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0789 - accuracy: 0.9716 - val_loss: 0.1442 - val_accuracy: 0.9623 - rmse: 0.3689\n",
      "Epoch 166/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9720\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0796 - accuracy: 0.9720 - val_loss: 0.1399 - val_accuracy: 0.9643 - rmse: 0.3682\n",
      "Epoch 167/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9730\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0810 - accuracy: 0.9730 - val_loss: 0.1357 - val_accuracy: 0.9671 - rmse: 0.3456\n",
      "Epoch 168/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9721\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 0.1391 - val_accuracy: 0.9646 - rmse: 0.3603\n",
      "Epoch 169/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9735\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0770 - accuracy: 0.9735 - val_loss: 0.1337 - val_accuracy: 0.9681 - rmse: 0.3425\n",
      "Epoch 170/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9705\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0830 - accuracy: 0.9705 - val_loss: 0.1401 - val_accuracy: 0.9663 - rmse: 0.3377\n",
      "Epoch 171/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9740\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 0.1454 - val_accuracy: 0.9636 - rmse: 0.3892\n",
      "Epoch 172/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.9732\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.1465 - val_accuracy: 0.9633 - rmse: 0.3549\n",
      "Epoch 173/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9720\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0814 - accuracy: 0.9720 - val_loss: 0.1518 - val_accuracy: 0.9603 - rmse: 0.3720\n",
      "Epoch 174/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9740\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0755 - accuracy: 0.9740 - val_loss: 0.1483 - val_accuracy: 0.9631 - rmse: 0.3655\n",
      "Epoch 175/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9722\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0785 - accuracy: 0.9722 - val_loss: 0.1296 - val_accuracy: 0.9684 - rmse: 0.3431\n",
      "Epoch 176/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9732\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0758 - accuracy: 0.9732 - val_loss: 0.1471 - val_accuracy: 0.9649 - rmse: 0.3777\n",
      "Epoch 177/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9736\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0754 - accuracy: 0.9735 - val_loss: 0.1428 - val_accuracy: 0.9635 - rmse: 0.3786\n",
      "Epoch 178/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9722\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0789 - accuracy: 0.9722 - val_loss: 0.1441 - val_accuracy: 0.9633 - rmse: 0.3752\n",
      "Epoch 179/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9733\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0749 - accuracy: 0.9733 - val_loss: 0.1313 - val_accuracy: 0.9669 - rmse: 0.3387\n",
      "Epoch 180/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9738\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0741 - accuracy: 0.9738 - val_loss: 0.1386 - val_accuracy: 0.9667 - rmse: 0.3557\n",
      "Epoch 181/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.9746\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0733 - accuracy: 0.9746 - val_loss: 0.1504 - val_accuracy: 0.9636 - rmse: 0.3444\n",
      "Epoch 182/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 0.9737\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 0.1452 - val_accuracy: 0.9637 - rmse: 0.3798\n",
      "Epoch 183/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.9745\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 0.1359 - val_accuracy: 0.9668 - rmse: 0.3607\n",
      "Epoch 184/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9737\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0746 - accuracy: 0.9737 - val_loss: 0.1424 - val_accuracy: 0.9639 - rmse: 0.3786\n",
      "Epoch 185/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.9749\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0718 - accuracy: 0.9749 - val_loss: 0.1326 - val_accuracy: 0.9692 - rmse: 0.3560\n",
      "Epoch 186/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9737\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0739 - accuracy: 0.9737 - val_loss: 0.1271 - val_accuracy: 0.9706 - rmse: 0.3245\n",
      "Epoch 187/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9748\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0712 - accuracy: 0.9749 - val_loss: 0.1395 - val_accuracy: 0.9655 - rmse: 0.3563\n",
      "Epoch 188/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9747\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0726 - accuracy: 0.9747 - val_loss: 0.1477 - val_accuracy: 0.9614 - rmse: 0.3817\n",
      "Epoch 189/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.9738\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0718 - accuracy: 0.9738 - val_loss: 0.1384 - val_accuracy: 0.9664 - rmse: 0.3758\n",
      "Epoch 190/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9744\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0719 - accuracy: 0.9744 - val_loss: 0.1417 - val_accuracy: 0.9647 - rmse: 0.3791\n",
      "Epoch 191/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9754\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0711 - accuracy: 0.9754 - val_loss: 0.1338 - val_accuracy: 0.9689 - rmse: 0.3310\n",
      "Epoch 192/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9745\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0713 - accuracy: 0.9745 - val_loss: 0.1383 - val_accuracy: 0.9675 - rmse: 0.3563\n",
      "Epoch 193/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9744\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0702 - accuracy: 0.9744 - val_loss: 0.1343 - val_accuracy: 0.9681 - rmse: 0.3425\n",
      "Epoch 194/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.9754\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0691 - accuracy: 0.9754 - val_loss: 0.1397 - val_accuracy: 0.9655 - rmse: 0.3445\n",
      "Epoch 195/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.9756\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.1368 - val_accuracy: 0.9659 - rmse: 0.3545\n",
      "Epoch 196/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9750\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0712 - accuracy: 0.9750 - val_loss: 0.1393 - val_accuracy: 0.9666 - rmse: 0.3692\n",
      "Epoch 197/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9759\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0673 - accuracy: 0.9759 - val_loss: 0.1362 - val_accuracy: 0.9665 - rmse: 0.3303\n",
      "Epoch 198/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9756\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0702 - accuracy: 0.9756 - val_loss: 0.1297 - val_accuracy: 0.9688 - rmse: 0.3352\n",
      "Epoch 199/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9746\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0700 - accuracy: 0.9746 - val_loss: 0.1356 - val_accuracy: 0.9663 - rmse: 0.3490\n",
      "Epoch 200/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9759\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0677 - accuracy: 0.9759 - val_loss: 0.1357 - val_accuracy: 0.9695 - rmse: 0.3407\n",
      "Epoch 201/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9757\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0688 - accuracy: 0.9757 - val_loss: 0.1309 - val_accuracy: 0.9689 - rmse: 0.3357\n",
      "Epoch 202/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9769\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.1298 - val_accuracy: 0.9680 - rmse: 0.3396\n",
      "Epoch 203/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9757\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0678 - accuracy: 0.9757 - val_loss: 0.1260 - val_accuracy: 0.9702 - rmse: 0.3355\n",
      "Epoch 204/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9768\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 41s 36ms/step - loss: 0.0652 - accuracy: 0.9768 - val_loss: 0.1388 - val_accuracy: 0.9663 - rmse: 0.3312\n",
      "Epoch 205/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9761\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0656 - accuracy: 0.9762 - val_loss: 0.1305 - val_accuracy: 0.9695 - rmse: 0.3502\n",
      "Epoch 206/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9762\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0672 - accuracy: 0.9762 - val_loss: 0.1410 - val_accuracy: 0.9650 - rmse: 0.3771\n",
      "Epoch 207/400\n",
      "1121/1121 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9770\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 64s 57ms/step - loss: 0.0646 - accuracy: 0.9770 - val_loss: 0.1443 - val_accuracy: 0.9640 - rmse: 0.3632\n",
      "Epoch 208/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9757\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 51s 45ms/step - loss: 0.0680 - accuracy: 0.9757 - val_loss: 0.1311 - val_accuracy: 0.9696 - rmse: 0.3221\n",
      "Epoch 209/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9756\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0679 - accuracy: 0.9756 - val_loss: 0.1319 - val_accuracy: 0.9697 - rmse: 0.3390\n",
      "Epoch 210/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9771\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 64s 57ms/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.1354 - val_accuracy: 0.9679 - rmse: 0.3422\n",
      "Epoch 211/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9767\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 82s 73ms/step - loss: 0.0644 - accuracy: 0.9767 - val_loss: 0.1459 - val_accuracy: 0.9639 - rmse: 0.3782\n",
      "Epoch 212/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9780\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 66s 59ms/step - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.1462 - val_accuracy: 0.9647 - rmse: 0.3564\n",
      "Epoch 213/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9768\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 67s 59ms/step - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.1340 - val_accuracy: 0.9680 - rmse: 0.3458\n",
      "Epoch 214/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9765\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 47s 42ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.1386 - val_accuracy: 0.9679 - rmse: 0.3451\n",
      "Epoch 215/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9773\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0650 - accuracy: 0.9773 - val_loss: 0.1480 - val_accuracy: 0.9634 - rmse: 0.3998\n",
      "Epoch 216/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9773\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0641 - accuracy: 0.9773 - val_loss: 0.1284 - val_accuracy: 0.9697 - rmse: 0.3283\n",
      "Epoch 217/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.9782\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0624 - accuracy: 0.9782 - val_loss: 0.1376 - val_accuracy: 0.9663 - rmse: 0.3528\n",
      "Epoch 218/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9774\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 0.1322 - val_accuracy: 0.9709 - rmse: 0.3487\n",
      "Epoch 219/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9789\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0606 - accuracy: 0.9789 - val_loss: 0.1271 - val_accuracy: 0.9695 - rmse: 0.3253\n",
      "Epoch 220/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9771\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0654 - accuracy: 0.9771 - val_loss: 0.1267 - val_accuracy: 0.9692 - rmse: 0.3565\n",
      "Epoch 221/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9778\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0619 - accuracy: 0.9777 - val_loss: 0.1240 - val_accuracy: 0.9717 - rmse: 0.3264\n",
      "Epoch 222/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9778\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0614 - accuracy: 0.9778 - val_loss: 0.1347 - val_accuracy: 0.9677 - rmse: 0.3282\n",
      "Epoch 223/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9780\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0628 - accuracy: 0.9779 - val_loss: 0.1423 - val_accuracy: 0.9658 - rmse: 0.3518\n",
      "Epoch 224/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9765\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0657 - accuracy: 0.9765 - val_loss: 0.1339 - val_accuracy: 0.9680 - rmse: 0.3424\n",
      "Epoch 225/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9790\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.1408 - val_accuracy: 0.9671 - rmse: 0.3398\n",
      "Epoch 226/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9770\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0639 - accuracy: 0.9770 - val_loss: 0.1373 - val_accuracy: 0.9660 - rmse: 0.3572\n",
      "Epoch 227/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9785\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 0.1334 - val_accuracy: 0.9692 - rmse: 0.3401\n",
      "Epoch 228/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9774\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0632 - accuracy: 0.9774 - val_loss: 0.1318 - val_accuracy: 0.9700 - rmse: 0.3519\n",
      "Epoch 229/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 0.9779\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.1393 - val_accuracy: 0.9666 - rmse: 0.3400\n",
      "Epoch 230/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9786\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0601 - accuracy: 0.9786 - val_loss: 0.1334 - val_accuracy: 0.9672 - rmse: 0.3554\n",
      "Epoch 231/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9783\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0610 - accuracy: 0.9783 - val_loss: 0.1301 - val_accuracy: 0.9717 - rmse: 0.3142\n",
      "Epoch 232/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9790\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.1323 - val_accuracy: 0.9686 - rmse: 0.3469\n",
      "Epoch 233/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9795\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0587 - accuracy: 0.9795 - val_loss: 0.1332 - val_accuracy: 0.9699 - rmse: 0.3395\n",
      "Epoch 234/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9779\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0614 - accuracy: 0.9779 - val_loss: 0.1344 - val_accuracy: 0.9693 - rmse: 0.3411\n",
      "Epoch 235/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9793\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.1305 - val_accuracy: 0.9692 - rmse: 0.3522\n",
      "Epoch 236/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9784\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0597 - accuracy: 0.9784 - val_loss: 0.1292 - val_accuracy: 0.9698 - rmse: 0.3393\n",
      "Epoch 237/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9782\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0606 - accuracy: 0.9782 - val_loss: 0.1435 - val_accuracy: 0.9663 - rmse: 0.3596\n",
      "Epoch 238/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9786\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0599 - accuracy: 0.9786 - val_loss: 0.1405 - val_accuracy: 0.9662 - rmse: 0.3490\n",
      "Epoch 239/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9798\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0576 - accuracy: 0.9798 - val_loss: 0.1338 - val_accuracy: 0.9690 - rmse: 0.3232\n",
      "Epoch 240/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9788\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0586 - accuracy: 0.9787 - val_loss: 0.1417 - val_accuracy: 0.9655 - rmse: 0.3667\n",
      "Epoch 241/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9782\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0610 - accuracy: 0.9782 - val_loss: 0.1359 - val_accuracy: 0.9669 - rmse: 0.3729\n",
      "Epoch 242/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9796\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0567 - accuracy: 0.9796 - val_loss: 0.1304 - val_accuracy: 0.9705 - rmse: 0.3407\n",
      "Epoch 243/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9783\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0598 - accuracy: 0.9783 - val_loss: 0.1397 - val_accuracy: 0.9663 - rmse: 0.3552\n",
      "Epoch 244/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9793\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0584 - accuracy: 0.9794 - val_loss: 0.1245 - val_accuracy: 0.9724 - rmse: 0.3291\n",
      "Epoch 245/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9804\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0555 - accuracy: 0.9803 - val_loss: 0.1360 - val_accuracy: 0.9678 - rmse: 0.3468\n",
      "Epoch 246/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9780\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0600 - accuracy: 0.9779 - val_loss: 0.1335 - val_accuracy: 0.9684 - rmse: 0.3397\n",
      "Epoch 247/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9799\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.1398 - val_accuracy: 0.9666 - rmse: 0.3716\n",
      "Epoch 248/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9792\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.1239 - val_accuracy: 0.9707 - rmse: 0.3383\n",
      "Epoch 249/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9802\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0553 - accuracy: 0.9802 - val_loss: 0.1424 - val_accuracy: 0.9653 - rmse: 0.3729\n",
      "Epoch 250/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9802\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0561 - accuracy: 0.9802 - val_loss: 0.1287 - val_accuracy: 0.9715 - rmse: 0.3312\n",
      "Epoch 251/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9793\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0579 - accuracy: 0.9793 - val_loss: 0.1377 - val_accuracy: 0.9666 - rmse: 0.3364\n",
      "Epoch 252/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9805\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0561 - accuracy: 0.9805 - val_loss: 0.1364 - val_accuracy: 0.9678 - rmse: 0.3472\n",
      "Epoch 253/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9797\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0568 - accuracy: 0.9797 - val_loss: 0.1423 - val_accuracy: 0.9665 - rmse: 0.3671\n",
      "Epoch 254/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9803\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.1360 - val_accuracy: 0.9681 - rmse: 0.3550\n",
      "Epoch 255/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 0.9804\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 0.1396 - val_accuracy: 0.9650 - rmse: 0.3436\n",
      "Epoch 256/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9799\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0557 - accuracy: 0.9799 - val_loss: 0.1357 - val_accuracy: 0.9679 - rmse: 0.3456\n",
      "Epoch 257/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9802\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0540 - accuracy: 0.9802 - val_loss: 0.1328 - val_accuracy: 0.9684 - rmse: 0.3538\n",
      "Epoch 258/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9805\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.1386 - val_accuracy: 0.9675 - rmse: 0.3484\n",
      "Epoch 259/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9800\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 0.1349 - val_accuracy: 0.9672 - rmse: 0.3598\n",
      "Epoch 260/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9810\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.1301 - val_accuracy: 0.9697 - rmse: 0.3284\n",
      "Epoch 261/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9801\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0535 - accuracy: 0.9801 - val_loss: 0.1323 - val_accuracy: 0.9692 - rmse: 0.3411\n",
      "Epoch 262/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9814\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0531 - accuracy: 0.9814 - val_loss: 0.1312 - val_accuracy: 0.9690 - rmse: 0.3324\n",
      "Epoch 263/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9796\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0568 - accuracy: 0.9796 - val_loss: 0.1328 - val_accuracy: 0.9696 - rmse: 0.3534\n",
      "Epoch 264/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9811\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.1288 - val_accuracy: 0.9700 - rmse: 0.3556\n",
      "Epoch 265/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9810\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.1473 - val_accuracy: 0.9649 - rmse: 0.3462\n",
      "Epoch 266/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9812\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0532 - accuracy: 0.9812 - val_loss: 0.1328 - val_accuracy: 0.9697 - rmse: 0.3323\n",
      "Epoch 267/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9821\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0520 - accuracy: 0.9821 - val_loss: 0.1298 - val_accuracy: 0.9710 - rmse: 0.3111\n",
      "Epoch 268/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9802\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0558 - accuracy: 0.9802 - val_loss: 0.1281 - val_accuracy: 0.9703 - rmse: 0.3341\n",
      "Epoch 269/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9810\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.1348 - val_accuracy: 0.9679 - rmse: 0.3632\n",
      "Epoch 270/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9811\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.1381 - val_accuracy: 0.9688 - rmse: 0.3383\n",
      "Epoch 271/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0516 - accuracy: 0.9818\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 0.1369 - val_accuracy: 0.9675 - rmse: 0.3689\n",
      "Epoch 272/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9810\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.1271 - val_accuracy: 0.9692 - rmse: 0.3160\n",
      "Epoch 273/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9811\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0525 - accuracy: 0.9811 - val_loss: 0.1352 - val_accuracy: 0.9689 - rmse: 0.3461\n",
      "Epoch 274/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9814\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0518 - accuracy: 0.9814 - val_loss: 0.1322 - val_accuracy: 0.9690 - rmse: 0.3499\n",
      "Epoch 275/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9809\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0526 - accuracy: 0.9809 - val_loss: 0.1292 - val_accuracy: 0.9695 - rmse: 0.3430\n",
      "Epoch 276/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9818\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0515 - accuracy: 0.9818 - val_loss: 0.1355 - val_accuracy: 0.9679 - rmse: 0.3433\n",
      "Epoch 277/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9807\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 43s 38ms/step - loss: 0.0532 - accuracy: 0.9807 - val_loss: 0.1341 - val_accuracy: 0.9681 - rmse: 0.3467\n",
      "Epoch 278/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9811\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0524 - accuracy: 0.9811 - val_loss: 0.1340 - val_accuracy: 0.9691 - rmse: 0.3577\n",
      "Epoch 279/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9814\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 41s 37ms/step - loss: 0.0524 - accuracy: 0.9814 - val_loss: 0.1318 - val_accuracy: 0.9687 - rmse: 0.3513\n",
      "Epoch 280/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9816\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0519 - accuracy: 0.9816 - val_loss: 0.1310 - val_accuracy: 0.9697 - rmse: 0.3249\n",
      "Epoch 281/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9825\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 0.1274 - val_accuracy: 0.9704 - rmse: 0.3410\n",
      "Epoch 282/400\n",
      "1120/1121 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9826\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 41s 36ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.1338 - val_accuracy: 0.9688 - rmse: 0.3342\n",
      "Epoch 283/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9815\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0531 - accuracy: 0.9814 - val_loss: 0.1313 - val_accuracy: 0.9700 - rmse: 0.3127\n",
      "Epoch 284/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9819\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 35ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 0.1521 - val_accuracy: 0.9639 - rmse: 0.3766\n",
      "Epoch 285/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9809\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0525 - accuracy: 0.9809 - val_loss: 0.1357 - val_accuracy: 0.9681 - rmse: 0.3325\n",
      "Epoch 286/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9826\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.1309 - val_accuracy: 0.9688 - rmse: 0.3249\n",
      "Epoch 287/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9823\n",
      "\n",
      "Epoch End - Custom Validation Callback\n",
      "1121/1121 [==============================] - 39s 34ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.1299 - val_accuracy: 0.9689 - rmse: 0.3378\n",
      "Epoch 288/400\n",
      "1119/1121 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9815\n",
      "\n",
      "Epoch End - Custom Validation Callback\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "mpri_model2 = MPRI_model2()\n",
    "trg_results2 = mpri_model2.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e18af68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trg_results2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrg_results2\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m acc2 \u001b[38;5;241m=\u001b[39m trg_results2\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m val_loss2 \u001b[38;5;241m=\u001b[39m trg_results2\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trg_results2' is not defined"
     ]
    }
   ],
   "source": [
    "loss2 = trg_results2.history['loss']\n",
    "acc2 = trg_results2.history['accuracy']\n",
    "val_loss2 = trg_results2.history['val_loss']\n",
    "val_acc2 = trg_results2.history['val_accuracy']\n",
    "rmse2 = trg_results2.history['rmse']\n",
    "epochs2 = [i for i in range(len(rmse2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e057a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "fig, axs = plt.subplots(1,3)\n",
    "\n",
    "axs[0].plot(epochs2, loss2, color='teal', label='trg_loss')\n",
    "axs[0].plot(epochs2, val_loss2, color='orange', label='val_loss')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[0].set_title('Loss', fontsize=20)\n",
    "\n",
    "axs[1].plot(epochs2, acc2, color='teal', label='acc')\n",
    "axs[1].plot(epochs2, val_acc2, color='orange', label='val_acc')\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[1].set_title('Accuracy', fontsize=20)\n",
    "\n",
    "axs[2].plot(epochs2, rmse2, color='teal', label='rmse')\n",
    "axs[2].legend(loc='upper left')\n",
    "axs[2].set_title('RMSE', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f32a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss2= np.array(val_loss2\n",
    "print(f'Minimum loss: {val_loss2min()}')\n",
    "best_epoch2= np.where(val_loss2== val_loss2min())[0][0]\n",
    "\n",
    "print(f'Best Epoch no: {best_epoch2}')\n",
    "print(f'Best val loss: {val_loss2best_epoch2}, Best val acc: {val_acc2best_epoch2}')\n",
    "print(f'Best trg loss: {loss2best_epoch2}, Best trg acc: {acc2best_epoch2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9901d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "rmse2, dist_errors2, cdf_vals2 = mpri_model2.test_model(\"mpri_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75341f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "plt.plot(dist_errors2, cdf_vals2, marker='o')\n",
    "plt.xlabel('Distance Error(m)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Probability Function')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fd37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
