{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed1d466",
   "metadata": {
    "papermill": {
     "duration": 0.004498,
     "end_time": "2023-06-20T01:09:23.304296",
     "exception": false,
     "start_time": "2023-06-20T01:09:23.299798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tuning on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86fc65b7",
   "metadata": {
    "papermill": {
     "duration": 8.90105,
     "end_time": "2023-06-20T01:09:32.209449",
     "exception": false,
     "start_time": "2023-06-20T01:09:23.308399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, SeparableConv2D, Add, Dense, \\\n",
    "BatchNormalization, ReLU, MaxPool2D, GlobalAvgPool2D, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f07cd69",
   "metadata": {
    "papermill": {
     "duration": 0.32422,
     "end_time": "2023-06-20T01:09:32.537866",
     "exception": false,
     "start_time": "2023-06-20T01:09:32.213646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "# Configure amd test GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Prevent automatic GPU memory pre-allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(tf.__version__)\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8add5f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:32.549152Z",
     "iopub.status.busy": "2023-06-20T01:09:32.547548Z",
     "iopub.status.idle": "2023-06-20T01:09:32.562521Z",
     "shell.execute_reply": "2023-06-20T01:09:32.561623Z"
    },
    "papermill": {
     "duration": 0.022098,
     "end_time": "2023-06-20T01:09:32.564315",
     "exception": false,
     "start_time": "2023-06-20T01:09:32.542217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/augmented-dataset-outdoor-v2/augmented_features_10_ue1_v2_ds.npy\n",
      "/kaggle/input/augmented-dataset-outdoor-v2/augmented_labels_10_ue1_v2_ds.npy\n"
     ]
    }
   ],
   "source": [
    "# for kaggle\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97147b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:32.574063Z",
     "iopub.status.busy": "2023-06-20T01:09:32.573606Z",
     "iopub.status.idle": "2023-06-20T01:09:33.758362Z",
     "shell.execute_reply": "2023-06-20T01:09:33.757334Z"
    },
    "papermill": {
     "duration": 1.192621,
     "end_time": "2023-06-20T01:09:33.760860",
     "exception": false,
     "start_time": "2023-06-20T01:09:32.568239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class HyperModel(kt.HyperModel):\n",
    "    \n",
    "    def build(self, hp):\n",
    "        \n",
    "        fc_dropout = hp.Boolean('fc_dropout', default = False)\n",
    "        pooling_dropout = hp.Boolean('pooling_dropout', default = False)\n",
    "        lr = hp.Choice('learning_rate', [0.01, 0.001, 0.0001])\n",
    "        l2_conv2d = hp.Choice('l2_conv2d', [0.0, 0.01])\n",
    "        l2_sepconv2d = hp.Choice('l2_sepconv2d', [0.0, 0.01])\n",
    "        \n",
    "        # Conv2D + Batch Normalization\n",
    "        def conv_bn(x, filters, kernel_size, strides = 1):\n",
    "            x = Conv2D(filters = filters, kernel_size = kernel_size,\n",
    "                   strides = strides, padding = 'same', use_bias = False,\n",
    "                      kernel_regularizer = keras.regularizers.L2(l2_conv2d))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            return x\n",
    "\n",
    "        # Make a seperable convolutional block (Seperable Conv2D + Batch Normalization)\n",
    "        def sep_bn(x, filters, kernel_size, strides = 1):\n",
    "            x = SeparableConv2D(filters = filters, kernel_size = kernel_size, strides = strides,\n",
    "                           padding = 'same', use_bias = False, kernel_regularizer = keras.regularizers.L2(l2_sepconv2d))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            return x\n",
    "        \n",
    "        # Construct the entry flow\n",
    "        def entry_flow(x):\n",
    "\n",
    "            # conv_bn(x, filters, kernel_size, strides)\n",
    "            x = conv_bn(x, filters = 32, kernel_size = 3, strides = 2)\n",
    "            x = ReLU()(x)\n",
    "\n",
    "            x = conv_bn(x, filters = 64, kernel_size = 3)\n",
    "            tensor = ReLU()(x)\n",
    "\n",
    "            # Normal flow\n",
    "            x = sep_bn(tensor, filters = 128, kernel_size = 3)\n",
    "            x = ReLU()(x)\n",
    "            x = sep_bn(x, filters = 128, kernel_size = 3)\n",
    "            x = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "            \n",
    "            if pooling_dropout:\n",
    "                x = Dropout(rate = 0.2)(x)\n",
    "\n",
    "            # Skip connection\n",
    "            tensor = conv_bn(tensor, filters = 128, kernel_size = 1, strides = 2)\n",
    "            x = Add()([x, tensor])\n",
    "            # End of first skip connection\n",
    "\n",
    "            # Skip connection\n",
    "            tensor = conv_bn(tensor, filters = 256, kernel_size = 1, strides = 2)\n",
    "\n",
    "            # Normal flow\n",
    "            x = ReLU()(x)\n",
    "            x = sep_bn(x, filters = 256, kernel_size = 3)\n",
    "            x = ReLU()(x)\n",
    "            x = sep_bn(x, filters = 256, kernel_size = 3)\n",
    "            x = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "            \n",
    "            if pooling_dropout:\n",
    "                x = Dropout(rate = 0.2)(x)\n",
    "                \n",
    "            x = Add()([x, tensor])\n",
    "\n",
    "            # End of second skip connection\n",
    "\n",
    "            # Skip connection\n",
    "            tensor = conv_bn(tensor, filters = 728, kernel_size = 1, strides = 2)\n",
    "\n",
    "            # Normal flow\n",
    "            x = ReLU()(x)\n",
    "            x = sep_bn(x, filters = 728, kernel_size = 3)\n",
    "            x = ReLU()(x)\n",
    "            x = sep_bn(x, filters = 728, kernel_size = 3)\n",
    "            x = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "            \n",
    "            if pooling_dropout:\n",
    "                x = Dropout(rate = 0.2)(x)\n",
    "                \n",
    "            x = Add()([x, tensor])\n",
    "\n",
    "            # End of third skip connection\n",
    "\n",
    "            return x\n",
    "        \n",
    "        # Construct the middle flow\n",
    "        # Combine output from the entry flow and the convolution layers in the middle flow\n",
    "        def middle_flow(tensor):\n",
    "\n",
    "            for _ in range(8):\n",
    "\n",
    "                x = ReLU()(tensor)\n",
    "                x = sep_bn(x, filters = 728, kernel_size = 3)\n",
    "                x = ReLU()(x)\n",
    "                x = sep_bn(x, filters = 728, kernel_size = 3)\n",
    "                x = ReLU()(x)\n",
    "                x = sep_bn(x, filters = 728, kernel_size = 3)\n",
    "\n",
    "                tensor = Add()([x, tensor])\n",
    "\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        def exit_flow(tensor, num_classes = 1000):\n",
    "\n",
    "            # Normal path\n",
    "            x = ReLU()(tensor)\n",
    "            x = sep_bn(x, filters = 728, kernel_size = 3)\n",
    "            x = ReLU()(x)\n",
    "            x = sep_bn(x, filters = 1024, kernel_size = 3)\n",
    "            x = MaxPool2D(pool_size = 3, strides = 2, padding = 'same')(x)\n",
    "            \n",
    "            if pooling_dropout:\n",
    "                x = Dropout(rate = 0.2)(x)\n",
    "\n",
    "            # Skip connection\n",
    "            tensor = conv_bn(tensor, filters = 1024, kernel_size = 1, strides = 2)\n",
    "\n",
    "            # Add outputs\n",
    "            x = Add()([tensor, x])\n",
    "\n",
    "            x = sep_bn(x, filters = 1536, kernel_size = 3)\n",
    "            x = ReLU()(x)\n",
    "            x = sep_bn(x, filters = 2048, kernel_size = 3)\n",
    "            x = ReLU()(x)\n",
    "\n",
    "            x = GlobalAvgPool2D()(x)\n",
    "            \n",
    "            if fc_dropout:\n",
    "                x = Dropout(rate = 0.5)(x)\n",
    "                \n",
    "            x = Dense(units = num_classes, activation = 'softmax')(x)\n",
    "\n",
    "            return x\n",
    "        \n",
    "        model_inputs = Input(shape = (193,16,1))\n",
    "        model_outputs = exit_flow(middle_flow(entry_flow(model_inputs)), num_classes = 3876)\n",
    "        xception_model = Model(model_inputs, model_outputs)\n",
    "\n",
    "        # Check number of parameters\n",
    "        # xception_model.summary()\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(lr)\n",
    "        xception_model.compile(optimizer = optimizer,\n",
    "                              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                              metrics = ['accuracy'])\n",
    "        \n",
    "        return xception_model\n",
    "    \n",
    "    def fit(self, hp, model, X_train, y_train, validation_data = None, **kwargs):\n",
    "        \n",
    "        return model.fit(X_train, y_train,\n",
    "                        validation_data = validation_data,\n",
    "                        batch_size = hp.Choice('batch_size', [16,32,64]),\n",
    "                        **kwargs,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04b937b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:33.770594Z",
     "iopub.status.busy": "2023-06-20T01:09:33.770300Z",
     "iopub.status.idle": "2023-06-20T01:09:38.703527Z",
     "shell.execute_reply": "2023-06-20T01:09:38.702557Z"
    },
    "papermill": {
     "duration": 4.940855,
     "end_time": "2023-06-20T01:09:38.706073",
     "exception": false,
     "start_time": "2023-06-20T01:09:33.765218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "        HyperModel(),\n",
    "        objective = 'val_loss',\n",
    "        max_trials = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada6566e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:38.716343Z",
     "iopub.status.busy": "2023-06-20T01:09:38.716038Z",
     "iopub.status.idle": "2023-06-20T01:09:38.721575Z",
     "shell.execute_reply": "2023-06-20T01:09:38.720678Z"
    },
    "papermill": {
     "duration": 0.012991,
     "end_time": "2023-06-20T01:09:38.723509",
     "exception": false,
     "start_time": "2023-06-20T01:09:38.710518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "fc_dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "pooling_dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "l2_conv2d (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.01], 'ordered': True}\n",
      "l2_sepconv2d (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.01], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5b77ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:38.733806Z",
     "iopub.status.busy": "2023-06-20T01:09:38.732432Z",
     "iopub.status.idle": "2023-06-20T01:09:38.739553Z",
     "shell.execute_reply": "2023-06-20T01:09:38.738741Z"
    },
    "papermill": {
     "duration": 0.013997,
     "end_time": "2023-06-20T01:09:38.741525",
     "exception": false,
     "start_time": "2023-06-20T01:09:38.727528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "/kaggle/input/augmented-dataset-outdoor-v2\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../input/augmented-dataset-outdoor-v2')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d05fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:38.751584Z",
     "iopub.status.busy": "2023-06-20T01:09:38.750995Z",
     "iopub.status.idle": "2023-06-20T01:09:58.215520Z",
     "shell.execute_reply": "2023-06-20T01:09:58.214555Z"
    },
    "papermill": {
     "duration": 19.472063,
     "end_time": "2023-06-20T01:09:58.218062",
     "exception": false,
     "start_time": "2023-06-20T01:09:38.745999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features np array: (89628, 193, 16)\n",
      "Shape of labels np array: (89628,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import dataset\n",
    "features = np.load('augmented_features_10_ue1_v2_ds.npy')\n",
    "labels = np.load('augmented_labels_10_ue1_v2_ds.npy')\n",
    "\n",
    "print(f'Shape of features np array: {features.shape}')\n",
    "print(f'Shape of labels np array: {labels.shape}')\n",
    "\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e60aa91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:58.228353Z",
     "iopub.status.busy": "2023-06-20T01:09:58.228061Z",
     "iopub.status.idle": "2023-06-20T01:09:58.232993Z",
     "shell.execute_reply": "2023-06-20T01:09:58.232120Z"
    },
    "papermill": {
     "duration": 0.012689,
     "end_time": "2023-06-20T01:09:58.235266",
     "exception": false,
     "start_time": "2023-06-20T01:09:58.222577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/augmented-dataset-outdoor-v2\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../../working')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62060620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T01:09:58.245624Z",
     "iopub.status.busy": "2023-06-20T01:09:58.244968Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-06-20T01:09:58.239487",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [02h 03m 02s]\n",
      "val_loss: 0.29336273670196533\n",
      "\n",
      "Best val_loss So Far: 0.25114965438842773\n",
      "Total elapsed time: 11h 44m 21s\n",
      "\n",
      "Search: Running Trial #12\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "False             |True              |fc_dropout\n",
      "True              |False             |pooling_dropout\n",
      "0.01              |0.0001            |learning_rate\n",
      "0                 |0                 |l2_conv2d\n",
      "0.01              |0.01              |l2_sepconv2d\n",
      "64                |16                |batch_size\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 12:54:32.657840: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121/1121 [==============================] - 133s 94ms/step - loss: 7.9339 - accuracy: 0.0010 - val_loss: 7.7580 - val_accuracy: 0.0012\n",
      "Epoch 2/100\n",
      "1121/1121 [==============================] - 99s 88ms/step - loss: 6.9418 - accuracy: 0.0051 - val_loss: 8.1829 - val_accuracy: 0.0025\n",
      "Epoch 3/100\n",
      "1121/1121 [==============================] - 103s 92ms/step - loss: 5.5639 - accuracy: 0.0319 - val_loss: 8.7285 - val_accuracy: 0.0102\n",
      "Epoch 4/100\n",
      "1121/1121 [==============================] - 104s 93ms/step - loss: 4.0834 - accuracy: 0.1096 - val_loss: 4.2528 - val_accuracy: 0.1269\n",
      "Epoch 5/100\n",
      "1121/1121 [==============================] - 105s 93ms/step - loss: 3.0781 - accuracy: 0.2224 - val_loss: 3.0259 - val_accuracy: 0.2462\n",
      "Epoch 6/100\n",
      "1121/1121 [==============================] - 103s 92ms/step - loss: 2.4449 - accuracy: 0.3244 - val_loss: 3.6029 - val_accuracy: 0.2342\n",
      "Epoch 7/100\n",
      "1121/1121 [==============================] - 105s 93ms/step - loss: 1.9619 - accuracy: 0.4190 - val_loss: 2.5021 - val_accuracy: 0.3274\n",
      "Epoch 8/100\n",
      "1121/1121 [==============================] - 105s 94ms/step - loss: 1.6433 - accuracy: 0.4869 - val_loss: 1.8442 - val_accuracy: 0.4535\n",
      "Epoch 9/100\n",
      " 207/1121 [====>.........................] - ETA: 1:15 - loss: 1.4794 - accuracy: 0.5247"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(X_train, y_train,\n",
    "            validation_data = (X_test, y_test),\n",
    "            epochs = 100,\n",
    "            callbacks = [stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875685e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f26a72cb",
   "metadata": {},
   "source": [
    "## Analysis of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb739389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/xception\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06d3b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/committed_git/xception\n",
      "['trial09.json', 'trial06.json', 'trial04.json', 'trial08.json', 'trial10.json', 'trial01.json', 'trial05.json', 'trial00.json', 'trial07.json', 'trial03.json', 'trial02.json']\n"
     ]
    }
   ],
   "source": [
    "# Analysis of results\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "for _, _, file_names in os.walk('tuning_results'):\n",
    "    print(file_names)\n",
    "    files = file_names    \n",
    "\n",
    "tuning_results = {}\n",
    "\n",
    "for file in files:\n",
    "    cur_filename = 'tuning_results/' + file\n",
    "    data = open(cur_filename)\n",
    "    data = json.load(data)\n",
    "    \n",
    "    trial_results = {}\n",
    "    trial_results['trial_id'] = data['trial_id']\n",
    "    trial_results['values'] = data['hyperparameters']['values']\n",
    "    trial_results['val_loss'] = data['metrics']['metrics']['val_loss']['observations'][0]['value'][0]\n",
    "    trial_results['status'] = data['status']\n",
    "    tuning_results[data['trial_id']] = trial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0d0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial that resulted in minimum validation loss: 00\n",
      "Validation Loss: 0.25114965438842773\n",
      "Best Hyperparameters: {'fc_dropout': True, 'pooling_dropout': False, 'learning_rate': 0.0001, 'l2_conv2d': 0.0, 'l2_sepconv2d': 0.01, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(tuning_results.keys(), key=lambda x: tuning_results[x]['val_loss'])\n",
    "\n",
    "print(f'Trial that resulted in minimum validation loss: {best_trial}')\n",
    "print(f'Validation Loss: {tuning_results[best_trial][\"val_loss\"]}')\n",
    "print(f'Best Hyperparameters: {tuning_results[best_trial][\"values\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc24d2",
   "metadata": {},
   "source": [
    "## Best Hyperparameters:\n",
    "- fc_dropout: True\n",
    "- pooling_dropout: False\n",
    "- learning_rate: 0.0001\n",
    "- l2_conv2d: 0.0\n",
    "- l2_sepconv2d: 0.01\n",
    "- batch_size: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8cde7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-20T01:09:11.975837",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
